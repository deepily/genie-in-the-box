[default]

foo                               = the most ubiquitous variable name after 'i' and 'j' in programming

app_verbose                       = Verbosity flag for flask app. Options are True or False, defaults to False.
app_debug                         = Debugging flag for flask app. Options are True or False, defaults to False.
app_silent                        = Silent flag for flask app. Options are True or False, defaults to False.

stt_device_id                     = Device ID for STT model.  Options are 'cuda:0', 'cuda:1' or 'cpu', defaults to 'cuda:0'.
stt_model_id                      = Model ID for STT model.  Options are currently only 'distil-whisper/distil-large-v2', defaults to 'distil-whisper/distil-large-v2'.

tts_local_url_template            = URL string used to build arequest for the local TTS service
tts_generation_strategy           = Strategy for generating TTS audio.  Options are 'local' and 'openai', defaults to local.

app_config_server_name            = Name of the server that hosts the flask app.  Needed for CORS workaround.

path_to_snapshots_dir_wo_root     = Path to the snapshots directory, relative to the root of the project.
path_to_events_df_wo_root         = Path to the events dataframe, relative to the root of the project.

vox_command_llm_name              = Name of the LLM to use for the vox command.  Options are 'Mistral-7B-Instruct-v0.2/merged-00-2024.01.23.awq', defaults to 'Mistral-7B-Instruct-v0.2/merged-00-2024.01.23.awq'.
vox_command_llm_path_wo_root      = Where in the project tree can we find the vox command LLM?
vox_command_llm_device_map        = Which CUDA device should we assign the vox command LLM to?
vox_command_prompt_path_wo_root   = Where does the command prompt template live?

agent_router_prompt_path_wo_root  = Where does the agent router prompt template live?

tgi_server_codegen_url            = Fully qualified path to the codegen LLM server, including port, e.g. 'http://127.0.0.1:3000'
tgi_server_codegen_name           = Name of the codegen LLM to use, e.g. 'Phind-CodeLlama-34B-v2'

tgi_server_router_url             = Fully qualified path to the router LLM server, including port, e.g. 'http://127.0.0.1:3000'
tgi_server_router_name            = Name of the router LLM to use, e.g. 'Mistral-7B-Router-v0.2/merged-00-2024.02.05.awq'