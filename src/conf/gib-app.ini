[default]

foo = bar

#######################################################################################################################
[Genie in the Box: Production]
#######################################################################################################################
inherits                          = Genie in the Box: Baseline

tts_generation_strategy           = openai

#######################################################################################################################
[Genie in the Box: Development]
#######################################################################################################################
inherits                          = Genie in the Box: Baseline

app_config_server_name            = 127.0.0.1:7999

;agent_model_name_for_calendaring   = Groq/mixtral-8x7b-32768
agent_model_name_for_calendaring    = TGI/Phind-CodeLlama-34B-v2
agent_model_name_for_date_and_time  = TGI/Phind-CodeLlama-34B-v2
;agent_model_name_for_debugger      = TGI/Phind-CodeLlama-34B-v2
agent_model_name_for_debugger       = Groq/llama2-70b-4096
;agent_model_name_for_weather       = OpenAI/gpt-4-0613
agent_model_name_for_weather        = OpenAI/gpt-3.5-turbo-1106
agent_model_name_for_todo_list      = TGI/Phind-CodeLlama-34B-v2
;agent_model_name_for_todo_list     = OpenAI/gpt-3.5-turbo-1106
agent_model_name_for_bug_injector   = TGI/Phind-CodeLlama-34B-v2

agent_prompt_for_calendaring   = /src/conf/prompts/agents/calendaring.txt
agent_prompt_for_date_and_time = /src/conf/prompts/agents/date-and-time.txt
agent_prompt_for_weather       = /src/conf/prompts/agents/weather.txt
agent_prompt_for_todo_list     = /src/conf/prompts/agents/todo-lists.txt
agent_prompt_for_debugger      = /src/conf/prompts/agents/debugger.txt
agent_prompt_for_bug_injector  = /src/conf/prompts/agents/bug-injector.txt

agent_todo_list_serialize_prompt_to_json = False
agent_todo_list_serialize_code_to_json   = False

database_path_wo_root            = /src/conf/long-term-memory/gib.lancedb

;formatter_model_name_for_calendaring   = OpenAI/gpt-4-0613
;formatter_model_name_for_calendaring   = Groq/llama2-70b-4096
formatter_model_name_for_calendaring    = TGI/Phind-CodeLlama-34B-v2
formatter_model_name_for_date_and_time  = TGI/Phind-CodeLlama-34B-v2
;formatter_model_name_for_date_and_time = OpenAI/gpt-3.5-turbo-1106
;formatter_model_name_for_date_and_time = OpenAI/gpt-4-0613
formatter_model_name_for_weather        = OpenAI/gpt-3.5-turbo-1106
;formatter_model_name_for_todo_list     = TGI/Phind-CodeLlama-34B-v2
formatter_model_name_for_todo_list      = OpenAI/gpt-3.5-turbo-1106

formatter_prompt_for_calendaring   = /src/conf/prompts/formatters/calendaring.txt
formatter_prompt_for_date_and_time = /src/conf/prompts/formatters/date-and-time.txt
formatter_prompt_for_weather       = /src/conf/prompts/formatters/weather.txt
formatter_prompt_for_todo_list     = /src/conf/prompts/formatters/todo-list.txt

llm_model_keys_for_debugger        = [ "llm_debugger_params_phind_34b_v2", "llm_debugger_params_google_gemini_pro", "llm_debugger_params_openai_gpt_4" ]
# llm_model_keys_for_debugger        = [ "llm_debugger_params_google_gemini_pro" ]
# llm_model_keys_for_debugger        = [ "llm_debugger_params_phind_34b_v2", "llm_debugger_params_google_gemini_pro", "llm_debugger_params_groq_llama2_70b" ]

llm_debugger_params_phind_34b_v2      = { "model": "TGI/Phind-CodeLlama-34B-v2", "short_name": "phind-34b-v2", "temperature": 0.5, "top_k": 10, "top_p": 0.25, "max_new_tokens": 1024, "stop_sequence": [ "</response>" ] }
llm_debugger_params_google_gemini_pro = { "model": "Google/gemini-1.0-pro-latest", "short_name": "gemini-1.0", "temperature": 0.5, "top_k": 10, "top_p": 0.25, "max_new_tokens": 1024, "stop_sequence": [ "</response>" ] }
llm_debugger_params_openai_gpt_4      = { "model": "OpenAI/gpt-4-0613", "short_name": "gpt4", "temperature": 0.5, "top_k": 10, "top_p": 0.25, "max_new_tokens": 1024, "stop_sequence": [ "</response>" ] }
llm_debugger_params_groq_llama2_70b   = { "model": "Groq/llama2-70b-4096", "short_name": "llama2-70b", "temperature": 0.5, "top_k": 10, "top_p": 0.25, "max_new_tokens": 1024, "stop_sequence": [ "</response>" ] }
llm_debugger_params_groq_mixtral_8x78 = { "model": "Groq/mixtral-8x7b-32768", "short_name": "mixtral-8x7b", "temperature": 0.5, "top_k": 10, "top_p": 0.25, "max_new_tokens": 1024, "stop_sequence": [ "</response>" ] }
llm_debugger_params_openai_gpt_3_5    = { "model": "OpenAI/gpt-3.5-turbo-1106", "short_name": "gpt3.5", "temperature": 0.5, "top_k": 10, "top_p": 0.25, "max_new_tokens": 1024, "stop_sequence": [ "</response>" ] }

path_to_debugger_prompts_wo_root  = /src/conf/prompts/iterative-agents/debugger/

path_to_events_df_wo_root         = /src/conf/long-term-memory/events.csv
path_to_event_prompts_wo_root     = /src/conf/prompts/incremental-agents/events/

path_to_snapshots_dir_wo_root     = /src/conf/long-term-memory/solutions/

path_to_todolist_df_wo_root       = /src/conf/long-term-memory/todo.csv
path_to_todolist_prompts_wo_root  = /src/conf/prompts/incremental-agents/todo-lists/


snapshot_similiarity_threshold     = 92.5

stt_device_id                     = cuda:0
stt_model_id                      = distil-whisper/distil-large-v2

tts_local_url_template            = http://192.168.0.188:5002/api/tts?text={tts_text}
tts_generation_strategy           = openai

tgi_server_codegen_url            = http://172.17.0.3:3000
tgi_server_router_name            = Mistral-7B-Router-v0.2/merged-00-2024.02.05.awq

vox_command_llm_name              = Mistral-7B-Instruct-v0.2.AWQ (2024.02.05)
vox_command_llm_path_wo_root      = /models/Mistral-7B-Instruct-v0.2/merged-00-2024.02.05.awq/
vox_command_llm_device_map        = cuda:0
vox_command_prompt_path_wo_root   = /src/conf/prompts/vox-command-template.txt

agent_router_prompt_path_wo_root  = /src/conf/prompts/agent-router-template.txt

#######################################################################################################################
[Genie in the Box: Baseline]
#######################################################################################################################


app_debug                         = True
app_verbose                       = True
app_silent                        = False

auto_debug                        = True
inject_bugs                       = False

tts_generation_strategy           = local