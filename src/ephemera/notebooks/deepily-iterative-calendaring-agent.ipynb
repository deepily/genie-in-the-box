{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# load the notebook magic that forces source code to be reloaded\n",
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T15:41:21.984084Z",
     "start_time": "2023-12-05T15:41:21.960010Z"
    }
   },
   "id": "b5f09708803cc601"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/genie-in-the-box/src/ephemera/notebooks\n",
      "/var/genie-in-the-box/src\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "# get current working directory\n",
    "print( os.getcwd() )\n",
    "\n",
    "# change current directory\n",
    "os.chdir( \"/var/genie-in-the-box/src/\" )\n",
    "\n",
    "print( os.getcwd() )\n",
    "\n",
    "import lib.utils.util as du\n",
    "import lib.utils.util_stopwatch as sw"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T15:41:24.263481Z",
     "start_time": "2023-12-05T15:41:24.056068Z"
    }
   },
   "id": "fdc361c258f43d39"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from lib.agents.agent import Agent\n",
    "from lib.agents.agent_calendaring import CalendaringAgent\n",
    "import re\n",
    "import datetime\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T15:41:27.932600Z",
     "start_time": "2023-12-05T15:41:27.383721Z"
    }
   },
   "id": "56d3cde401f93e59"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from lib.agents.agent_code import CodeAgent\n",
    "import lib.utils.util_xml as dux\n",
    "from lib.memory.solution_snapshot import SolutionSnapshot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T15:41:28.670190Z",
     "start_time": "2023-12-05T15:41:28.664707Z"
    }
   },
   "id": "7a2c8567c2e8cafc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CalendaringAgentIterative( CalendaringAgent ):\n",
    "    \n",
    "    PHIND_34B_v2  = \"Phind/Phind-CodeLlama-34B-v2\"\n",
    "    \n",
    "    def __init__( self, path_to_df, question=\"\", default_model=Agent.PHIND_34B_v2, push_counter=-1, debug=False, verbose=False ):\n",
    "        \n",
    "        super().__init__( path_to_df, question=question, default_model=default_model, push_counter=push_counter, debug=debug, verbose=verbose )\n",
    "        \n",
    "        self.token_count       = 0\n",
    "        self.prompt_components = None\n",
    "        self.question          = question\n",
    "        self.prompt_components = self._initialize_prompt_components( self.df, self.question )\n",
    "        \n",
    "    def _initialize_prompt_components( self, df, question ):\n",
    "        \n",
    "        head, event_value_counts = self._get_df_metadata( df )\n",
    "        \n",
    "        # The only Python libraries that you may use: You must only use the datetime and Pandas libraries, which have been imported in the following manner: `import pandas as pd` and`import datetime as dt`.\n",
    "        step_1 = f\"\"\"\n",
    "        You are a cheerfully and helpful assistant, with proven expertise using Python to query pandas dataframes.\n",
    "                \n",
    "        Your job is to translate human questions about calendars, dates, and events into a self-contained Python functions that can be used to answer the question now and reused in the future.\n",
    "                \n",
    "        About the Pandas dataframe: The name of the events dataframe is `df` and is already loaded in memory ready to be queried.\n",
    "        \n",
    "        Here are some hints to keep in mind and guide you as you craft your solution:\n",
    "        Start and end dates: An event that I have today may have started before today and may end tomorrow or next week, so be careful how you filter on dates.\n",
    "        Filtering: When filtering by dates, use `pd.Timestamp( day )` to convert a Python datetime object into a Pandas `datetime64[ns]` value.\n",
    "        Return values: You should always return a dataframe, and it must always include all columns in the dataframe, and never a subset.\n",
    "        \n",
    "        This is the ouput from `print(df.head().to_xml())`, in XML format:\n",
    "        {head}\n",
    "        \n",
    "        This is the output from `print(self.df.event_type.value_counts())`:\n",
    "        \n",
    "        {event_value_counts}\n",
    "        \n",
    "        Given the context I have provided above, I want you to write a Python function to answer the following question:\n",
    "        \n",
    "        Question: `{question}`\n",
    "        \n",
    "        In order to successfully write a function that answers the question above, you must follow my instructions step by step. As you complete each step I will recount your progress on the previous steps and provide you with the next step's instructions.\n",
    "        \n",
    "        Step one) Think: think out loud about what you are being asked, including what are the steps that you will need to take in your code to solve this problem. Be critical of your thought process! And make sure to consider what you will call the entry point to your python solution, such as `def get_events_for_today( df )`, or `def get_events_for_tomorrow( df )`, or `def get_events_for_this_week( df )` or even `def get_birthday_for( df, name )`.\n",
    "        \"\"\"\n",
    "        xml_formatting_instructions_step_1 = \"\"\"\n",
    "        You must respond to the step one directive using the following XML format:\n",
    "        <response>\n",
    "            <thoughts>Your thoughts</thoughts>\n",
    "        </response>\n",
    "        \n",
    "        Begin!\n",
    "        \"\"\"\n",
    "        \n",
    "        step_2 = \"\"\"\n",
    "        In response to the instructions that you received for step one you replied:\n",
    "        \n",
    "        {response}\n",
    "        \n",
    "        Step two) Code: Now that you have thought about how you are going to solve the problem, it's time to generate the Python code that you will use to arrive at your answer. The code must be complete, syntactically correct, and capable of running to completion. The last line of your function code must be `return solution`.  Remember: You must never return a subset of a dataframe's columns. \n",
    "        \"\"\"\n",
    "        xml_formatting_instructions_step_2 = \"\"\"\n",
    "        You must respond to the step 2 directive using the following XML format:\n",
    "        <response>\n",
    "            <code>\n",
    "                <line>def function_name_here( df, arg1, arg2 ):</line>\n",
    "                <line>    ...</line>\n",
    "                <line>    ...</line>\n",
    "                <line>    return solution</line>\n",
    "            </code>\n",
    "        </response>\n",
    "        \n",
    "        Begin!\n",
    "        \"\"\"\n",
    "        \n",
    "        step_3 = \"\"\"\n",
    "        In response to the instructions that you received for step two, you replied:\n",
    "        \n",
    "        {response}\n",
    "        \n",
    "        Now that you have generated the code, you will need to perform the following three steps:\n",
    "        \n",
    "        Step three) Return: Report on the object type of the variable `solution` returned in your last line of code. Use one word to represent the object type.\n",
    "        \n",
    "        Step four) Example: Create a one line example of how to call your code.\n",
    "        \n",
    "        Step five) Explain: Explain how your code works, including any assumptions that you have made.\n",
    "        \"\"\"\n",
    "        xml_formatting_instructions_step_3 = \"\"\"\n",
    "        You must respond to the directives in steps three, four and five using the following XML format:\n",
    "        \n",
    "        <response>\n",
    "            <returns>Object type of the variable `solution`</returns>\n",
    "            <example>One-line example of how to call your code: solution = function_name_here( arguments )</example>\n",
    "            <explanation>Explanation of how the code works</explanation>\n",
    "        </response>\n",
    "        \n",
    "        Begin!\n",
    "        \"\"\"\n",
    "        \n",
    "        step_4 = \"\"\"\n",
    "        In response to the instructions that you received for step three, you replied:\n",
    "        \n",
    "        {response}\n",
    "        \n",
    "        Congratulations! We're finished ðŸ˜€\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        prompt_components = {    \n",
    "                                  \"steps\" : [ step_1, step_2, step_3, step_4 ],\n",
    "                              \"responses\" : [ ],\n",
    "                     \"response_tag_names\" : [ [ \"thoughts\" ], [ \"code\" ], [ \"returns\", \"example\", \"explanation\" ] ],\n",
    "                        \"running_history\" : \"\",\n",
    "            \"xml_formatting_instructions\" : [ \n",
    "                xml_formatting_instructions_step_1, xml_formatting_instructions_step_2, xml_formatting_instructions_step_3 \n",
    "            ]\n",
    "        }   \n",
    "        \n",
    "        return prompt_components   \n",
    "    \n",
    "    def _get_df_metadata( self, df ):\n",
    "    \n",
    "        head = df.head( 3 ).to_xml( index=False )\n",
    "        head = head + df.tail( 3 ).to_xml( index=False )\n",
    "        head = head.replace( \"data>\", \"events>\" ).replace( \"<?xml version='1.0' encoding='utf-8'?>\", \"\" )\n",
    "        \n",
    "        event_value_counts = df.event_type.value_counts()\n",
    "        \n",
    "        return head, event_value_counts\n",
    "    \n",
    "    def run_prompt( self ):\n",
    "    \n",
    "        self.token_count            = 0\n",
    "        timer                       = sw.Stopwatch( msg=f\"Running iterative prompt with {len( self.prompt_components[ 'steps' ] )} steps...\" )\n",
    "        prompt_response_dict        = {}\n",
    "        \n",
    "        steps                       = self.prompt_components[ \"steps\" ]\n",
    "        xml_formatting_instructions = self.prompt_components[ \"xml_formatting_instructions\" ]\n",
    "        response_tag_names          = self.prompt_components[ \"response_tag_names\" ]\n",
    "        responses                   = self.prompt_components[ \"responses\" ]\n",
    "        running_history             = self.prompt_components[ \"running_history\" ]\n",
    "        \n",
    "        for step in range( len( steps ) ):\n",
    "            \n",
    "            if step == 0:\n",
    "                # the first step doesn't have any previous responses to incorporate into it\n",
    "                running_history = steps[ step ]\n",
    "            else:\n",
    "                # incorporate the previous response into the current step, append it to the running history    \n",
    "                running_history = running_history + steps[ step ].format( response=responses[ step - 1 ] )\n",
    "                \n",
    "            # we're not going to execute the last step, it's been added just to keep the running history current\n",
    "            if step != len( steps ) - 1:\n",
    "                \n",
    "                response = self._query_llm_phind( running_history, xml_formatting_instructions[ step ] )\n",
    "                responses.append( response )\n",
    "                \n",
    "                # Incrementally update the contents of the response dictionary according to the results of the XML-esque parsing \n",
    "                prompt_response_dict = self._update_response_dictionary( step, response, prompt_response_dict, response_tag_names, debug=False )\n",
    "    \n",
    "        self.prompt_components[ \"running_history\" ] = running_history\n",
    "        self.prompt_response_dict = prompt_response_dict\n",
    "        \n",
    "        timer.print( \"Done!\", use_millis=True, prepend_nl=False )\n",
    "        tokens_per_second = self.token_count / ( timer.get_delta_ms() / 1000.0 )\n",
    "        print( f\"Tokens per second [{round( tokens_per_second, 1 )}]\" )\n",
    "        \n",
    "        return self.prompt_response_dict\n",
    "\n",
    "    def _query_llm_phind( self, preamble, instructions, model=PHIND_34B_v2, temperature=0.50, max_new_tokens=1024, debug=False ):\n",
    "    \n",
    "        timer = sw.Stopwatch( msg=f\"Asking LLM [{model}]...\" )\n",
    "        \n",
    "        client         = InferenceClient( du.get_tgi_server_url() )\n",
    "        token_list     = [ ]\n",
    "        ellipsis_count = 0\n",
    "        \n",
    "        prompt = f\"{preamble}{instructions}\\n\"\n",
    "        print( prompt )\n",
    "        \n",
    "        for token in client.text_generation(\n",
    "            prompt, max_new_tokens=max_new_tokens, stream=True, stop_sequences=[ \"</response>\" ], temperature=temperature\n",
    "        ):\n",
    "            print( token, end=\"\" )\n",
    "            token_list.append( token )\n",
    "            \n",
    "        response         = \"\".join( token_list ).strip()\n",
    "        self.token_count = self.token_count + len( token_list )\n",
    "        \n",
    "        print()\n",
    "        print( f\"Response tokens [{len( token_list )}]\" )\n",
    "        timer.print( \"Done!\", use_millis=True, prepend_nl=True )\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _update_response_dictionary( self, step, response, prompt_response_dict, tag_names, debug=True ):\n",
    "    \n",
    "        if debug: print( f\"update_response_dictionary called with step [{step}]...\" )\n",
    "        \n",
    "        # Parse response and update response dictionary\n",
    "        xml_tags_for_step_n = tag_names[ step ]\n",
    "        \n",
    "        for xml_tag in xml_tags_for_step_n:\n",
    "            \n",
    "            if debug: print( f\"Looking for xml_tag [{xml_tag}]\" )\n",
    "            \n",
    "            if xml_tag == \"code\":\n",
    "                # the get_code method expects enclosing tags\n",
    "                xml_string = \"<code>\" + du.get_value_by_xml_tag_name( response, xml_tag ) + \"</code>\"\n",
    "                prompt_response_dict[ xml_tag ] = self._get_code( xml_string, debug=debug )\n",
    "            else:\n",
    "                prompt_response_dict[ xml_tag ] = du.get_value_by_xml_tag_name( response, xml_tag ).strip()\n",
    "\n",
    "        return prompt_response_dict\n",
    "    \n",
    "    def _get_code( self, xml_string, debug=False ):\n",
    "    \n",
    "        # if debug:\n",
    "        #     du.print_banner( \"get_code called...\" )\n",
    "        #     print( f\"xml_string [{xml_string}]\" )\n",
    "    \n",
    "        skip_list = []#[ \"import pandas\", \"import datetime\" ]\n",
    "        \n",
    "        # Matches all text between the opening and closing line tags, including the white space after the opening line tag\n",
    "        pattern   = re.compile( r\"<line>(.*?)</line>\" )\n",
    "        code      = du.get_value_by_xml_tag_name( xml_string, \"code\" )\n",
    "        code_list = []\n",
    "    \n",
    "        for line in code.split( \"\\n\" ):\n",
    "    \n",
    "            match = pattern.search( line )\n",
    "            \n",
    "            for skip in skip_list:\n",
    "                if skip in line:\n",
    "                    if debug: print( f\"[SKIPPING '{skip}']\" )\n",
    "                    match = None\n",
    "                    break\n",
    "                    \n",
    "            if match:\n",
    "                line = match.group( 1 )\n",
    "                line = line.replace( \"&gt;\", \">\" ).replace( \"&lt;\", \"<\" ).replace( \"&amp;\", \"&\" )\n",
    "                code_list.append( line )\n",
    "                if debug: print( line )\n",
    "            else:\n",
    "                code_list.append( \"\" )\n",
    "                if debug: print( \"[]\" )\n",
    "    \n",
    "        return code_list\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    path_to_df    = \"/src/conf/long-term-memory/events.csv\"\n",
    "    # question      = \"What birthdays do I have on my calendar this week?\"\n",
    "    question      = \"What's today's date?\"\n",
    "    agent         = CalendaringAgentIterative( path_to_df, question=question, debug=True, verbose=False )\n",
    "    prompt_response_dict = agent.run_prompt()\n",
    "    \n",
    "    # agent.print_code()\n",
    "    \n",
    "    code_response    = agent.run_code()\n",
    "    du.print_banner( \"code_response:\", prepend_nl=False )\n",
    "    print( code_response )\n",
    "    # formatted_output = agent.format_output()\n",
    "    # \n",
    "    # du.print_banner( question, prepend_nl=False )\n",
    "    # for line in formatted_output.split( \"\\n\" ):\n",
    "    #     print( line )\n",
    "    #     \n",
    "    # # code_response_dict = prompt_response_dict[ \"code\" ]\n",
    "    # \n",
    "    # du.print_banner( \"Done! prompt_response_dict:\", prepend_nl=True )\n",
    "    # print( prompt_response_dict )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f2b70face385c5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d5acb37f39b51864"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
