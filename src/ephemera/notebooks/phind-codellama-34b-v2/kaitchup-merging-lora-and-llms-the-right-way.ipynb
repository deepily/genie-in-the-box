{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os \n",
    "import wandb\n",
    "os.chdir( \"/var/model\" )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T15:59:45.588164Z",
     "start_time": "2023-11-17T15:59:45.219559Z"
    }
   },
   "id": "acb985871746d539"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14G\r\n",
      "drwxrwxr-x  6 1001 1001 4.0K Nov 17 15:51 .\r\n",
      "drwxr-xr-x  1 root root 4.0K Nov 17 15:36 ..\r\n",
      "drwxr-xr-x  2 root root 4.0K Nov 11 03:01 .ipynb_checkpoints\r\n",
      "-rw-rw-r--  1 1001 1001 6.9K Nov  5 17:36 LICENSE\r\n",
      "-rw-rw-r--  1 1001 1001 6.1K Nov  5 17:36 README.md\r\n",
      "-rw-rw-r--  1 1001 1001 4.7K Nov  5 17:36 USE_POLICY.md\r\n",
      "-rw-r--r--  1 root root 9.3K Nov 11 02:12 code-llama-instruct-7b-peft.ipynb\r\n",
      "-rw-r--r--  1 1001 1001  97K Nov 11 03:08 code-llama-instruct-7b.ipynb\r\n",
      "-rw-rw-r--  1 1001 1001  646 Nov  5 17:36 config.json\r\n",
      "-rw-rw-r--  1 1001 1001  116 Nov  5 17:36 generation_config.json\r\n",
      "drwxr-xr-x  2 root root 4.0K Nov 17 15:47 merged\r\n",
      "-rw-rw-r--  1 1001 1001 9.3G Nov  5 17:42 model-00001-of-00002.safetensors\r\n",
      "-rw-rw-r--  1 1001 1001 3.3G Nov  5 17:40 model-00002-of-00002.safetensors\r\n",
      "-rw-rw-r--  1 1001 1001  25K Nov  5 17:36 model.safetensors.index.json\r\n",
      "-rw-rw-r--  1 1001 1001  24K Nov  5 17:36 pytorch_model.bin.index.json\r\n",
      "-rw-rw-r--  1 1001 1001  411 Nov  5 17:36 special_tokens_map.json\r\n",
      "-rw-r--r--  1 1001 1001  27K Nov 10 21:15 text-generation.ipynb\r\n",
      "-rw-------  1 1001 1001 1.1G Nov 10 18:44 tmpdknh986h\r\n",
      "-rw-rw-r--  1 1001 1001 1.8M Nov  5 17:36 tokenizer.json\r\n",
      "-rw-rw-r--  1 1001 1001 489K Nov  5 17:36 tokenizer.model\r\n",
      "-rw-rw-r--  1 1001 1001  749 Nov  5 17:36 tokenizer_config.json\r\n",
      "drwxr-xr-x  2 root root 4.0K Nov 17 15:51 training-results\r\n",
      "-rw-r--r--  1 1001 1001    1 Nov 10 18:43 version.txt\r\n",
      "drwxr-xr-x 10 root root 4.0K Nov 17 15:51 wandb\r\n"
     ]
    }
   ],
   "source": [
    "! ls -alh"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T15:59:45.700521Z",
     "start_time": "2023-11-17T15:59:45.588095Z"
    }
   },
   "id": "a814fb2fabc32aa1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mricardo-felipe-ruiz\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T15:59:46.946394Z",
     "start_time": "2023-11-17T15:59:45.947995Z"
    }
   },
   "id": "bc706e68e79bb92d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=codellama-7b-instruct-hf-peft-fine-tuning\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=codellama-7b-instruct-hf-peft-fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T15:59:49.214155Z",
     "start_time": "2023-11-17T15:59:49.206053Z"
    }
   },
   "id": "43e8781863112cc6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "#Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained( \".\", add_eos_token=True, use_fast=True )\n",
    "#Create a new token and add it to the tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "dataset = load_dataset( \"timdettmers/openassistant-guanaco\" )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:00:01.861378Z",
     "start_time": "2023-11-17T15:59:57.741335Z"
    }
   },
   "id": "e313f9d5c01516b3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitsAndBytesConfig {\n",
      "  \"bnb_4bit_compute_dtype\": \"float16\",\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "  \"llm_int8_has_fp16_weight\": false,\n",
      "  \"llm_int8_skip_modules\": null,\n",
      "  \"llm_int8_threshold\": 6.0,\n",
      "  \"load_in_4bit\": true,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"quant_method\": \"bitsandbytes\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab0180f37e45468f8668b0b60741f93b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "compute_dtype = getattr( torch, \"float16\" )\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "print( bnb_config )\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \".\", quantization_config=bnb_config, device_map={\"\": 0}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:00:22.811091Z",
     "start_time": "2023-11-17T16:00:18.042833Z"
    }
   },
   "id": "81d4f8e996310e3f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:00:51.013016Z",
     "start_time": "2023-11-17T16:00:50.601742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/518 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b7e0535ffe5496d8c85009eb72e6450"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    r=16,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules= [\"gate_proj\", \"down_proj\", \"up_proj\"]\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "        output_dir=\"./training-results\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        do_eval=True,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=8,\n",
    "        per_device_eval_batch_size=4,\n",
    "        log_level=\"debug\",\n",
    "        save_steps=100,\n",
    "        logging_steps=100,\n",
    "        learning_rate=4e-4,\n",
    "        eval_steps=100,\n",
    "        fp16=True,\n",
    "        num_train_epochs=1,\n",
    "        warmup_steps=100,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset['train'],\n",
    "        eval_dataset=dataset['test'],\n",
    "        peft_config=peft_config,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=512,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 4\n",
      "***** Running training *****\n",
      "  Num examples = 9,846\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Training with DataParallel so batch size has been adjusted to: 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 307\n",
      "  Number of trainable parameters = 23,199,744\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/var/model/wandb/run-20231117_160102-yko3ozlt</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/ricardo-felipe-ruiz/codellama-7b-instruct-hf-peft-fine-tuning/runs/yko3ozlt' target=\"_blank\">gentle-fog-8</a></strong> to <a href='https://wandb.ai/ricardo-felipe-ruiz/codellama-7b-instruct-hf-peft-fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/ricardo-felipe-ruiz/codellama-7b-instruct-hf-peft-fine-tuning' target=\"_blank\">https://wandb.ai/ricardo-felipe-ruiz/codellama-7b-instruct-hf-peft-fine-tuning</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/ricardo-felipe-ruiz/codellama-7b-instruct-hf-peft-fine-tuning/runs/yko3ozlt' target=\"_blank\">https://wandb.ai/ricardo-felipe-ruiz/codellama-7b-instruct-hf-peft-fine-tuning/runs/yko3ozlt</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeLlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.train()\n",
    "\n",
    "#stop reporting to wandb\n",
    "wandb.finish()\n",
    "# adapter = \"./results/checkpoint-615/\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-17T16:01:02.283324Z"
    }
   },
   "id": "eebf4e57ecc2b99e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
