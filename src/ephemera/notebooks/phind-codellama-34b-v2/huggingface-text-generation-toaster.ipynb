{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc7a09d-34cb-4e43-9428-bf01759f3467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (23.1)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Collecting ninja\n",
      "  Obtaining dependency information for ninja from https://files.pythonhosted.org/packages/6d/92/8d7aebd4430ab5ff65df2bfee6d5745f95c004284db2d8ca76dcbfd9de47/ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "Installing collected packages: ninja\n",
      "Successfully installed ninja-1.11.1.1\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install packaging\n",
    "! pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5baee7-ce3b-4f46-a2e3-e82cdf37d201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: ninja: not found\n"
     ]
    }
   ],
   "source": [
    "! ninja --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa45e00-ba9c-4f9f-b11d-963d4c08b4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: nvcc: not found\n"
     ]
    }
   ],
   "source": [
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b835c380-40fa-475b-8ffe-34cb27318dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.3.3.tar.gz (2.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m24.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from flash-attn) (2.0.1)\n",
      "Collecting einops (from flash-attn)\n",
      "  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from flash-attn) (23.1)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/site-packages (from flash-attn) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/site-packages (from torch->flash-attn) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (65.5.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (0.41.1)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/site-packages (from triton==2.0.0->torch->flash-attn) (3.27.5)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/site-packages (from triton==2.0.0->torch->flash-attn) (17.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.6/44.6 kB\u001B[0m \u001B[31m22.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hBuilding wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for flash-attn: filename=flash_attn-2.3.3-cp310-cp310-linux_x86_64.whl size=30036691 sha256=0217a66b286e84e29e041a6161e84329253126eeb338bcfc3ff245dff3fa7ab5\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/e6/fa/941802ec61d1afd320d27160ab1db98e6dba65381f84b76d4a\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: einops, flash-attn\n",
      "Successfully installed einops-0.7.0 flash-attn-2.3.3\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816200d7-da55-447d-b4f5-ee020281436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03b86cf-172c-4157-abc6-6847119a8f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T18:26:56.176198Z",
     "start_time": "2023-11-13T18:26:54.187704Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd19d804-a7ab-43f7-a904-8fc75b77b103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T18:26:58.072728Z",
     "start_time": "2023-11-13T18:26:58.054073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'/'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca770e1d-ea83-486c-b265-80771a262d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c342e64d38344308b4cd7edf97b561b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"Phind/Phind-CodeLlama-34B-v2\"\n",
    "\n",
    "# bnb_8bit_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,\n",
    "#     llm_int8_threshold = 6.0,\n",
    "#     bnb_8bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "bnb_4bit_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    # use_flash_attention_2=True\n",
    ")\n",
    "\n",
    "model_4bit = AutoModelForCausalLM.from_pretrained( \".\", quantization_config=bnb_4bit_config, device_map=\"auto\" )\n",
    "# model_8bit = AutoModelForCausalLM.from_pretrained( \".\", quantization_config=bnb_8bit_config, device_map=\"auto\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad6542d9-8b21-4667-b2ba-7adff56af911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained( model_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e672f1a5-3e4b-4b92-8510-86faddafa5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 11 02:51:30 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:01:00.0 Off |                  Off |\n",
      "|  0%   40C    P2              70W / 450W |   8342MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        On  | 00000000:02:00.0 Off |                  Off |\n",
      "|  0%   49C    P2              71W / 450W |  10462MiB / 24564MiB |      5%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0103b88b-55c3-4389-9d23-7a1a2546eb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x7fa0041be770>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator_4bit = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_4bit, \n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "text_generator_4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69ebd784-4828-4ce7-96c0-d3e3f9e5d207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.embed_tokens': 0,\n",
       " 'model.layers.0': 0,\n",
       " 'model.layers.1': 0,\n",
       " 'model.layers.2': 0,\n",
       " 'model.layers.3': 0,\n",
       " 'model.layers.4': 0,\n",
       " 'model.layers.5': 0,\n",
       " 'model.layers.6': 0,\n",
       " 'model.layers.7': 0,\n",
       " 'model.layers.8': 0,\n",
       " 'model.layers.9': 0,\n",
       " 'model.layers.10': 0,\n",
       " 'model.layers.11': 0,\n",
       " 'model.layers.12': 0,\n",
       " 'model.layers.13': 0,\n",
       " 'model.layers.14': 0,\n",
       " 'model.layers.15': 0,\n",
       " 'model.layers.16': 0,\n",
       " 'model.layers.17': 0,\n",
       " 'model.layers.18': 0,\n",
       " 'model.layers.19': 0,\n",
       " 'model.layers.20': 0,\n",
       " 'model.layers.21': 1,\n",
       " 'model.layers.22': 1,\n",
       " 'model.layers.23': 1,\n",
       " 'model.layers.24': 1,\n",
       " 'model.layers.25': 1,\n",
       " 'model.layers.26': 1,\n",
       " 'model.layers.27': 1,\n",
       " 'model.layers.28': 1,\n",
       " 'model.layers.29': 1,\n",
       " 'model.layers.30': 1,\n",
       " 'model.layers.31': 1,\n",
       " 'model.layers.32': 1,\n",
       " 'model.layers.33': 1,\n",
       " 'model.layers.34': 1,\n",
       " 'model.layers.35': 1,\n",
       " 'model.layers.36': 1,\n",
       " 'model.layers.37': 1,\n",
       " 'model.layers.38': 1,\n",
       " 'model.layers.39': 1,\n",
       " 'model.layers.40': 1,\n",
       " 'model.layers.41': 1,\n",
       " 'model.layers.42': 1,\n",
       " 'model.layers.43': 1,\n",
       " 'model.layers.44': 1,\n",
       " 'model.layers.45': 1,\n",
       " 'model.layers.46': 1,\n",
       " 'model.layers.47': 1,\n",
       " 'model.norm': 1,\n",
       " 'lm_head': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4bit.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e3b2a07-08ec-4973-b809-88f3453f042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_haversine(lat1, lon1, lat2, lon2):\n",
      "    import math\n",
      "\n",
      "    # convert decimal degrees to radians\n",
      "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
      "\n",
      "    # haversine formula\n",
      "    dlat = lat2 - lat1\n",
      "    dlon = lon2 - lon1\n",
      "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
      "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
      "\n",
      "    # 6371 km is the earth's radius\n",
      "    km = 6371 * c\n",
      "    return km\n",
      "\n",
      "def get_distance_matrix(locations):\n",
      "    import numpy as np\n",
      "\n",
      "    n = len(locations)\n",
      "    matrix = np.zeros((n, n))\n",
      "\n",
      "    for i in range(n):\n",
      "        for j in range(i+1, n):\n",
      "            lat1, lon1 = locations[i]\n",
      "            lat2, lon2 = locations[j]\n",
      "            d = get_haversine(lat1, lon1, lat2, lon2)\n",
      "            matrix[i, j] = d\n",
      "            matrix[j, i] = d\n",
      "\n",
      "    return matrix\n",
      "\n",
      "locations = [(40.7128, -74.0060), (34.0522, -118.2437), (51.5074, -0.1278)]\n",
      "matrix = get_distance_matrix(locations)\n",
      "print(matrix)\n",
      "CPU times: user 28.2 s, sys: 87.7 ms, total: 28.3 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = \"def get_haversine(\"\n",
    "device = \"cuda:0\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model_4bit.generate(**inputs, max_new_tokens=400)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00221b37-3843-447b-a8f1-4cfa649bf5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Write a python function to calculate the haversine distance between two points.\n",
      "    Start your output with ```python. \n",
      "    \n",
      "    The haversine distance is a measure of the distance between two points on a sphere. The haversine formula can be used to calculate this distance.\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def haversine_distance(lat1, lon1, lat2, lon2):\n",
      "    R = 6371  # Earth's radius in km\n",
      "\n",
      "    dLat = math.radians(lat2 - lat1)\n",
      "    dLon = math.radians(lon2 - lon1)\n",
      "\n",
      "    a = math.sin(dLat / 2) * math.sin(dLat / 2) + \\\n",
      "        math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * \\\n",
      "        math.sin(dLon / 2) * math.sin(dLon / 2)\n",
      "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
      "\n",
      "    distance = R * c  # Distance in km\n",
      "    return distance\n",
      "\n",
      "# Example usage:\n",
      "lat1, lon1 = 40.7128, -74.0060  # New York\n",
      "lat2, lon2 = 51.5074, -0.1278  # London\n",
      "\n",
      "print(haversine_distance(lat1, lon1, lat2, lon2))\n",
      "```\n",
      "\n",
      "This function takes in the latitude and longitude of two points and returns the haversine distance between them in kilometers. It uses the standard radius of the Earth (6371 km). Note that you need to convert the latitude and longitude\n",
      "CPU times: user 26.6 s, sys: 67.5 ms, total: 26.7 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequences = text_generator_4bit(\n",
    "    \"\"\"Write a python function to calculate the haversine distance between two points.\n",
    "    Start your output with ```python. \n",
    "    \"\"\",\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    "    top_p=0.9,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=400,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d111c15-d81e-43dc-9ec5-2279dbc608b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text( prompt ):\n",
    "    \n",
    "    sequences = text_generator_4bit(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p=0.9,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=400,\n",
    "    )\n",
    "\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85a23b15-23e3-42ac-8530-75be66aa8957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': \"Write a python function to calculate the haversine distance between two points. Start your output with ```python.The Haversine formula calculates the great-circle distance between two points on a sphere, which is useful for calculating distances on Earth. The formula takes into account the Earth's curvature and is more accurate than the Euclidean distance.\\n\\nHere's a Python function to calculate the Haversine distance between two points:\\n\\n```python\\nimport math\\n\\ndef haversine_distance(lat1, lon1, lat2, lon2):\\n    # Convert latitude and longitude to radians\\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\\n\\n    # Haversine formula\\n    dlat = lat2 - lat1\\n    dlon = lon2 - lon1\\n    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\\n\\n    # Earth's radius in meters\\n    r = 6371000\\n\\n    # Calculate distance\\n    distance = r * c\\n\\n    return distance\\n\\n# Example usage:\\nlat1, lon1 = 40.7128, -74.0060  # New York\\nlat2, lon2 = 51.5074, -0.1278  # London\\nprint(haversine_distance(lat1, lon1, lat2, lon2))\\n```\\n\\nIn this code, the `haversine_distance` function takes two\"}\n",
      "Write a python function to calculate the haversine distance between two points. Start your output with ```python.The Haversine formula calculates the great-circle distance between two points on a sphere, which is useful for calculating distances on Earth. The formula takes into account the Earth's curvature and is more accurate than the Euclidean distance.\n",
      "\n",
      "Here's a Python function to calculate the Haversine distance between two points:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def haversine_distance(lat1, lon1, lat2, lon2):\n",
      "    # Convert latitude and longitude to radians\n",
      "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
      "\n",
      "    # Haversine formula\n",
      "    dlat = lat2 - lat1\n",
      "    dlon = lon2 - lon1\n",
      "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
      "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
      "\n",
      "    # Earth's radius in meters\n",
      "    r = 6371000\n",
      "\n",
      "    # Calculate distance\n",
      "    distance = r * c\n",
      "\n",
      "    return distance\n",
      "\n",
      "# Example usage:\n",
      "lat1, lon1 = 40.7128, -74.0060  # New York\n",
      "lat2, lon2 = 51.5074, -0.1278  # London\n",
      "print(haversine_distance(lat1, lon1, lat2, lon2))\n",
      "```\n",
      "\n",
      "In this code, the `haversine_distance` function takes two\n",
      "CPU times: user 26.9 s, sys: 137 ms, total: 27.1 s\n",
      "Wall time: 27.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sequences = gen_text( \"Write a python function to calculate the haversine distance between two points. Start your output with ```python.\" )\n",
    "\n",
    "for seq in sequences:\n",
    "    print( seq )\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63337cba-3b5e-48ac-946f-6f8b043a20b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
