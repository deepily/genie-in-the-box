{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\r\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.10.3)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\r\n",
      "Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m26.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: tiktoken\r\n",
      "Successfully installed tiktoken-0.5.2\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3 -m pip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# ! pip install xmlschema\n",
    "# ! pip install scikit-learn\n",
    "# ! pip install openai\n",
    "! pip install tiktoken\n",
    "# ! pip install trl\n",
    "# ! pip install lzma"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T16:40:22.156430Z",
     "start_time": "2024-01-02T16:40:19.940662Z"
    }
   },
   "id": "913059d75bfb9b60"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\r\n"
     ]
    }
   ],
   "source": [
    "! python3 --version"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:49:31.608744Z",
     "start_time": "2024-01-02T17:49:31.500030Z"
    }
   },
   "id": "40d7f5a05bdbaeef"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "\n",
    "import json\n",
    "import wandb\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:14:50.099326Z",
     "start_time": "2024-01-02T17:14:47.000713Z"
    }
   },
   "id": "c213bdd2418b70f4"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 404K\r\n",
      "drwxr--r-- 32 1001 1001 4.0K Jan  2 15:00 .\r\n",
      "drwxr-xr-x  1 root root 4.0K Jan  2 16:36 ..\r\n",
      "drwxr--r--  3 1001 1001 4.0K Aug 22 13:57 .idea\r\n",
      "drwxr--r-- 16 1001 1001 4.0K Aug 15 19:52 Auto-GPT\r\n",
      "drwxrwxr-x  6 1001 1001 4.0K Nov 19 02:04 CodeLlama-13b-Instruct-hf\r\n",
      "drwxrwxr-x  7 1001 1001 4.0K Dec 19 14:10 CodeLlama-7b-Instruct-hf\r\n",
      "-rwxr--r--  1 1001 1001 3.3K Feb 28  2023 Dockerfile\r\n",
      "drwxrwxr-x 15 1001 1001 4.0K Nov  8 18:06 OpenLLM\r\n",
      "drwxrwxr-x  6 1001 1001 4.0K Jan  2 15:54 Phind-CodeLlama-34B-v2\r\n",
      "drwxrwxr-x 13 1001 1001 4.0K Dec 13 00:08 TTS\r\n",
      "drwxr--r--  6 1001 1001 4.0K Feb 28  2023 ampe\r\n",
      "drwxr--r--  5 1001 1001 4.0K Jul  5 15:19 cache\r\n",
      "-rwxr--r--  1 1001 1001 254K Aug  1 01:17 chat_history.txt\r\n",
      "drwxr--r--  5 1001 1001 4.0K Apr 28  2023 coursework\r\n",
      "drwxrwxr-x  8 1001 1001 4.0K Nov  3 15:33 cursor-flask-chatbot\r\n",
      "drwxr--r--  6 1001 1001 4.0K Sep  3 23:49 cursor-flask-js-websocket\r\n",
      "drwxr-xr-x  3 1001 1001 4.0K Oct 16 18:49 cursor-gib\r\n",
      "drwxr--r--  3 1001 1001 4.0K Sep  6 19:51 cursor-langchain-experiments\r\n",
      "drwxrwxr-x  2 1001 1001 4.0K Nov 10 18:45 falcon-7b-instruct\r\n",
      "drwxr-xr-x  2 root root 4.0K Nov 10 18:46 falcon-7b-instruct-hf\r\n",
      "drwxr--r-- 12 1001 1001 4.0K Jul 31 22:55 foo\r\n",
      "drwxr--r-- 10 1001 1001 4.0K Dec 12 14:59 genie-in-the-box\r\n",
      "drwxr--r--  9 1001 1001 4.0K Dec 25 23:40 genie-plugin-firefox\r\n",
      "drwxr--r--  9 1001 1001 4.0K Aug 21 17:49 genie-plugin-intellij\r\n",
      "drwxr--r--  2 1001 1001 4.0K Mar 24  2023 io\r\n",
      "drwxr-xr-x  2 1001 1001 4.0K Nov 16 23:00 kaitshup.substack.com\r\n",
      "drwxr--r--  9 1001 1001 4.0K Aug 22 14:30 langchain\r\n",
      "drwxr--r--  5 1001 1001 4.0K Dec 13 19:15 mimape\r\n",
      "-rw-------  1 root root 4.3K Dec 27 02:27 nohup.out\r\n",
      "drwxr--r--  5 1001 1001 4.0K Dec 13 16:25 pyxtermjs\r\n",
      "drwxr--r--  6 1001 1001 4.0K Mar 28  2023 scripts\r\n",
      "drwxrwxr-x 15 1001 1001 4.0K Jan  2 15:24 text-generation-inference\r\n",
      "drwxrwxr-x 16 1001 1001 4.0K Dec 26 19:52 transformers\r\n",
      "-rw-r--r--  1 root root    1 Nov 10 19:04 version.txt\r\n",
      "drwxr--r--  6 1001 1001 4.0K Sep  8 14:36 wandb\r\n",
      "drwxr--r-- 64 1001 1001 4.0K Apr 26  2023 webextensions-examples\r\n"
     ]
    }
   ],
   "source": [
    "# Print current working directory\n",
    "# !ls -alh /var/model/Phind-CodeLlama-34B-v2\n",
    "# Change to /var/model/Phind-CodeLlama-34B-v2\n",
    "# os.chdir( \"/var/model/Phind-CodeLlama-34B-v2\" )\n",
    "# Print current working directory\n",
    "# os.getcwd()\n",
    "! ls -alh /var/model/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:12:49.287170Z",
     "start_time": "2024-01-02T17:12:49.174725Z"
    }
   },
   "id": "644a6196802f8630"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:21:24.404399Z",
     "start_time": "2023-12-21T16:21:02.402301Z"
    }
   },
   "id": "d49e208217c2ea36"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=Phind-CodeLlama-34B-v2-peft-fine-tuning\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=Phind-CodeLlama-34B-v2-peft-fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:21:28.462340Z",
     "start_time": "2023-12-21T16:21:28.451245Z"
    }
   },
   "id": "d03f99f12eb04c9e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# dataset_name = \"iamtarun/python_code_instructions_18k_alpaca\"\n",
    "# split = \"train[:10%]\"\n",
    "# # finetunes_model_name = \"output/codellama-7b-finetuned-int4-python-18k-alpaca\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:21:42.157884Z",
     "start_time": "2023-12-21T16:21:42.101662Z"
    }
   },
   "id": "90fba6c4ff2875f3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# \n",
    "# dataset = load_dataset( dataset_name, split=split )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:21:47.639139Z",
     "start_time": "2023-12-21T16:21:47.627074Z"
    }
   },
   "id": "ccedc3adeb45dcb8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# dataset[ 0 ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:21:52.600528Z",
     "start_time": "2023-12-21T16:21:52.527632Z"
    }
   },
   "id": "d4f6af0454318fbb"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from xmlschema import XMLSchema\n",
    "\n",
    "os.chdir( \"/var/model/genie-in-the-box/src\" )\n",
    "import lib.utils.util     as du\n",
    "import lib.utils.util_xml as dux\n",
    "import lib.utils.util_pytorch as dupt\n",
    "\n",
    "from ephemera.prompts.xml_fine_tuning_prompt_generator import XmlFineTuningPromptGenerator\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:31:55.615703Z",
     "start_time": "2024-01-02T17:31:55.291808Z"
    }
   },
   "id": "4e1faf28cf522ca7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get training dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fcd418053c3052b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "path = \"/var/model/genie-in-the-box/src/ephemera/prompts/data/voice-commands-xml-train.jsonl\"\n",
    "deepily_dataset_train = du.get_file_as_list( path )\n",
    "deepily_dataset_train = [ json.loads( line ) for line in deepily_dataset_train ]\n",
    "# deepily_dataset_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:22:54.063840Z",
     "start_time": "2023-12-21T16:22:54.048669Z"
    }
   },
   "id": "ae76c88a9a5e791d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "path = \"/var/model/genie-in-the-box/src/ephemera/prompts/data/voice-commands-xml-test.jsonl\"\n",
    "deepily_dataset_test = du.get_file_as_list( path )\n",
    "deepily_dataset_test = [ json.loads( line ) for line in deepily_dataset_test ]\n",
    "# deepily_dataset_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:22:59.227078Z",
     "start_time": "2023-12-21T16:22:59.219934Z"
    }
   },
   "id": "f1c868ec60880dcc"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( deepily_dataset_test )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:23:16.200441Z",
     "start_time": "2023-12-21T16:23:16.149418Z"
    }
   },
   "id": "628d1fc7f1058b94"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Use the Task below and the Input given to write the Response, which is a programmatic instruction that can solve the following Task:\n",
    "def prompt_instruction_format( sample ):\n",
    "    \n",
    "  return f\"\"\"### Instruction:\n",
    "    Use the Task below and the Input given to write a Response that can solve the following Task:\n",
    "\n",
    "    ### Task:\n",
    "    {sample['instruction']}\n",
    "\n",
    "    ### Input:\n",
    "    {sample['input']}\n",
    "\n",
    "    ### Response:\n",
    "    {sample['output']}\n",
    "    \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T16:46:16.646706Z",
     "start_time": "2024-01-02T16:46:16.633420Z"
    }
   },
   "id": "58e3fd8b1b81ce1d"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "    Use the Task below and the Input given to write a Response that can solve the following Task:\n",
      "\n",
      "    ### Task:\n",
      "    Your job is to discern the intent of a human voice command transcription and translate it into a standardized command that a browser on your computer would understand.\n",
      "\n",
      "        You will be given a human voice command and a list of possible standardized commands. You must choose the correct standardized command from the following list: `'search new tab', 'search current tab', 'search google new tab', 'search google current tab', 'search google scholar new tab', 'search google scholar current tab' and 'none'`.\n",
      "\n",
      "        Requirement: You MUST NOT use python code to answer this question.\n",
      "        Requirement: You MUST use your linguistic knowledge and intuition to answer this question.\n",
      "        Hint: Anything that isn't a part of the command itself should be treated as arguments related to the command.\n",
      "\n",
      "    ### Input:\n",
      "    \n",
      "        Below is the raw human voice command transcription formatted using simple XML:\n",
      "        \n",
      "        <human>\n",
      "            <voice-command>Start a Google search on How do you address resource-related warnings in Python, especially regarding resource usage? in a new tab</voice-command>\n",
      "        </human>\n",
      "        \n",
      "        The standardized command that you translate MUST be returned wrapped in simple, well-formed XML:\n",
      "        \n",
      "        <response>\n",
      "            <browser-command></browser-command>\n",
      "            <args></args>\n",
      "        </response>\n",
      "\n",
      "        Requirement: The first word of your response MUST be `<response>`\n",
      "\n",
      "    ### Response:\n",
      "    \n",
      "        <response>\n",
      "            <browser-command>search google new tab</browser-command>\n",
      "            <args>How do you address resource-related warnings in Python, especially regarding resource usage?</args>\n",
      "        </response>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for line in prompt_instruction_format( deepily_dataset_test[ 0 ] ).split( \"\\n\" ): print( line )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:23:40.877584Z",
     "start_time": "2023-12-21T16:23:40.830370Z"
    }
   },
   "id": "e66898ac4c85e976"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def generate_text( foo_tokenizer, model, question, max_new_tokens=256, debug=False ):\n",
    "    \n",
    "    instruction = f\"\"\"### Instruction:\n",
    "    Use the Task below and the Input given to write a Response that can solve the following Task:\n",
    "\n",
    "    ### Task:\n",
    "    Your job is to discern the intent of a human voice command transcription and translate it into a standardized command that a browser on your computer would understand.\n",
    "\n",
    "    You will be given a human voice command and a list of possible standardized commands. You must choose the correct standardized command from the following list: `'search new tab', 'search current tab', 'search google new tab', 'search google current tab', 'search google scholar new tab', 'search google scholar current tab' and 'none'`.\n",
    "\n",
    "    Requirement: You MUST NOT use python code to answer this question.\n",
    "    Requirement: You MUST use your linguistic knowledge and intuition to answer this question.\n",
    "    Hint: Anything that isn't a part of the command itself should be treated as arguments related to the command.\n",
    "\n",
    "    ### Input:\n",
    "    \n",
    "    Below is the raw human voice command transcription formatted using simple XML:\n",
    "    \n",
    "    <human>\n",
    "        <voice-command>{question}</voice-command>\n",
    "    </human>\n",
    "    \n",
    "    The standardized command that you translate MUST be returned wrapped in simple, well-formed XML:\n",
    "    \n",
    "    <response>\n",
    "        <browser-command></browser-command>\n",
    "        <args></args>\n",
    "    </response>\n",
    "\n",
    "    Requirement: The first word of your response MUST be `<response>`\n",
    "\n",
    "    ### Response:\"\"\"\n",
    "    \n",
    "    \n",
    "    device = \"cuda:0\"\n",
    "    inputs = foo_tokenizer( instruction, return_tensors=\"pt\" ).to( device )\n",
    "    \n",
    "    stop_token_id = foo_tokenizer.encode( \"</response>\" )[ 0 ]\n",
    "    \n",
    "    generation_output = model.generate(\n",
    "        input_ids=inputs[ \"input_ids\" ],\n",
    "        attention_mask=inputs[ \"attention_mask\" ],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        eos_token_id=stop_token_id,\n",
    "        pad_token_id=stop_token_id\n",
    "    )\n",
    "        \n",
    "    if debug: \n",
    "        print( \"generation_output[ 0 ]:\", generation_output[ 0 ], end=\"\\n\\n\" )\n",
    "        print( \"generation_output[ 0 ].shape:\", generation_output[ 0 ].shape, end=\"\\n\\n\" )\n",
    "    \n",
    "    # Skip decoding the prompt part of the output   \n",
    "    input_length = inputs[ \"input_ids\" ].size( 1 )\n",
    "    raw_output = foo_tokenizer.decode( generation_output[ 0 ][ input_length: ] )\n",
    "    \n",
    "    if debug: \n",
    "        print( \"raw_output:\", raw_output, end=\"\\n\\n\" )\n",
    "        print(  \"len( raw_output ):\", len( raw_output ), end=\"\\n\\n\")\n",
    "    \n",
    "    # response   = raw_output.split( \"### Response:\" )[ 1 ]\n",
    "    \n",
    "    response = raw_output.replace( \"</s><s>\", \"\" ).strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "question = \"Ask Google scholar about QLORA and PEFT fine-tuning for XML output, show results in Another tab\"\n",
    "\n",
    "# for line in generate_text( tokenizer, base_model, question ).split( \"\\n\" ): print( line )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:14:58.919188Z",
     "start_time": "2024-01-02T17:14:58.910603Z"
    }
   },
   "id": "deee8f0e5ce7efd5"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir( \"/var/model/Phind-CodeLlama-34B-v2\" )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:36:59.066449Z",
     "start_time": "2024-01-02T17:36:59.056060Z"
    }
   },
   "id": "7ba53819b2920023"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitsAndBytesConfig {\n",
      "  \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "  \"llm_int8_has_fp16_weight\": false,\n",
      "  \"llm_int8_skip_modules\": null,\n",
      "  \"llm_int8_threshold\": 6.0,\n",
      "  \"load_in_4bit\": true,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"quant_method\": \"bitsandbytes\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d72691a71f054fe29e8d80912b91b2ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "print( bnb_config )\n",
    "tokenizer              = AutoTokenizer.from_pretrained( \".\" )\n",
    "tokenizer.pad_token    = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# ¡OJO! Why are All the examples I'm finding online turning off the cache here? It makes a huge performance difference: 21 vs 14 tokens per second!\n",
    "# Now I remember: cashing is suspended while training, should only be used for inference\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \".\", quantization_config=bnb_config, device_map=\"auto\", low_cpu_mem_usage=True, use_cache=True, use_flash_attention_2=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:31:41.822267Z",
     "start_time": "2023-12-21T16:30:58.989289Z"
    }
   },
   "id": "b6e2cfb0fbdd120"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# for line in generate_text( tokenizer, base_model, product ).split( \"\\n\" ): print( line )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T00:39:46.545676Z",
     "start_time": "2023-12-21T00:39:46.499368Z"
    }
   },
   "id": "dcaaf8f2e4c38178"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# def ppl_model( model, tokenizer, dataset ):\n",
    "#     nlls = [ ]\n",
    "#     max_length = 4096 #2048\n",
    "#     stride = 512\n",
    "#     for s in tqdm( range( len( dataset[ 'prompt' ] ) ) ):\n",
    "#         encodings = tokenizer( dataset[ 'prompt' ][ s ], return_tensors=\"pt\", truncation=True, max_length=max_length )\n",
    "#         seq_len = encodings.input_ids.size( 1 )\n",
    "#         prev_end_loc = 0\n",
    "#         for begin_loc in range( 0, seq_len, stride ):\n",
    "#             end_loc = min( begin_loc + max_length, seq_len )\n",
    "#             trg_len = end_loc - prev_end_loc\n",
    "#             input_ids = encodings.input_ids[ :, begin_loc:end_loc ].to( \"cuda\" )\n",
    "#             target_ids = input_ids.clone()\n",
    "#             target_ids[ :, :-trg_len ] = -100\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = model( input_ids, labels=target_ids )\n",
    "#                 neg_log_likelihood = outputs.loss\n",
    "#             nlls.append( neg_log_likelihood )\n",
    "#             prev_end_loc = end_loc\n",
    "#             if end_loc == seq_len:\n",
    "#                 break\n",
    "#     ppl = torch.exp( torch.stack( nlls ).mean() )\n",
    "#     return ppl.item()\n",
    "# \n",
    "# # ppl for \"iamtarun/python_code_instructions_18k_alpaca\": 4.75\n",
    "# # ppl for \"deepily-xml-prompts\": "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:34:05.826707Z",
     "start_time": "2023-12-21T16:34:05.779641Z"
    }
   },
   "id": "fa2e407f1f9b833e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# ppl_model( base_model, tokenizer, dataset )\n",
    "\n",
    "# This error happens whenever the training object is instantiated twice in a session. There's got to be a better way to know whatever actions the\n",
    "# training object has taken without having to restart The notebook server\n",
    "# RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:35:54.824766Z",
     "start_time": "2023-12-21T16:35:54.773258Z"
    }
   },
   "id": "b32d8cac687b71db"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "1496"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "# del base_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:36:07.873256Z",
     "start_time": "2023-12-21T16:36:07.866278Z"
    }
   },
   "id": "a6e40707f4760dd2"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'model.embed_tokens': 0,\n 'model.layers.0': 0,\n 'model.layers.1': 0,\n 'model.layers.2': 0,\n 'model.layers.3': 0,\n 'model.layers.4': 0,\n 'model.layers.5': 0,\n 'model.layers.6': 0,\n 'model.layers.7': 0,\n 'model.layers.8': 0,\n 'model.layers.9': 0,\n 'model.layers.10': 0,\n 'model.layers.11': 0,\n 'model.layers.12': 0,\n 'model.layers.13': 0,\n 'model.layers.14': 0,\n 'model.layers.15': 0,\n 'model.layers.16': 0,\n 'model.layers.17': 0,\n 'model.layers.18': 0,\n 'model.layers.19': 0,\n 'model.layers.20': 0,\n 'model.layers.21': 1,\n 'model.layers.22': 1,\n 'model.layers.23': 1,\n 'model.layers.24': 1,\n 'model.layers.25': 1,\n 'model.layers.26': 1,\n 'model.layers.27': 1,\n 'model.layers.28': 1,\n 'model.layers.29': 1,\n 'model.layers.30': 1,\n 'model.layers.31': 1,\n 'model.layers.32': 1,\n 'model.layers.33': 1,\n 'model.layers.34': 1,\n 'model.layers.35': 1,\n 'model.layers.36': 1,\n 'model.layers.37': 1,\n 'model.layers.38': 1,\n 'model.layers.39': 1,\n 'model.layers.40': 1,\n 'model.layers.41': 1,\n 'model.layers.42': 1,\n 'model.layers.43': 1,\n 'model.layers.44': 1,\n 'model.layers.45': 1,\n 'model.layers.46': 1,\n 'model.layers.47': 1,\n 'model.norm': 1,\n 'lm_head': 1}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.hf_device_map"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:36:18.242034Z",
     "start_time": "2023-12-21T16:36:18.230456Z"
    }
   },
   "id": "fbb05c78a2bde3e4"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter model.embed_tokens.weight is on device cuda:0\n",
      "Parameter model.layers.0.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.0.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.0.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.0.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.0.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.0.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.0.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.0.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.0.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.1.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.1.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.1.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.1.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.1.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.1.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.1.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.1.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.1.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.2.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.2.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.2.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.2.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.2.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.2.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.2.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.2.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.2.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.3.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.3.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.3.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.3.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.3.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.3.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.3.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.3.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.3.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.4.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.4.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.4.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.4.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.4.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.4.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.4.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.4.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.4.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.5.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.5.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.5.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.5.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.5.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.5.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.5.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.5.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.5.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.6.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.6.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.6.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.6.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.6.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.6.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.6.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.6.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.6.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.7.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.7.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.7.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.7.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.7.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.7.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.7.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.7.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.7.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.8.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.8.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.8.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.8.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.8.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.8.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.8.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.8.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.8.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.9.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.9.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.9.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.9.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.9.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.9.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.9.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.9.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.9.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.10.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.10.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.10.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.10.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.10.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.10.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.10.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.10.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.10.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.11.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.11.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.11.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.11.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.11.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.11.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.11.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.11.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.11.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.12.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.12.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.12.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.12.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.12.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.12.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.12.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.12.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.12.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.13.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.13.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.13.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.13.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.13.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.13.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.13.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.13.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.13.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.14.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.14.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.14.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.14.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.14.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.14.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.14.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.14.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.14.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.15.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.15.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.15.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.15.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.15.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.15.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.15.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.15.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.15.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.16.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.16.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.16.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.16.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.16.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.16.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.16.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.16.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.16.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.17.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.17.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.17.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.17.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.17.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.17.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.17.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.17.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.17.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.18.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.18.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.18.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.18.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.18.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.18.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.18.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.18.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.18.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.19.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.19.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.19.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.19.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.19.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.19.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.19.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.19.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.19.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.20.self_attn.q_proj.weight is on device cuda:0\n",
      "Parameter model.layers.20.self_attn.k_proj.weight is on device cuda:0\n",
      "Parameter model.layers.20.self_attn.v_proj.weight is on device cuda:0\n",
      "Parameter model.layers.20.self_attn.o_proj.weight is on device cuda:0\n",
      "Parameter model.layers.20.mlp.gate_proj.weight is on device cuda:0\n",
      "Parameter model.layers.20.mlp.up_proj.weight is on device cuda:0\n",
      "Parameter model.layers.20.mlp.down_proj.weight is on device cuda:0\n",
      "Parameter model.layers.20.input_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.20.post_attention_layernorm.weight is on device cuda:0\n",
      "Parameter model.layers.21.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.21.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.21.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.21.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.21.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.21.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.21.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.21.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.21.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.22.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.22.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.22.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.22.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.22.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.22.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.22.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.22.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.22.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.23.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.23.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.23.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.23.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.23.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.23.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.23.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.23.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.23.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.24.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.24.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.24.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.24.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.24.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.24.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.24.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.24.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.24.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.25.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.25.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.25.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.25.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.25.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.25.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.25.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.25.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.25.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.26.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.26.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.26.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.26.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.26.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.26.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.26.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.26.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.26.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.27.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.27.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.27.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.27.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.27.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.27.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.27.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.27.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.27.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.28.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.28.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.28.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.28.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.28.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.28.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.28.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.28.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.28.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.29.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.29.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.29.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.29.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.29.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.29.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.29.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.29.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.29.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.30.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.30.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.30.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.30.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.30.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.30.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.30.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.30.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.30.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.31.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.31.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.31.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.31.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.31.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.31.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.31.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.31.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.31.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.32.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.32.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.32.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.32.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.32.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.32.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.32.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.32.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.32.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.33.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.33.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.33.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.33.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.33.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.33.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.33.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.33.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.33.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.34.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.34.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.34.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.34.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.34.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.34.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.34.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.34.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.34.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.35.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.35.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.35.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.35.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.35.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.35.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.35.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.35.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.35.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.36.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.36.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.36.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.36.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.36.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.36.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.36.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.36.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.36.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.37.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.37.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.37.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.37.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.37.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.37.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.37.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.37.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.37.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.38.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.38.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.38.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.38.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.38.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.38.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.38.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.38.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.38.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.39.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.39.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.39.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.39.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.39.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.39.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.39.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.39.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.39.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.40.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.40.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.40.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.40.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.40.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.40.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.40.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.40.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.40.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.41.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.41.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.41.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.41.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.41.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.41.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.41.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.41.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.41.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.42.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.42.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.42.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.42.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.42.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.42.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.42.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.42.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.42.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.43.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.43.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.43.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.43.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.43.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.43.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.43.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.43.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.43.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.44.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.44.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.44.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.44.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.44.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.44.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.44.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.44.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.44.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.45.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.45.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.45.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.45.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.45.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.45.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.45.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.45.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.45.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.46.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.46.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.46.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.46.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.46.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.46.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.46.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.46.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.46.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.47.self_attn.q_proj.weight is on device cuda:1\n",
      "Parameter model.layers.47.self_attn.k_proj.weight is on device cuda:1\n",
      "Parameter model.layers.47.self_attn.v_proj.weight is on device cuda:1\n",
      "Parameter model.layers.47.self_attn.o_proj.weight is on device cuda:1\n",
      "Parameter model.layers.47.mlp.gate_proj.weight is on device cuda:1\n",
      "Parameter model.layers.47.mlp.up_proj.weight is on device cuda:1\n",
      "Parameter model.layers.47.mlp.down_proj.weight is on device cuda:1\n",
      "Parameter model.layers.47.input_layernorm.weight is on device cuda:1\n",
      "Parameter model.layers.47.post_attention_layernorm.weight is on device cuda:1\n",
      "Parameter model.norm.weight is on device cuda:1\n",
      "Parameter lm_head.weight is on device cuda:1\n"
     ]
    }
   ],
   "source": [
    "for name, param in base_model.named_parameters():\n",
    "    print(f\"Parameter {name} is on device {param.device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:36:20.261205Z",
     "start_time": "2023-12-21T16:36:20.243138Z"
    }
   },
   "id": "77a87b656bdf19ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up training arguments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "528b5d0d39d9b5df"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_config, PeftModel, PeftConfig, get_peft_model, AutoPeftModelForCausalLM\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=32, \n",
    "    # When target_modules was disabled, it was causing detention layers to be assigned to the CPU, throwing this runtime error:\n",
    "    # RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! \n",
    "    # (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n",
    "    target_modules=[ \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\" ], \n",
    "    lora_dropout=0.10, \n",
    "    bias=\"none\", \n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T03:12:05.069913Z",
     "start_time": "2023-12-21T03:12:05.058997Z"
    }
   },
   "id": "393f4bbf9c6c3ca4"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "1878"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del trainingArgs\n",
    "del trainer\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T03:07:24.696350Z",
     "start_time": "2023-12-21T03:07:24.531371Z"
    }
   },
   "id": "aaa10811f488bb61"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "trainingArgs = TrainingArguments(\n",
    "    output_dir=\"./training-results\", # Output directory where the model predictions and checkpoints will be stored\n",
    "    num_train_epochs=4, # Number of training epochs\n",
    "    per_device_train_batch_size=1, # Batch size per GPU for training\n",
    "    gradient_accumulation_steps=4,  # Number of update steps to accumulate the gradients for\n",
    "    gradient_checkpointing=True,# Enable gradient checkpointing\n",
    "    optim=\"paged_adamw_32bit\", # Optimizer to use\n",
    "    #save_steps=save_steps,\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    \n",
    "    # Setting this may help with the warning message: The input hidden states seems to be silently casted in float32, \n",
    "    # this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n",
    "    fp16=True,\n",
    "    # Test to confirm that this works!\n",
    "    # BTW: according to PHIND, this may actually improve fine-tuning performance as well: https://www.phind.com/search?cache=ygn9dbyl0ij4kotmgns2nsrw\n",
    "    \n",
    "    bf16=False,\n",
    "    # tf32=True,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    #max_steps=max_steps,\n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    disable_tqdm=True,\n",
    "    report_to=\"wandb\",\n",
    "    seed=42\n",
    ")\n",
    "# Create the trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=deepily_dataset_train,\n",
    "    eval_dataset=deepily_dataset_test,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=4096, #2048,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    formatting_func=prompt_instruction_format,\n",
    "    args=trainingArgs,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T03:12:15.075674Z",
     "start_time": "2023-12-21T03:12:13.657796Z"
    }
   },
   "id": "e0ad2d859cefb9c4"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def print_trainable_parameters( model ):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params:,} || all params: {all_param:,} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:37:06.067814Z",
     "start_time": "2023-12-21T16:37:06.062306Z"
    }
   },
   "id": "8275555ac7a5093d"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 525,082,624 || all params: 17,134,526,464 || trainable%: 3.06\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters( base_model )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:37:07.262528Z",
     "start_time": "2023-12-21T16:37:07.253156Z"
    }
   },
   "id": "e5d11100b64024ed"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter model.embed_tokens.weight is on cuda:0\n",
      "Parameter model.layers.0.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.0.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.0.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.0.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.0.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.0.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.0.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.0.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.0.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.1.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.1.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.1.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.1.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.1.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.1.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.1.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.1.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.1.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.2.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.2.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.2.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.2.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.2.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.2.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.2.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.2.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.2.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.3.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.3.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.3.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.3.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.3.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.3.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.3.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.3.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.3.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.4.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.4.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.4.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.4.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.4.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.4.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.4.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.4.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.4.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.5.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.5.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.5.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.5.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.5.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.5.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.5.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.5.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.5.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.6.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.6.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.6.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.6.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.6.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.6.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.6.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.6.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.6.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.7.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.7.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.7.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.7.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.7.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.7.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.7.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.7.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.7.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.8.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.8.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.8.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.8.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.8.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.8.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.8.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.8.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.8.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.9.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.9.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.9.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.9.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.9.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.9.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.9.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.9.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.9.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.10.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.10.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.10.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.10.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.10.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.10.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.10.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.10.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.10.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.11.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.11.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.11.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.11.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.11.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.11.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.11.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.11.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.11.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.12.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.12.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.12.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.12.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.12.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.12.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.12.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.12.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.12.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.13.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.13.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.13.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.13.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.13.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.13.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.13.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.13.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.13.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.14.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.14.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.14.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.14.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.14.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.14.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.14.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.14.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.14.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.15.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.15.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.15.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.15.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.15.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.15.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.15.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.15.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.15.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.16.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.16.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.16.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.16.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.16.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.16.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.16.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.16.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.16.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.17.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.17.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.17.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.17.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.17.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.17.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.17.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.17.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.17.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.18.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.18.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.18.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.18.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.18.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.18.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.18.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.18.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.18.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.19.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.19.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.19.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.19.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.19.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.19.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.19.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.19.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.19.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.20.self_attn.q_proj.weight is on cuda:0\n",
      "Parameter model.layers.20.self_attn.k_proj.weight is on cuda:0\n",
      "Parameter model.layers.20.self_attn.v_proj.weight is on cuda:0\n",
      "Parameter model.layers.20.self_attn.o_proj.weight is on cuda:0\n",
      "Parameter model.layers.20.mlp.gate_proj.weight is on cuda:0\n",
      "Parameter model.layers.20.mlp.up_proj.weight is on cuda:0\n",
      "Parameter model.layers.20.mlp.down_proj.weight is on cuda:0\n",
      "Parameter model.layers.20.input_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.20.post_attention_layernorm.weight is on cuda:0\n",
      "Parameter model.layers.21.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.21.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.21.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.21.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.21.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.21.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.21.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.21.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.21.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.22.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.22.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.22.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.22.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.22.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.22.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.22.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.22.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.22.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.23.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.23.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.23.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.23.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.23.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.23.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.23.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.23.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.23.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.24.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.24.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.24.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.24.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.24.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.24.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.24.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.24.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.24.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.25.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.25.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.25.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.25.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.25.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.25.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.25.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.25.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.25.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.26.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.26.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.26.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.26.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.26.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.26.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.26.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.26.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.26.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.27.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.27.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.27.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.27.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.27.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.27.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.27.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.27.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.27.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.28.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.28.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.28.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.28.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.28.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.28.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.28.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.28.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.28.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.29.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.29.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.29.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.29.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.29.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.29.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.29.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.29.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.29.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.30.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.30.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.30.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.30.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.30.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.30.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.30.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.30.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.30.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.31.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.31.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.31.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.31.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.31.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.31.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.31.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.31.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.31.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.32.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.32.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.32.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.32.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.32.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.32.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.32.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.32.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.32.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.33.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.33.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.33.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.33.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.33.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.33.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.33.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.33.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.33.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.34.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.34.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.34.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.34.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.34.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.34.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.34.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.34.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.34.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.35.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.35.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.35.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.35.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.35.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.35.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.35.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.35.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.35.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.36.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.36.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.36.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.36.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.36.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.36.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.36.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.36.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.36.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.37.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.37.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.37.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.37.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.37.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.37.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.37.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.37.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.37.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.38.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.38.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.38.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.38.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.38.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.38.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.38.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.38.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.38.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.39.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.39.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.39.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.39.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.39.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.39.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.39.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.39.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.39.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.40.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.40.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.40.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.40.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.40.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.40.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.40.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.40.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.40.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.41.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.41.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.41.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.41.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.41.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.41.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.41.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.41.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.41.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.42.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.42.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.42.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.42.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.42.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.42.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.42.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.42.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.42.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.43.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.43.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.43.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.43.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.43.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.43.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.43.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.43.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.43.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.44.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.44.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.44.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.44.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.44.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.44.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.44.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.44.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.44.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.45.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.45.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.45.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.45.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.45.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.45.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.45.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.45.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.45.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.46.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.46.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.46.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.46.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.46.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.46.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.46.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.46.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.46.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.47.self_attn.q_proj.weight is on cuda:1\n",
      "Parameter model.layers.47.self_attn.k_proj.weight is on cuda:1\n",
      "Parameter model.layers.47.self_attn.v_proj.weight is on cuda:1\n",
      "Parameter model.layers.47.self_attn.o_proj.weight is on cuda:1\n",
      "Parameter model.layers.47.mlp.gate_proj.weight is on cuda:1\n",
      "Parameter model.layers.47.mlp.up_proj.weight is on cuda:1\n",
      "Parameter model.layers.47.mlp.down_proj.weight is on cuda:1\n",
      "Parameter model.layers.47.input_layernorm.weight is on cuda:1\n",
      "Parameter model.layers.47.post_attention_layernorm.weight is on cuda:1\n",
      "Parameter model.norm.weight is on cuda:1\n",
      "Parameter lm_head.weight is on cuda:1\n"
     ]
    }
   ],
   "source": [
    "for name, param in base_model.named_parameters():\n",
    "    print(f\"Parameter {name} is on {param.device}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:37:16.800873Z",
     "start_time": "2023-12-21T16:37:16.792145Z"
    }
   },
   "id": "1b1f7733e1c1786d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/var/model/Phind-CodeLlama-34B-v2/wandb/run-20231221_031226-hhuvnvmc</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/ricardo-felipe-ruiz/Phind-CodeLlama-34B-v2-peft-fine-tuning/runs/hhuvnvmc' target=\"_blank\">solar-river-9</a></strong> to <a href='https://wandb.ai/ricardo-felipe-ruiz/Phind-CodeLlama-34B-v2-peft-fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/ricardo-felipe-ruiz/Phind-CodeLlama-34B-v2-peft-fine-tuning' target=\"_blank\">https://wandb.ai/ricardo-felipe-ruiz/Phind-CodeLlama-34B-v2-peft-fine-tuning</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/ricardo-felipe-ruiz/Phind-CodeLlama-34B-v2-peft-fine-tuning/runs/hhuvnvmc' target=\"_blank\">https://wandb.ai/ricardo-felipe-ruiz/Phind-CodeLlama-34B-v2-peft-fine-tuning/runs/hhuvnvmc</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5477, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 0.4307, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.05}\n",
      "{'loss': 0.3226, 'learning_rate': 0.000125, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2261, 'learning_rate': 0.0001666666666666667, 'epoch': 1.0}\n",
      "{'loss': 0.1358, 'learning_rate': 0.00019999918050612108, 'epoch': 1.03}\n",
      "{'loss': 0.0998, 'learning_rate': 0.0001999704996306308, 'epoch': 1.05}\n",
      "{'loss': 0.0897, 'learning_rate': 0.00019990085749160822, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0835, 'learning_rate': 0.00019979028262377118, 'epoch': 2.01}\n",
      "{'loss': 0.07, 'learning_rate': 0.00019963882033334826, 'epoch': 2.03}\n",
      "{'loss': 0.0636, 'learning_rate': 0.00019944653267951504, 'epoch': 2.06}\n",
      "{'loss': 0.0584, 'learning_rate': 0.00019921349844896654, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0562, 'learning_rate': 0.00019893981312363562, 'epoch': 3.01}\n",
      "{'loss': 0.0463, 'learning_rate': 0.00019862558884157068, 'epoch': 3.04}\n",
      "{'loss': 0.0459, 'learning_rate': 0.00019827095435098925, 'epoch': 3.06}\n",
      "{'loss': 0.048, 'learning_rate': 0.00019787605495752528, 'epoch': 3.09}\n",
      "{'train_runtime': 6304.2352, 'train_samples_per_second': 0.508, 'train_steps_per_second': 0.127, 'train_loss': 0.15215845870507227, 'epoch': 3.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ba62dadf39a45a2863bf71aa6bb8bff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▃▃▃▃▆▆▆▆█████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train/learning_rate</td><td>▁▃▅▇███████████</td></tr><tr><td>train/loss</td><td>█▆▅▄▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.1</td></tr><tr><td>train/global_step</td><td>77</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>0.048</td></tr><tr><td>train/total_flos</td><td>2.542620700972155e+17</td></tr><tr><td>train/train_loss</td><td>0.15216</td></tr><tr><td>train/train_runtime</td><td>6304.2352</td></tr><tr><td>train/train_samples_per_second</td><td>0.508</td></tr><tr><td>train/train_steps_per_second</td><td>0.127</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">solar-river-9</strong> at: <a href='https://wandb.ai/ricardo-felipe-ruiz/Phind-CodeLlama-34B-v2-peft-fine-tuning/runs/hhuvnvmc' target=\"_blank\">https://wandb.ai/ricardo-felipe-ruiz/Phind-CodeLlama-34B-v2-peft-fine-tuning/runs/hhuvnvmc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231221_031226-hhuvnvmc/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "#stop reporting to wandb\n",
    "wandb.finish()\n",
    "\n",
    "# save model\n",
    "trainer.save_model()\n",
    "\n",
    "print( \"Model saved\" )\n",
    "\n",
    "# {'loss': 0.5582, 'learning_rate': 1.1111111111111112e-05, 'epoch': 0.03}\n",
    "# {'loss': 0.512, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.05}\n",
    "# {'loss': 0.4509, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.07}\n",
    "# {'loss': 0.3753, 'learning_rate': 4.4444444444444447e-05, 'epoch': 1.0}\n",
    "# {'loss': 0.3123, 'learning_rate': 5.555555555555556e-05, 'epoch': 1.03}\n",
    "# {'loss': 0.259, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.05}\n",
    "# {'loss': 0.1952, 'learning_rate': 7.777777777777778e-05, 'epoch': 1.08}\n",
    "# {'loss': 0.1454, 'learning_rate': 8.888888888888889e-05, 'epoch': 2.01}\n",
    "# {'loss': 0.1129, 'learning_rate': 0.0001, 'epoch': 2.03}\n",
    "# {'loss': 0.0995, 'learning_rate': 0.00011111111111111112, 'epoch': 2.06}\n",
    "# {'loss': 0.0877, 'learning_rate': 0.00012222222222222224, 'epoch': 2.08}\n",
    "# {'loss': 0.0815, 'learning_rate': 0.00013333333333333334, 'epoch': 3.01}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T04:57:37.816689Z",
     "start_time": "2023-12-21T03:12:26.869705Z"
    }
   },
   "id": "597fd4a8fa0f143f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T17:49:55.354783Z",
     "start_time": "2023-11-16T17:49:55.314638Z"
    }
   },
   "id": "4f1d623ab4bc7b2e"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_output[ 0 ]: tensor([    1,   835,  2799,  4080, 29901,    13,  1678,  4803,   278,  9330,\n",
      "         2400,   322,   278, 10567,  2183,   304,  2436,   263, 13291,   393,\n",
      "          508,  4505,   278,  1494,  9330, 29901,    13,    13,  1678,   835,\n",
      "         9330, 29901,    13,  1678,  3575,  4982,   338,   304,  2313,   824,\n",
      "          278,  7609,   310,   263,  5199,  7314,  1899,  1301,  3395,   322,\n",
      "        14240,   372,   964,   263,  3918,  1891,  1899,   393,   263,  4714,\n",
      "          373,   596,  6601,   723,  2274, 29889,    13,    13,  1678,   887,\n",
      "          674,   367,  2183,   263,  5199,  7314,  1899,   322,   263,  1051,\n",
      "          310,  1950,  3918,  1891,  8260, 29889,   887,  1818,  6755,   278,\n",
      "         1959,  3918,  1891,  1899,   515,   278,  1494,  1051, 29901, 16218,\n",
      "         4478,   716,  4434,   742,   525,  4478,  1857,  4434,   742,   525,\n",
      "         4478,  5386,   716,  4434,   742,   525,  4478,  5386,  1857,  4434,\n",
      "          742,   525,  4478,  5386, 21344,   716,  4434,   742,   525,  4478,\n",
      "         5386, 21344,  1857,  4434, 29915,   322,   525,  9290, 29915,  1412,\n",
      "           13,    13,  1678,   830,  1548,   358, 29901,   887,   341, 17321,\n",
      "         6058,   671,  3017,   775,   304,  1234,   445,  1139, 29889,    13,\n",
      "         1678,   830,  1548,   358, 29901,   887,   341, 17321,   671,   596,\n",
      "        21110,  4695,  7134,   322, 26877,   654,   304,  1234,   445,  1139,\n",
      "        29889,    13,  1678,   379,   524, 29901,   530,  1541,   292,   393,\n",
      "         3508, 29915, 29873,   263,   760,   310,   278,  1899,  3528,   881,\n",
      "          367, 14914,   408,  6273,  4475,   304,   278,  1899, 29889,    13,\n",
      "           13,  1678,   835, 10567, 29901,    13,   268,    13,  1678, 13866,\n",
      "          338,   278, 10650,  5199,  7314,  1899,  1301,  3395, 20917,   773,\n",
      "         2560,  6560, 29901,    13,   268,    13,  1678,   529, 26029, 29958,\n",
      "           13,  4706,   529, 14917, 29899,  6519, 29958, 29909,   808,  5087,\n",
      "        21344,  1048,   660, 29931,  1955, 29909,   322,   349, 29923,  7818,\n",
      "         2691, 29899, 29873, 27964,   363,  6560,  1962, 29892,  1510,  2582,\n",
      "          297,   263,   716,  4434,   829, 14917, 29899,  6519, 29958,    13,\n",
      "         1678,  1533, 26029, 29958,    13,   268,    13,  1678,   450,  3918,\n",
      "         1891,  1899,   393,   366, 14240,   341, 17321,   367,  4133, 21021,\n",
      "          297,  2560, 29892,  1532, 29899, 15628,  6560, 29901,    13,   268,\n",
      "           13,  1678,   529,  5327, 29958,    13,  4706,   529, 15965, 29899,\n",
      "         6519,  2565, 15965, 29899,  6519, 29958,    13,  4706,   529,  5085,\n",
      "         2565,  5085, 29958,    13,  1678,  1533,  5327, 29958,    13,    13,\n",
      "         1678,   830,  1548,   358, 29901,   450,   937,  1734,   310,   596,\n",
      "         2933,   341, 17321,   367, 14935,  5327, 13885,    13,    13,  1678,\n",
      "          835, 13291, 29901,    13,   268,    13,  1678,   529,  5327, 29958,\n",
      "           13,  4706,   529, 15965, 29899,  6519, 29958,  4478,  5386, 21344,\n",
      "          716,  4434,   829, 15965, 29899,  6519, 29958,    13,  4706,   529,\n",
      "         5085, 29958,  2239,  1955, 29909,   322,   349, 29923,  7818,  2691,\n",
      "        29899, 29873, 27964,   363,  6560,  1962,   829,  5085, 29958,    13,\n",
      "         1678,  1533,  5327, 29958,     2], device='cuda:0')\n",
      "\n",
      "generation_output[ 0 ].shape: torch.Size([415])\n",
      "\n",
      "raw_output: <s> ### Instruction:\n",
      "    Use the Task below and the Input given to write a Response that can solve the following Task:\n",
      "\n",
      "    ### Task:\n",
      "    Your job is to discern the intent of a human voice command transcription and translate it into a standardized command that a browser on your computer would understand.\n",
      "\n",
      "    You will be given a human voice command and a list of possible standardized commands. You must choose the correct standardized command from the following list: `'search new tab', 'search current tab', 'search google new tab', 'search google current tab', 'search google scholar new tab', 'search google scholar current tab' and 'none'`.\n",
      "\n",
      "    Requirement: You MUST NOT use python code to answer this question.\n",
      "    Requirement: You MUST use your linguistic knowledge and intuition to answer this question.\n",
      "    Hint: Anything that isn't a part of the command itself should be treated as arguments related to the command.\n",
      "\n",
      "    ### Input:\n",
      "    \n",
      "    Below is the raw human voice command transcription formatted using simple XML:\n",
      "    \n",
      "    <human>\n",
      "        <voice-command>Ask Google scholar about QLORA and PEFT fine-tuning for XML output, show results in a new tab</voice-command>\n",
      "    </human>\n",
      "    \n",
      "    The standardized command that you translate MUST be returned wrapped in simple, well-formed XML:\n",
      "    \n",
      "    <response>\n",
      "        <browser-command></browser-command>\n",
      "        <args></args>\n",
      "    </response>\n",
      "\n",
      "    Requirement: The first word of your response MUST be `<response>`\n",
      "\n",
      "    ### Response:\n",
      "    \n",
      "    <response>\n",
      "        <browser-command>search google scholar new tab</browser-command>\n",
      "        <args>QLORA and PEFT fine-tuning for XML output</args>\n",
      "    </response></s>\n",
      "\n",
      "len( raw_output ): 1669\n",
      "\n",
      "\n",
      "    \n",
      "    <response>\n",
      "        <browser-command>search google scholar new tab</browser-command>\n",
      "        <args>QLORA and PEFT fine-tuning for XML output</args>\n",
      "    </response></s>\n"
     ]
    }
   ],
   "source": [
    "for line in generate_text( tokenizer, base_model, question ).split( \"\\n\" ): print( line )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T16:45:47.960472Z",
     "start_time": "2023-12-21T16:45:43.178815Z"
    }
   },
   "id": "8b7bf973e2dcedd8"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "493"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drops 16.4/19.0 GB per GPU down to 3.25 GB per GPU!\n",
    "import gc\n",
    "base_model = None \n",
    "adapter_plus_model = None\n",
    "torch.cuda.empty_cache() \n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:47:43.968306Z",
     "start_time": "2024-01-02T17:47:43.964562Z"
    }
   },
   "id": "23550e0e9f04149f"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "os.chdir( \"/var/model/Phind-CodeLlama-34B-v2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:39:23.256866Z",
     "start_time": "2024-01-02T17:39:23.241443Z"
    }
   },
   "id": "9a386f368f985182"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitsAndBytesConfig {\n",
      "  \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "  \"llm_int8_has_fp16_weight\": false,\n",
      "  \"llm_int8_skip_modules\": null,\n",
      "  \"llm_int8_threshold\": 6.0,\n",
      "  \"load_in_4bit\": true,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"quant_method\": \"bitsandbytes\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1353789412b84098b1c891392bf2215a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "print( bnb_config )\n",
    "tokenizer              = AutoTokenizer.from_pretrained( \".\" )\n",
    "tokenizer.pad_token    = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# ¡OJO! Why were we turning off the cash here? \n",
    "# We're not! It makes a huge performance difference: 21 vs 14 tokens per second!\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \".\", quantization_config=bnb_config, device_map=\"auto\", low_cpu_mem_usage=True, use_cache=True, use_flash_attention_2=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:39:59.234228Z",
     "start_time": "2024-01-02T17:39:24.829328Z"
    }
   },
   "id": "55afe25a14757322"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight: cuda:0\n",
      "model.layers.0.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.0.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.0.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.0.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.0.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.0.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.0.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.0.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.0.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.0.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.0.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.0.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.0.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.0.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.0.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.0.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.0.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.0.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.0.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.0.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.0.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.0.input_layernorm.weight: cuda:0\n",
      "model.layers.0.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.1.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.1.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.1.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.1.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.1.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.1.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.1.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.1.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.1.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.1.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.1.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.1.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.1.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.1.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.1.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.1.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.1.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.1.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.1.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.1.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.1.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.1.input_layernorm.weight: cuda:0\n",
      "model.layers.1.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.2.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.2.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.2.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.2.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.2.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.2.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.2.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.2.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.2.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.2.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.2.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.2.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.2.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.2.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.2.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.2.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.2.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.2.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.2.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.2.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.2.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.2.input_layernorm.weight: cuda:0\n",
      "model.layers.2.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.3.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.3.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.3.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.3.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.3.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.3.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.3.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.3.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.3.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.3.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.3.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.3.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.3.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.3.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.3.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.3.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.3.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.3.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.3.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.3.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.3.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.3.input_layernorm.weight: cuda:0\n",
      "model.layers.3.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.4.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.4.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.4.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.4.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.4.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.4.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.4.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.4.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.4.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.4.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.4.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.4.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.4.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.4.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.4.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.4.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.4.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.4.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.4.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.4.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.4.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.4.input_layernorm.weight: cuda:0\n",
      "model.layers.4.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.5.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.5.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.5.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.5.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.5.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.5.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.5.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.5.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.5.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.5.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.5.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.5.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.5.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.5.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.5.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.5.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.5.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.5.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.5.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.5.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.5.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.5.input_layernorm.weight: cuda:0\n",
      "model.layers.5.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.6.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.6.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.6.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.6.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.6.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.6.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.6.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.6.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.6.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.6.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.6.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.6.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.6.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.6.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.6.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.6.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.6.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.6.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.6.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.6.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.6.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.6.input_layernorm.weight: cuda:0\n",
      "model.layers.6.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.7.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.7.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.7.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.7.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.7.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.7.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.7.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.7.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.7.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.7.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.7.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.7.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.7.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.7.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.7.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.7.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.7.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.7.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.7.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.7.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.7.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.7.input_layernorm.weight: cuda:0\n",
      "model.layers.7.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.8.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.8.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.8.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.8.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.8.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.8.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.8.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.8.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.8.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.8.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.8.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.8.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.8.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.8.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.8.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.8.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.8.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.8.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.8.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.8.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.8.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.8.input_layernorm.weight: cuda:0\n",
      "model.layers.8.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.9.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.9.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.9.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.9.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.9.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.9.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.9.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.9.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.9.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.9.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.9.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.9.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.9.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.9.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.9.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.9.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.9.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.9.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.9.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.9.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.9.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.9.input_layernorm.weight: cuda:0\n",
      "model.layers.9.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.10.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.10.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.10.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.10.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.10.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.10.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.10.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.10.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.10.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.10.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.10.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.10.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.10.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.10.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.10.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.10.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.10.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.10.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.10.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.10.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.10.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.10.input_layernorm.weight: cuda:0\n",
      "model.layers.10.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.11.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.11.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.11.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.11.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.11.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.11.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.11.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.11.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.11.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.11.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.11.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.11.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.11.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.11.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.11.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.11.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.11.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.11.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.11.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.11.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.11.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.11.input_layernorm.weight: cuda:0\n",
      "model.layers.11.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.12.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.12.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.12.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.12.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.12.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.12.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.12.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.12.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.12.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.12.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.12.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.12.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.12.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.12.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.12.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.12.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.12.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.12.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.12.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.12.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.12.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.12.input_layernorm.weight: cuda:0\n",
      "model.layers.12.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.13.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.13.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.13.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.13.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.13.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.13.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.13.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.13.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.13.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.13.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.13.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.13.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.13.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.13.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.13.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.13.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.13.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.13.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.13.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.13.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.13.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.13.input_layernorm.weight: cuda:0\n",
      "model.layers.13.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.14.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.14.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.14.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.14.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.14.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.14.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.14.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.14.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.14.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.14.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.14.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.14.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.14.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.14.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.14.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.14.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.14.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.14.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.14.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.14.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.14.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.14.input_layernorm.weight: cuda:0\n",
      "model.layers.14.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.15.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.15.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.15.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.15.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.15.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.15.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.15.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.15.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.15.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.15.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.15.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.15.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.15.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.15.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.15.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.15.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.15.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.15.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.15.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.15.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.15.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.15.input_layernorm.weight: cuda:0\n",
      "model.layers.15.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.16.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.16.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.16.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.16.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.16.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.16.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.16.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.16.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.16.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.16.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.16.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.16.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.16.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.16.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.16.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.16.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.16.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.16.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.16.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.16.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.16.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.16.input_layernorm.weight: cuda:0\n",
      "model.layers.16.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.17.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.17.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.17.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.17.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.17.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.17.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.17.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.17.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.17.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.17.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.17.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.17.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.17.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.17.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.17.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.17.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.17.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.17.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.17.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.17.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.17.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.17.input_layernorm.weight: cuda:0\n",
      "model.layers.17.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.18.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.18.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.18.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.18.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.18.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.18.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.18.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.18.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.18.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.18.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.18.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.18.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.18.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.18.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.18.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.18.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.18.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.18.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.18.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.18.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.18.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.18.input_layernorm.weight: cuda:0\n",
      "model.layers.18.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.19.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.19.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.19.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.19.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.19.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.19.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.19.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.19.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.19.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.19.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.19.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.19.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.19.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.19.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.19.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.19.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.19.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.19.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.19.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.19.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.19.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.19.input_layernorm.weight: cuda:0\n",
      "model.layers.19.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.20.self_attn.q_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.20.self_attn.q_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.20.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "model.layers.20.self_attn.k_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.20.self_attn.k_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.20.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "model.layers.20.self_attn.v_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.20.self_attn.v_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.20.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "model.layers.20.self_attn.o_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.20.self_attn.o_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.20.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "model.layers.20.mlp.gate_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.20.mlp.gate_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.20.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "model.layers.20.mlp.up_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.20.mlp.up_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.20.mlp.up_proj.base_layer.weight: cuda:0\n",
      "model.layers.20.mlp.down_proj.lora_A.default.weight: cuda:0\n",
      "model.layers.20.mlp.down_proj.lora_B.default.weight: cuda:0\n",
      "model.layers.20.mlp.down_proj.base_layer.weight: cuda:0\n",
      "model.layers.20.input_layernorm.weight: cuda:0\n",
      "model.layers.20.post_attention_layernorm.weight: cuda:0\n",
      "model.layers.21.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.21.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.21.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.21.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.21.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.21.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.21.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.21.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.21.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.21.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.21.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.21.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.21.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.21.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.21.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.21.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.21.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.21.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.21.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.21.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.21.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.21.input_layernorm.weight: cuda:1\n",
      "model.layers.21.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.22.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.22.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.22.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.22.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.22.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.22.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.22.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.22.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.22.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.22.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.22.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.22.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.22.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.22.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.22.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.22.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.22.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.22.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.22.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.22.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.22.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.22.input_layernorm.weight: cuda:1\n",
      "model.layers.22.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.23.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.23.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.23.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.23.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.23.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.23.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.23.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.23.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.23.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.23.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.23.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.23.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.23.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.23.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.23.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.23.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.23.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.23.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.23.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.23.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.23.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.23.input_layernorm.weight: cuda:1\n",
      "model.layers.23.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.24.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.24.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.24.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.24.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.24.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.24.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.24.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.24.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.24.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.24.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.24.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.24.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.24.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.24.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.24.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.24.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.24.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.24.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.24.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.24.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.24.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.24.input_layernorm.weight: cuda:1\n",
      "model.layers.24.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.25.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.25.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.25.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.25.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.25.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.25.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.25.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.25.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.25.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.25.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.25.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.25.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.25.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.25.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.25.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.25.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.25.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.25.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.25.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.25.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.25.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.25.input_layernorm.weight: cuda:1\n",
      "model.layers.25.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.26.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.26.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.26.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.26.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.26.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.26.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.26.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.26.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.26.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.26.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.26.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.26.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.26.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.26.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.26.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.26.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.26.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.26.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.26.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.26.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.26.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.26.input_layernorm.weight: cuda:1\n",
      "model.layers.26.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.27.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.27.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.27.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.27.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.27.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.27.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.27.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.27.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.27.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.27.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.27.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.27.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.27.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.27.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.27.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.27.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.27.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.27.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.27.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.27.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.27.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.27.input_layernorm.weight: cuda:1\n",
      "model.layers.27.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.28.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.28.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.28.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.28.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.28.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.28.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.28.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.28.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.28.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.28.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.28.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.28.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.28.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.28.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.28.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.28.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.28.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.28.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.28.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.28.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.28.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.28.input_layernorm.weight: cuda:1\n",
      "model.layers.28.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.29.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.29.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.29.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.29.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.29.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.29.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.29.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.29.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.29.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.29.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.29.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.29.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.29.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.29.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.29.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.29.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.29.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.29.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.29.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.29.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.29.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.29.input_layernorm.weight: cuda:1\n",
      "model.layers.29.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.30.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.30.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.30.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.30.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.30.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.30.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.30.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.30.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.30.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.30.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.30.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.30.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.30.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.30.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.30.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.30.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.30.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.30.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.30.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.30.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.30.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.30.input_layernorm.weight: cuda:1\n",
      "model.layers.30.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.31.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.31.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.31.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.31.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.31.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.31.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.31.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.31.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.31.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.31.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.31.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.31.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.31.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.31.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.31.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.31.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.31.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.31.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.31.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.31.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.31.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.31.input_layernorm.weight: cuda:1\n",
      "model.layers.31.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.32.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.32.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.32.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.32.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.32.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.32.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.32.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.32.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.32.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.32.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.32.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.32.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.32.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.32.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.32.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.32.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.32.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.32.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.32.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.32.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.32.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.32.input_layernorm.weight: cuda:1\n",
      "model.layers.32.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.33.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.33.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.33.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.33.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.33.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.33.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.33.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.33.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.33.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.33.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.33.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.33.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.33.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.33.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.33.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.33.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.33.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.33.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.33.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.33.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.33.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.33.input_layernorm.weight: cuda:1\n",
      "model.layers.33.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.34.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.34.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.34.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.34.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.34.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.34.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.34.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.34.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.34.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.34.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.34.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.34.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.34.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.34.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.34.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.34.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.34.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.34.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.34.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.34.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.34.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.34.input_layernorm.weight: cuda:1\n",
      "model.layers.34.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.35.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.35.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.35.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.35.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.35.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.35.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.35.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.35.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.35.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.35.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.35.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.35.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.35.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.35.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.35.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.35.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.35.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.35.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.35.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.35.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.35.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.35.input_layernorm.weight: cuda:1\n",
      "model.layers.35.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.36.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.36.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.36.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.36.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.36.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.36.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.36.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.36.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.36.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.36.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.36.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.36.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.36.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.36.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.36.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.36.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.36.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.36.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.36.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.36.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.36.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.36.input_layernorm.weight: cuda:1\n",
      "model.layers.36.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.37.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.37.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.37.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.37.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.37.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.37.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.37.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.37.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.37.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.37.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.37.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.37.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.37.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.37.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.37.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.37.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.37.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.37.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.37.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.37.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.37.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.37.input_layernorm.weight: cuda:1\n",
      "model.layers.37.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.38.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.38.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.38.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.38.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.38.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.38.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.38.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.38.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.38.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.38.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.38.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.38.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.38.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.38.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.38.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.38.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.38.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.38.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.38.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.38.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.38.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.38.input_layernorm.weight: cuda:1\n",
      "model.layers.38.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.39.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.39.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.39.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.39.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.39.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.39.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.39.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.39.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.39.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.39.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.39.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.39.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.39.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.39.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.39.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.39.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.39.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.39.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.39.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.39.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.39.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.39.input_layernorm.weight: cuda:1\n",
      "model.layers.39.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.40.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.40.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.40.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.40.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.40.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.40.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.40.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.40.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.40.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.40.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.40.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.40.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.40.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.40.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.40.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.40.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.40.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.40.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.40.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.40.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.40.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.40.input_layernorm.weight: cuda:1\n",
      "model.layers.40.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.41.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.41.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.41.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.41.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.41.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.41.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.41.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.41.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.41.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.41.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.41.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.41.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.41.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.41.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.41.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.41.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.41.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.41.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.41.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.41.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.41.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.41.input_layernorm.weight: cuda:1\n",
      "model.layers.41.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.42.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.42.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.42.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.42.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.42.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.42.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.42.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.42.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.42.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.42.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.42.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.42.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.42.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.42.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.42.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.42.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.42.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.42.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.42.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.42.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.42.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.42.input_layernorm.weight: cuda:1\n",
      "model.layers.42.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.43.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.43.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.43.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.43.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.43.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.43.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.43.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.43.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.43.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.43.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.43.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.43.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.43.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.43.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.43.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.43.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.43.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.43.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.43.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.43.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.43.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.43.input_layernorm.weight: cuda:1\n",
      "model.layers.43.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.44.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.44.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.44.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.44.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.44.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.44.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.44.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.44.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.44.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.44.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.44.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.44.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.44.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.44.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.44.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.44.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.44.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.44.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.44.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.44.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.44.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.44.input_layernorm.weight: cuda:1\n",
      "model.layers.44.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.45.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.45.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.45.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.45.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.45.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.45.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.45.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.45.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.45.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.45.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.45.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.45.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.45.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.45.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.45.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.45.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.45.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.45.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.45.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.45.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.45.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.45.input_layernorm.weight: cuda:1\n",
      "model.layers.45.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.46.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.46.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.46.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.46.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.46.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.46.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.46.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.46.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.46.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.46.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.46.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.46.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.46.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.46.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.46.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.46.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.46.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.46.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.46.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.46.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.46.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.46.input_layernorm.weight: cuda:1\n",
      "model.layers.46.post_attention_layernorm.weight: cuda:1\n",
      "model.layers.47.self_attn.q_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.47.self_attn.q_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.47.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "model.layers.47.self_attn.k_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.47.self_attn.k_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.47.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "model.layers.47.self_attn.v_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.47.self_attn.v_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.47.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "model.layers.47.self_attn.o_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.47.self_attn.o_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.47.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "model.layers.47.mlp.gate_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.47.mlp.gate_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.47.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "model.layers.47.mlp.up_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.47.mlp.up_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.47.mlp.up_proj.base_layer.weight: cuda:1\n",
      "model.layers.47.mlp.down_proj.lora_A.default.weight: cuda:1\n",
      "model.layers.47.mlp.down_proj.lora_B.default.weight: cuda:1\n",
      "model.layers.47.mlp.down_proj.base_layer.weight: cuda:1\n",
      "model.layers.47.input_layernorm.weight: cuda:1\n",
      "model.layers.47.post_attention_layernorm.weight: cuda:1\n",
      "model.norm.weight: cuda:1\n",
      "lm_head.weight: cuda:1\n"
     ]
    }
   ],
   "source": [
    "dupt.print_device_allocation( base_model )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:40:15.226399Z",
     "start_time": "2024-01-02T17:40:15.211768Z"
    }
   },
   "id": "4b0c2465c3fe3182"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<response>\n",
      "            <browser-command>search google scholar new tab</browser-command>\n",
      "            <args>QLORA and PEFT fine-tuning for XML output</args>\n",
      "        </response>]\n"
     ]
    }
   ],
   "source": [
    "response = generate_text( tokenizer, base_model, question )\n",
    "response = f\"[{response}]\"\n",
    "for line in response.split( \"\\n\" ): print( line )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:40:36.482588Z",
     "start_time": "2024-01-02T17:40:30.055813Z"
    }
   },
   "id": "2bbddb04a5a998aa"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "adapter_plus_model = PeftModel.from_pretrained( base_model, \"adapters/00-browser-vox-command\", use_flash_attention_2=True )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:40:54.062869Z",
     "start_time": "2024-01-02T17:40:52.857879Z"
    }
   },
   "id": "34796358a34b99c6"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "adapter_plus_model = accelerator.prepare( adapter_plus_model )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:45:44.705728Z",
     "start_time": "2024-01-02T17:45:44.692267Z"
    }
   },
   "id": "8a8382a512c938fd"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight: cuda:0\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.0.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.0.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.0.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.1.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.1.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.1.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.2.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.2.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.2.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.3.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.3.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.3.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.4.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.4.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.4.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.5.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.5.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.5.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.6.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.6.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.6.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.7.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.7.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.7.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.8.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.8.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.8.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.9.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.9.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.9.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.10.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.10.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.10.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.11.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.11.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.11.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.12.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.12.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.12.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.13.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.13.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.13.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.14.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.14.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.14.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.15.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.15.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.15.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.16.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.16.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.16.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.17.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.17.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.17.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.18.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.18.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.18.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.19.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.19.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.19.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.20.mlp.up_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.20.mlp.down_proj.base_layer.weight: cuda:0\n",
      "base_model.model.model.layers.20.input_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight: cuda:0\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.21.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.21.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.21.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.22.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.22.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.22.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.23.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.23.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.23.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.24.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.24.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.24.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.24.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.25.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.25.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.25.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.25.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.26.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.26.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.26.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.26.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.27.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.27.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.27.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.27.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.28.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.28.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.28.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.28.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.29.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.29.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.29.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.29.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.30.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.30.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.30.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.30.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.31.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.31.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.31.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.31.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.32.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.32.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.32.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.32.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.32.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.32.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.32.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.32.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.32.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.33.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.33.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.33.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.33.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.33.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.33.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.33.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.33.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.33.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.34.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.34.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.34.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.34.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.34.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.34.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.34.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.34.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.34.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.35.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.35.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.35.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.35.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.35.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.35.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.35.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.35.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.35.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.36.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.36.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.36.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.36.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.36.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.36.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.36.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.36.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.36.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.36.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.36.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.36.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.36.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.36.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.36.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.37.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.37.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.37.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.37.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.37.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.37.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.37.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.37.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.37.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.37.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.37.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.37.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.37.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.37.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.37.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.38.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.38.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.38.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.38.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.38.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.38.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.38.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.38.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.38.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.38.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.38.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.38.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.38.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.38.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.38.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.39.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.39.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.39.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.39.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.39.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.39.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.39.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.39.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.39.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.39.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.39.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.39.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.39.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.39.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.39.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.40.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.40.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.40.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.40.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.40.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.40.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.40.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.40.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.40.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.40.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.40.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.40.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.40.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.40.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.40.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.40.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.40.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.40.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.40.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.40.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.40.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.40.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.40.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.41.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.41.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.41.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.41.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.41.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.41.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.41.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.41.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.41.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.41.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.41.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.41.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.41.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.41.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.41.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.41.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.41.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.41.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.41.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.41.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.41.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.41.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.41.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.42.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.42.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.42.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.42.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.42.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.42.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.42.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.42.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.42.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.42.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.42.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.42.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.42.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.42.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.42.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.42.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.42.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.42.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.42.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.42.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.42.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.42.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.42.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.43.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.43.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.43.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.43.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.43.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.43.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.43.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.43.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.43.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.43.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.43.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.43.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.43.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.43.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.43.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.43.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.43.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.43.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.43.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.43.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.43.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.43.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.43.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.44.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.44.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.44.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.44.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.44.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.44.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.44.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.44.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.44.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.44.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.44.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.44.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.44.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.44.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.44.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.44.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.44.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.44.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.44.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.44.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.44.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.44.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.44.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.45.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.45.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.45.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.45.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.45.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.45.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.45.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.45.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.45.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.45.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.45.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.45.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.45.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.45.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.45.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.45.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.45.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.45.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.45.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.45.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.45.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.45.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.45.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.46.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.46.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.46.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.46.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.46.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.46.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.46.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.46.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.46.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.46.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.46.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.46.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.46.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.46.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.46.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.46.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.46.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.46.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.46.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.46.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.46.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.46.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.46.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.47.self_attn.q_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.47.self_attn.q_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.47.self_attn.q_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.47.self_attn.k_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.47.self_attn.k_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.47.self_attn.k_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.47.self_attn.v_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.47.self_attn.v_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.47.self_attn.v_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.47.self_attn.o_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.47.self_attn.o_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.47.self_attn.o_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.47.mlp.gate_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.47.mlp.gate_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.47.mlp.gate_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.47.mlp.up_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.47.mlp.up_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.47.mlp.up_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.47.mlp.down_proj.lora_A.default.weight: cpu\n",
      "base_model.model.model.layers.47.mlp.down_proj.lora_B.default.weight: cpu\n",
      "base_model.model.model.layers.47.mlp.down_proj.base_layer.weight: cuda:1\n",
      "base_model.model.model.layers.47.input_layernorm.weight: cuda:1\n",
      "base_model.model.model.layers.47.post_attention_layernorm.weight: cuda:1\n",
      "base_model.model.model.norm.weight: cuda:1\n",
      "base_model.model.lm_head.weight: cuda:1\n"
     ]
    }
   ],
   "source": [
    "dupt.print_device_allocation( adapter_plus_model )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:45:47.788671Z",
     "start_time": "2024-01-02T17:45:47.778991Z"
    }
   },
   "id": "4a4d57dcf172749f"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m generate_text( tokenizer, adapter_plus_model, question )\u001B[38;5;241m.\u001B[39msplit( \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m ): \u001B[38;5;28mprint\u001B[39m( line )\n",
      "Cell \u001B[0;32mIn[8], line 40\u001B[0m, in \u001B[0;36mgenerate_text\u001B[0;34m(foo_tokenizer, model, question, max_new_tokens, debug)\u001B[0m\n\u001B[1;32m     36\u001B[0m inputs \u001B[38;5;241m=\u001B[39m foo_tokenizer( instruction, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m )\u001B[38;5;241m.\u001B[39mto( device )\n\u001B[1;32m     38\u001B[0m stop_token_id \u001B[38;5;241m=\u001B[39m foo_tokenizer\u001B[38;5;241m.\u001B[39mencode( \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</response>\u001B[39m\u001B[38;5;124m\"\u001B[39m )[ \u001B[38;5;241m0\u001B[39m ]\n\u001B[0;32m---> 40\u001B[0m generation_output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput_ids\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mattention_mask\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_new_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop_token_id\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m debug: \n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28mprint\u001B[39m( \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration_output[ 0 ]:\u001B[39m\u001B[38;5;124m\"\u001B[39m, generation_output[ \u001B[38;5;241m0\u001B[39m ], end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m )\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py:1060\u001B[0m, in \u001B[0;36mPeftModelForCausalLM.generate\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m   1058\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mgeneration_config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeneration_config\n\u001B[1;32m   1059\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1060\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m   1062\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model_prepare_inputs_for_generation\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1753\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massisted_decoding(\n\u001B[1;32m   1737\u001B[0m         input_ids,\n\u001B[1;32m   1738\u001B[0m         assistant_model\u001B[38;5;241m=\u001B[39massistant_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1750\u001B[0m     )\n\u001B[1;32m   1751\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mGREEDY_SEARCH:\n\u001B[1;32m   1752\u001B[0m     \u001B[38;5;66;03m# 11. run greedy search\u001B[39;00m\n\u001B[0;32m-> 1753\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgreedy_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1754\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1755\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1756\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1757\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1758\u001B[0m \u001B[43m        \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1759\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1761\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1762\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1763\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1764\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1766\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mCONTRASTIVE_SEARCH:\n\u001B[1;32m   1767\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:2614\u001B[0m, in \u001B[0;36mGenerationMixin.greedy_search\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   2611\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m   2613\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[0;32m-> 2614\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2615\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2616\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2617\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2618\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2619\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2621\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[1;32m   2622\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# don't waste resources running the code we don't need\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:164\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    162\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 164\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:1034\u001B[0m, in \u001B[0;36mLlamaForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1031\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m   1033\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1034\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1035\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1036\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1037\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1038\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1039\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1040\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1041\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1042\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1043\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1044\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1046\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpretraining_tp \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:922\u001B[0m, in \u001B[0;36mLlamaModel.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    912\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    913\u001B[0m         decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    914\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    919\u001B[0m         use_cache,\n\u001B[1;32m    920\u001B[0m     )\n\u001B[1;32m    921\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 922\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    929\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    931\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:164\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    162\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 164\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:672\u001B[0m, in \u001B[0;36mLlamaDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001B[0m\n\u001B[1;32m    669\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_layernorm(hidden_states)\n\u001B[1;32m    671\u001B[0m \u001B[38;5;66;03m# Self Attention\u001B[39;00m\n\u001B[0;32m--> 672\u001B[0m hidden_states, self_attn_weights, present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    681\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    683\u001B[0m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:164\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    162\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 164\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:465\u001B[0m, in \u001B[0;36mLlamaFlashAttention2.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001B[0m\n\u001B[1;32m    461\u001B[0m output_attentions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    463\u001B[0m bsz, q_len, _ \u001B[38;5;241m=\u001B[39m hidden_states\u001B[38;5;241m.\u001B[39msize()\n\u001B[0;32m--> 465\u001B[0m query_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mq_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    466\u001B[0m key_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_proj(hidden_states)\n\u001B[1;32m    467\u001B[0m value_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_proj(hidden_states)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:290\u001B[0m, in \u001B[0;36mLinear4bit.forward\u001B[0;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[1;32m    287\u001B[0m     expected_dtype \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mdtype\n\u001B[1;32m    288\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(lora_A\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m--> 290\u001B[0m output \u001B[38;5;241m=\u001B[39m lora_B(\u001B[43mlora_A\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m requires_conversion:\n\u001B[1;32m    292\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mto(expected_dtype)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
     ]
    }
   ],
   "source": [
    "for line in generate_text( tokenizer, adapter_plus_model, question ).split( \"\\n\" ): print( line )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:45:20.151873Z",
     "start_time": "2024-01-02T17:45:19.819474Z"
    }
   },
   "id": "d84a5998d65cb738"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['instruction', 'input', 'output', 'prompt'])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepily_dataset_test[ 0 ].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T17:16:37.070534Z",
     "start_time": "2023-12-21T17:16:37.032215Z"
    }
   },
   "id": "dcb9efffadd2d939"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n        Below is the raw human voice command transcription formatted using simple XML:\\n        \\n        <human>\\n            <voice-command>Start a Google search on How do you address resource-related warnings in Python, especially regarding resource usage? in a new tab</voice-command>\\n        </human>\\n        \\n        The standardized command that you translate MUST be returned wrapped in simple, well-formed XML:\\n        \\n        <response>\\n            <browser-command></browser-command>\\n            <args></args>\\n        </response>\\n\\n        Requirement: The first word of your response MUST be `<response>`'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepily_dataset_test[ 0 ][ 'input' ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T17:17:28.199056Z",
     "start_time": "2023-12-21T17:17:28.145568Z"
    }
   },
   "id": "fa64c4a9f953dfdf"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T17:19:28.933078Z",
     "start_time": "2023-12-21T17:19:28.888697Z"
    }
   },
   "id": "f16775997e14a03c"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         instruction  \\\n0  Your job is to discern the intent of a human v...   \n1  Your job is to discern the intent of a human v...   \n2  Your job is to discern the intent of a human v...   \n3  Your job is to discern the intent of a human v...   \n4  Your job is to discern the intent of a human v...   \n\n                                               input  \\\n0  \\n        Below is the raw human voice command...   \n1  \\n        Below is the raw human voice command...   \n2  \\n        Below is the raw human voice command...   \n3  \\n        Below is the raw human voice command...   \n4  \\n        Below is the raw human voice command...   \n\n                                              output  \\\n0  \\n        <response>\\n            <browser-com...   \n1  \\n        <response>\\n            <browser-com...   \n2  \\n        <response>\\n            <browser-com...   \n3  \\n        <response>\\n            <browser-com...   \n4  \\n        <response>\\n            <browser-com...   \n\n                                              prompt  \n0  ### Instruction:\\n    Use the Task and Input g...  \n1  ### Instruction:\\n    Use the Task and Input g...  \n2  ### Instruction:\\n    Use the Task and Input g...  \n3  ### Instruction:\\n    Use the Task and Input g...  \n4  ### Instruction:\\n    Use the Task and Input g...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>input</th>\n      <th>output</th>\n      <th>prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json( \"/var/model/genie-in-the-box/src/ephemera/prompts/data/voice-commands-xml-test.jsonl\", lines=True )\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T20:34:36.779710Z",
     "start_time": "2023-12-21T20:34:36.719192Z"
    }
   },
   "id": "21de2f127247b122"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "'Now in this tab, Google Scholar best fashion trends this year'"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = test_df[ 'input' ].tolist()\n",
    "for idx, question in enumerate( questions ):\n",
    "    question = dux.get_value_by_xml_tag_name( question, \"voice-command\" )\n",
    "    # print( question )\n",
    "    questions[ idx ] = question\n",
    "    \n",
    "questions[ 0 ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T20:35:09.925340Z",
     "start_time": "2023-12-21T20:35:09.917988Z"
    }
   },
   "id": "e987324d2b86f79a"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "'<response>\\n            <browser-command>search google scholar current tab</browser-command>\\n            <args>best fashion trends this year</args>\\n        </response>'"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text( tokenizer, adapter_plus_model, questions[ 0 ] )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T20:35:55.172203Z",
     "start_time": "2023-12-21T20:35:49.828703Z"
    }
   },
   "id": "251cb152811e288d"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T20:39:05.921304Z",
     "start_time": "2023-12-21T20:39:05.862200Z"
    }
   },
   "id": "f1030836998a7aa"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] of [1000] [0.1%] [Now in this tab, Google Scholar best fashion trends this year]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>best fashion trends this year</args></response>]\n",
      "[2] of [1000] [0.2%] [Do a Google Scholar Warning search in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Warning</args></response>]\n",
      "[3] of [1000] [0.3%] [New tab, lookup for Using Pandas for ETL processes]\n",
      "[<response><browser-command>search new tab</browser-command><args>Using Pandas for ETL processes</args></response>]\n",
      "[4] of [1000] [0.4%] [Use this tab to Google AI for social good initiatives: What are some notable AI for social good initiatives?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI for social good initiatives: What are some notable AI for social good initiatives?</args></response>]\n",
      "[5] of [1000] [0.5%] [In a fresh tab, perform a Google search of How can buffer-related errors be detected and resolved in Python?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How can buffer-related errors be detected and resolved in Python?</args></response>]\n",
      "[6] of [1000] [0.6%] [Execute a search on Google for Data manipulation in Pandas, display in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Data manipulation in Pandas</args></response>]\n",
      "[7] of [1000] [0.7%] [Begin with Google Scholar ImportWarning]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>ImportWarning</args></response>]\n",
      "[8] of [1000] [0.8%] [Fetch what is the stock market? results in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>what is the stock market?</args></response>]\n",
      "[9] of [1000] [0.9%] [Get Google Scholar results for AI in autonomous vehicles here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in autonomous vehicles</args></response>]\n",
      "[10] of [1000] [1.0%] [In a fresh tab, launch a Google search for Optimizing Pandas code performance]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Optimizing Pandas code performance</args></response>]\n",
      "[11] of [1000] [1.1%] [Begin How do you address runtime warnings in Python, especially those indicating risky runtime behavior? search in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>How do you address runtime warnings in Python, especially those indicating risky runtime behavior?</args></response>]\n",
      "[12] of [1000] [1.2%] [Google Scholar, let's find Syntax Warning: Syntax issue warning]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Syntax Warning: Syntax issue warning</args></response>]\n",
      "[13] of [1000] [1.3%] [Begin a new tab and search for ZeroDivisionError]\n",
      "[<response><browser-command>search new tab</browser-command><args>ZeroDivisionError</args></response>]\n",
      "[14] of [1000] [1.4%] [Carry out a Google lookup for top 10 video games of all time, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>top 10 video games of all time</args></response>]\n",
      "[15] of [1000] [1.5%] [Carry out a Google lookup for What are user-defined warnings in Python, and how can they be effectively used?, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>What are user-defined warnings in Python, and how can they be effectively used?</args></response>]\n",
      "[16] of [1000] [1.6%] [Do a Google search in a new tab, keywords: How can general warnings in Python be addressed to improve code quality?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How can general warnings in Python be addressed to improve code quality?</args></response>]\n",
      "[17] of [1000] [1.7%] [This screen, Google Scholar AI in video analysis: What are the latest AI techniques in video analysis and processing?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in video analysis: What are the latest AI techniques in video analysis and processing?</args></response>]\n",
      "[18] of [1000] [1.8%] [This tab: Search for Sentiment Analysis tools: What tools are widely used for sentiment analysis in social media data?]\n",
      "[<response><browser-command>search current tab</browser-command><args>Sentiment Analysis tools: What tools are widely used for sentiment analysis in social media data?</args></response>]\n",
      "[19] of [1000] [1.9%] [Do a Google Scholar search in a new tab for Data anonymization in Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Data anonymization in Pandas</args></response>]\n",
      "[20] of [1000] [2.0%] [Scan AI-driven recommendation systems in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI-driven recommendation systems</args></response>]\n",
      "[21] of [1000] [2.1%] [Fetch Google Scholar results for Real-time data streaming: How do you handle real-time data streaming in big data projects? in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Real-time data streaming: How do you handle real-time data streaming in big data projects?</args></response>]\n",
      "[22] of [1000] [2.2%] [Google Scholar Managing data quality with Pandas in current window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Managing data quality with Pandas</args></response>]\n",
      "[23] of [1000] [2.3%] [Look for File Exists Error in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>File Exists Error</args></response>]\n",
      "[24] of [1000] [2.4%] [Buffer Error Google search in a fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Buffer Error</args></response>]\n",
      "[25] of [1000] [2.5%] [Search in this window for PyTorch vs. TensorFlow comparison]\n",
      "[<response><browser-command>search current tab</browser-command><args>PyTorch vs. TensorFlow comparison</args></response>]\n",
      "[26] of [1000] [2.6%] [New tab: search Google Scholar for Combining datasets with Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Combining datasets with Pandas</args></response>]\n",
      "[27] of [1000] [2.7%] [Run Google Scholar for Unicode Warning: Unicode related warning, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Unicode Warning: Unicode related warning</args></response>]\n",
      "[28] of [1000] [2.8%] [Explore Hadoop MapReduce tutorial: Where can you find a beginner-friendly tutorial for Hadoop MapReduce? in the current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Hadoop MapReduce tutorial: Where can you find a beginner-friendly tutorial for Hadoop MapReduce?</args></response>]\n",
      "[29] of [1000] [2.9%] [Execute Google Scholar search for Stream Processing with Kafka: What are the advantages of using Apache Kafka for stream processing? in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Stream Processing with Kafka: What are the advantages of using Apache Kafka for stream processing?</args></response>]\n",
      "[30] of [1000] [3.0%] [Search Syntax Error: Invalid syntax, display in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Syntax Error: Invalid syntax</args></response>]\n",
      "[31] of [1000] [3.1%] [New tab: commence Deep Reinforcement Learning: What are some of the breakthroughs achieved with deep reinforcement learning in recent years? search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Deep Reinforcement Learning: What are some of the breakthroughs achieved with deep reinforcement learning in recent years?</args></response>]\n",
      "[32] of [1000] [3.2%] [Search learning Japanese online in another window]\n",
      "[<response><browser-command>search new tab</browser-command><args>learning Japanese online</args></response>]\n",
      "[33] of [1000] [3.3%] [This tab, run Google Scholar search on Java for beginners]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Java for beginners</args></response>]\n",
      "[34] of [1000] [3.4%] [Run a Google Scholar search for How can assertion errors be used effectively for debugging in Python, and how are they resolved? and show in new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>How can assertion errors be used effectively for debugging in Python, and how are they resolved?</args></response>]\n",
      "[35] of [1000] [3.5%] [This screen, Google Scholar Pandas and regular expressions]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Pandas and regular expressions</args></response>]\n",
      "[36] of [1000] [3.6%] [Search google how to apply for a job in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to apply for a job</args></response>]\n",
      "[37] of [1000] [3.7%] [Find Deprecation Warning and display results in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Deprecation Warning</args></response>]\n",
      "[38] of [1000] [3.8%] [Initiate ZeroDivisionError search in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>ZeroDivisionError</args></response>]\n",
      "[39] of [1000] [3.9%] [Locate how to cook a turkey results in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>how to cook a turkey</args></response>]\n",
      "[40] of [1000] [4.0%] [Google Scholar top 10 video games of all time, please]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>top 10 video games of all time</args></response>]\n",
      "[41] of [1000] [4.1%] [In a new tab, perform a Google search of Bytes Warning: Bytecode issue]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Bytes Warning: Bytecode issue</args></response>]\n",
      "[42] of [1000] [4.2%] [In a fresh tab, conduct a Google search on UserWarning]\n",
      "[<response><browser-command>search google new tab</browser-command><args>UserWarning</args></response>]\n",
      "[43] of [1000] [4.3%] [Bring up Google Scholar, current news in tech, in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>current news in tech</args></response>]\n",
      "[44] of [1000] [4.4%] [Google Scholar BlockingIOError, initiate in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>BlockingIOError</args></response>]\n",
      "[45] of [1000] [4.5%] [Let's do a Google Scholar search for AI in smart cities, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI in smart cities</args></response>]\n",
      "[46] of [1000] [4.6%] [Search Connection Error, new tab please]\n",
      "[<response><browser-command>search new tab</browser-command><args>Connection Error</args></response>]\n",
      "[47] of [1000] [4.7%] [Execute Google search for latest developments in AI, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>latest developments in AI</args></response>]\n",
      "[48] of [1000] [4.8%] [Take me to Google Scholar's RuntimeWarning]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>RuntimeWarning</args></response>]\n",
      "[49] of [1000] [4.9%] [Make an enquiry for Overflow Error: Value too large to convert and display the output]\n",
      "[<response><browser-command>search current tab</browser-command><args>Overflow Error: Value too large to convert</args></response>]\n",
      "[50] of [1000] [5.0%] [Show me Big Data analysis techniques in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Big Data analysis techniques</args></response>]\n",
      "[51] of [1000] [5.1%] [Render Google search results for UserWarning in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>UserWarning</args></response>]\n",
      "[52] of [1000] [5.2%] [New tab, conduct Google lookup on Unicode Translate Error]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Unicode Translate Error</args></response>]\n",
      "[53] of [1000] [5.3%] [In a fresh tab, Google search for User Warning]\n",
      "[<response><browser-command>search google new tab</browser-command><args>User Warning</args></response>]\n",
      "[54] of [1000] [5.4%] [Initiate a new tab, then Google search buying a new laptop]\n",
      "[<response><browser-command>search google new tab</browser-command><args>buying a new laptop</args></response>]\n",
      "[55] of [1000] [5.5%] [Search Hadoop MapReduce tutorial, new tab please]\n",
      "[<response><browser-command>search new tab</browser-command><args>Hadoop MapReduce tutorial</args></response>]\n",
      "[56] of [1000] [5.6%] [Please conduct a Google Scholar search for TimeoutError in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>TimeoutError</args></response>]\n",
      "[57] of [1000] [5.7%] [Run Google Scholar for Azure Machine Learning platform: What features does the Azure Machine Learning platform provide for model deployment?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Azure Machine Learning platform: What features does the Azure Machine Learning platform provide for model deployment?</args></response>]\n",
      "[58] of [1000] [5.8%] [Commence a Google Scholar search for Visualizing data with Pandas in this window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Visualizing data with Pandas</args></response>]\n",
      "[59] of [1000] [5.9%] [Connection Error, Google Scholar now]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Connection Error</args></response>]\n",
      "[60] of [1000] [6.0%] [Could you search Random Forest in another tab?]\n",
      "[<response><browser-command>search new tab</browser-command><args>Random Forest</args></response>]\n",
      "[61] of [1000] [6.1%] [Locate How do you address resource-related warnings in Python, especially regarding resource usage? in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>How do you address resource-related warnings in Python, especially regarding resource usage?</args></response>]\n",
      "[62] of [1000] [6.2%] [Delve for User Warning: User-defined warning in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>User Warning: User-defined warning</args></response>]\n",
      "[63] of [1000] [6.3%] [Google Scholar Import Warning: Module import issue, open new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Import Warning: Module import issue</args></response>]\n",
      "[64] of [1000] [6.4%] [Scope out current global news on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>current global news</args></response>]\n",
      "[65] of [1000] [6.5%] [Search and provide results for What are buffer-related errors in Python, and how can they be resolved? here]\n",
      "[<response><browser-command>search current tab</browser-command><args>What are buffer-related errors in Python, and how can they be resolved?</args></response>]\n",
      "[66] of [1000] [6.6%] [Carry out a Google search for latest space exploration news in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>latest space exploration news</args></response>]\n",
      "[67] of [1000] [6.7%] [Launch a Google query for Working with datetime in Pandas in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Working with datetime in Pandas</args></response>]\n",
      "[68] of [1000] [6.8%] [Google search for How do you address resource-related warnings in Python, especially regarding resource usage?, show results in a fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How do you address resource-related warnings in Python, especially regarding resource usage?</args></response>]\n",
      "[69] of [1000] [6.9%] [Go to Google Scholar and search for Unicode Warning, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Unicode Warning</args></response>]\n",
      "[70] of [1000] [7.0%] [Find Ethical AI guidelines: What are some of the key guidelines for ethical AI development? and display results in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Ethical AI guidelines: What are some of the key guidelines for ethical AI development?</args></response>]\n",
      "[71] of [1000] [7.1%] [Look up Google Scholar for what is renewable energy?, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>what is renewable energy?</args></response>]\n",
      "[72] of [1000] [7.2%] [Present google results of Warning on current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Warning</args></response>]\n",
      "[73] of [1000] [7.3%] [In a fresh tab, begin a Google search for how to stay motivated]\n",
      "[<response><browser-command>search google new tab</browser-command><args>how to stay motivated</args></response>]\n",
      "[74] of [1000] [7.4%] [Show why do apples turn brown findings in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>why do apples turn brown</args></response>]\n",
      "[75] of [1000] [7.5%] [Perform a Google Scholar search in a new tab for popular podcasts]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>popular podcasts</args></response>]\n",
      "[76] of [1000] [7.6%] [Render Google search results for How can you resolve recursion errors due to excessive recursive calls in Python? in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How can you resolve recursion errors due to excessive recursive calls in Python?</args></response>]\n",
      "[77] of [1000] [7.7%] [Google Performance tuning in Pandas and display in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Performance tuning in Pandas</args></response>]\n",
      "[78] of [1000] [7.8%] [Initiate a Google search in a new tab for UnicodeTranslateError]\n",
      "[<response><browser-command>search google new tab</browser-command><args>UnicodeTranslateError</args></response>]\n",
      "[79] of [1000] [7.9%] [Can we search easy dinner recipes in a new tab?]\n",
      "[<response><browser-command>search new tab</browser-command><args>easy dinner recipes</args></response>]\n",
      "[80] of [1000] [8.0%] [Seek SyntaxWarning on Google in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>SyntaxWarning</args></response>]\n",
      "[81] of [1000] [8.1%] [Execute AI in retail analytics search in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in retail analytics</args></response>]\n",
      "[82] of [1000] [8.2%] [Please open a new tab and search AI in virtual reality]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in virtual reality</args></response>]\n",
      "[83] of [1000] [8.3%] [Open a new tab for Google Scholar and search ResourceWarning]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ResourceWarning</args></response>]\n",
      "[84] of [1000] [8.4%] [Look up how to make pizza dough in current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>how to make pizza dough</args></response>]\n",
      "[85] of [1000] [8.5%] [Launch a new tab, perform a Google search for Machine Learning in biotech]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Machine Learning in biotech</args></response>]\n",
      "[86] of [1000] [8.6%] [Tab search for Column-wise operations in Pandas]\n",
      "[<response><browser-command>search current tab</browser-command><args>Column-wise operations in Pandas</args></response>]\n",
      "[87] of [1000] [8.7%] [Commence Google Scholar System Error]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>System Error</args></response>]\n",
      "[88] of [1000] [8.8%] [Browse for AI in insurance underwriting on Google in this window]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in insurance underwriting</args></response>]\n",
      "[89] of [1000] [8.9%] [Please run a Google Scholar search in a new tab for BERT architecture: How has the BERT architecture advanced the field of natural language understanding?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>BERT architecture: How has the BERT architecture advanced the field of natural language understanding?</args></response>]\n",
      "[90] of [1000] [9.0%] [Research OSError on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>OSError</args></response>]\n",
      "[91] of [1000] [9.1%] [Carry out a Google search for Using Pandas in data science projects in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Using Pandas in data science projects</args></response>]\n",
      "[92] of [1000] [9.2%] [Look into Out Of Bounds Datetime: Out of bounds nanosecond timestamp on Google from this site]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Out Of Bounds Datetime: Out of bounds nanosecond timestamp</args></response>]\n",
      "[93] of [1000] [9.3%] [Open new tab, search for latest space exploration news]\n",
      "[<response><browser-command>search new tab</browser-command><args>latest space exploration news</args></response>]\n",
      "[94] of [1000] [9.4%] [In this tab, Google the terms Data partitioning in Pandas]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Data partitioning in Pandas</args></response>]\n",
      "[95] of [1000] [9.5%] [Probe AI in manufacturing in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI in manufacturing</args></response>]\n",
      "[96] of [1000] [9.6%] [Kindly start AI in supply chain optimization search in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in supply chain optimization</args></response>]\n",
      "[97] of [1000] [9.7%] [New tab, perform Google Scholar search for Custom sorting in Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Custom sorting in Pandas</args></response>]\n",
      "[98] of [1000] [9.8%] [Pull up healthy lunch ideas in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>healthy lunch ideas</args></response>]\n",
      "[99] of [1000] [9.9%] [Google Reference Error, show in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Reference Error</args></response>]\n",
      "[100] of [1000] [10.0%] [Perform a new tab search on Google Scholar for Using Pandas in data science projects]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Using Pandas in data science projects</args></response>]\n",
      "[101] of [1000] [10.1%] [Google Scholar best fashion trends this year, open new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>best fashion trends this year</args></response>]\n",
      "[102] of [1000] [10.2%] [Seek AI in smart cities: How are smart cities utilizing AI to improve urban living? in a fresh tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in smart cities: How are smart cities utilizing AI to improve urban living?</args></response>]\n",
      "[103] of [1000] [10.3%] [Let's do a Google Scholar search for Deep Reinforcement Learning: What are some of the breakthroughs achieved with deep reinforcement learning in recent years?, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Deep Reinforcement Learning: What are some of the breakthroughs achieved with deep reinforcement learning in recent years?</args></response>]\n",
      "[104] of [1000] [10.4%] [Let's initiate Empty Data Error: No columns to parse from file search in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Empty Data Error: No columns to parse from file</args></response>]\n",
      "[105] of [1000] [10.5%] [Perform Google search for DIY home improvement projects]\n",
      "[<response><browser-command>search google current tab</browser-command><args>DIY home improvement projects</args></response>]\n",
      "[106] of [1000] [10.6%] [Go fetch running shoes review on Google Scholar, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>running shoes review</args></response>]\n",
      "[107] of [1000] [10.7%] [Search for DeprecationWarning, new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>DeprecationWarning</args></response>]\n",
      "[108] of [1000] [10.8%] [Run a new tab and Google Scholar How can you detect and resolve syntax errors that occur due to incorrect structure or typos in Python code?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>How can you detect and resolve syntax errors that occur due to incorrect structure or typos in Python code?</args></response>]\n",
      "[109] of [1000] [10.9%] [Open a new tab, find Filtering data in Pandas DataFrame on Google Scholar]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Filtering data in Pandas DataFrame</args></response>]\n",
      "[110] of [1000] [11.0%] [Here, find Blocking IO Error]\n",
      "[<response><browser-command>search current tab</browser-command><args>Blocking IO Error</args></response>]\n",
      "[111] of [1000] [11.1%] [Go fetch Deep Learning in genomics on Google Scholar, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Deep Learning in genomics</args></response>]\n",
      "[112] of [1000] [11.2%] [Find AI in human resources on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in human resources</args></response>]\n",
      "[113] of [1000] [11.3%] [Look into AI in healthcare applications: How is AI transforming healthcare applications? on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in healthcare applications: How is AI transforming healthcare applications?</args></response>]\n",
      "[114] of [1000] [11.4%] [Open new tab: find ModuleNotFoundError]\n",
      "[<response><browser-command>search new tab</browser-command><args>ModuleNotFoundError</args></response>]\n",
      "[115] of [1000] [11.5%] [Perform Reference Error search on Google Scholar in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Reference Error</args></response>]\n",
      "[116] of [1000] [11.6%] [Please begin a Google search for ConnectionResetError in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>ConnectionResetError</args></response>]\n",
      "[117] of [1000] [11.7%] [Google Scholar Pandas and Matplotlib integration, show it]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Pandas and Matplotlib integration</args></response>]\n",
      "[118] of [1000] [11.8%] [Google Scholar, start with AI in energy management: How does AI contribute to efficient energy management?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in energy management: How does AI contribute to efficient energy management?</args></response>]\n",
      "[119] of [1000] [11.9%] [Open a fresh tab, Google search AI in healthcare applications]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in healthcare applications</args></response>]\n",
      "[120] of [1000] [12.0%] [Start a Google search for what is the stock market? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>what is the stock market?</args></response>]\n",
      "[121] of [1000] [12.1%] [Begin a new tab and search for easy recipes for breakfast]\n",
      "[<response><browser-command>search new tab</browser-command><args>easy recipes for breakfast</args></response>]\n",
      "[122] of [1000] [12.2%] [Show me google scholar results for what is the meaning of love? in this tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>what is the meaning of love?</args></response>]\n",
      "[123] of [1000] [12.3%] [Execute new tab, search for AI-driven predictive maintenance]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI-driven predictive maintenance</args></response>]\n",
      "[124] of [1000] [12.4%] [Initiate AI in supply chain optimization: How does AI contribute to supply chain optimization? search, new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in supply chain optimization: How does AI contribute to supply chain optimization?</args></response>]\n",
      "[125] of [1000] [12.5%] [New tab, carry out Google search on Unicode Warning: Unicode related warning]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Unicode Warning: Unicode related warning</args></response>]\n",
      "[126] of [1000] [12.6%] [New tab, carry out Google search on how to roast coffee beans]\n",
      "[<response><browser-command>search google new tab</browser-command><args>how to roast coffee beans</args></response>]\n",
      "[127] of [1000] [12.7%] [Look up best hiking gear on Google here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>best hiking gear</args></response>]\n",
      "[128] of [1000] [12.8%] [Execute search for Syntax Warning: Syntax issue warning in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Syntax Warning: Syntax issue warning</args></response>]\n",
      "[129] of [1000] [12.9%] [Search and open best travel destinations in Asia in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>best travel destinations in Asia</args></response>]\n",
      "[130] of [1000] [13.0%] [Launch Google Scholar search for URL Error in the present tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>URL Error</args></response>]\n",
      "[131] of [1000] [13.1%] [Open a new tab, find IOError]\n",
      "[<response><browser-command>search new tab</browser-command><args>IOError</args></response>]\n",
      "[132] of [1000] [13.2%] [FloatingPointError on Google Scholar, let's go]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>FloatingPointError</args></response>]\n",
      "[133] of [1000] [13.3%] [Please launch a Google search for Handling categorical data in Pandas in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Handling categorical data in Pandas</args></response>]\n",
      "[134] of [1000] [13.4%] [Google Scholar How do you address Unicode-related errors in Python, especially in string handling?, pull up in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>How do you address Unicode-related errors in Python, especially in string handling?</args></response>]\n",
      "[135] of [1000] [13.5%] [Open a fresh tab, Google search What are bytes warnings in Python, and how are they significant in data handling?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>What are bytes warnings in Python, and how are they significant in data handling?</args></response>]\n",
      "[136] of [1000] [13.6%] [Browse Google Scholar for Saving Pandas DataFrame to CSV in the current tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Saving Pandas DataFrame to CSV</args></response>]\n",
      "[137] of [1000] [13.7%] [Open a new tab and fetch Google Scholar results for latest space exploration news]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>latest space exploration news</args></response>]\n",
      "[138] of [1000] [13.8%] [Go fetch Pending Deprecation Warning on Google Scholar, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Pending Deprecation Warning</args></response>]\n",
      "[139] of [1000] [13.9%] [Google Scholar Image Recognition technologies: How have image recognition technologies evolved in recent years?, find it]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Image Recognition technologies: How have image recognition technologies evolved in recent years?</args></response>]\n",
      "[140] of [1000] [14.0%] [Generate a new tab, search what is the capital of Australia?]\n",
      "[<response><browser-command>search new tab</browser-command><args>what is the capital of Australia?</args></response>]\n",
      "[141] of [1000] [14.1%] [Perform a Google inspection for OSError]\n",
      "[<response><browser-command>search google current tab</browser-command><args>OSError</args></response>]\n",
      "[142] of [1000] [14.2%] [Browse Google Scholar for how to care for succulents in the current tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how to care for succulents</args></response>]\n",
      "[143] of [1000] [14.3%] [Run Google Scholar for Handling JSON data in Pandas, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Handling JSON data in Pandas</args></response>]\n",
      "[144] of [1000] [14.4%] [Google Scholar Warning: General warning message in current window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Warning: General warning message</args></response>]\n",
      "[145] of [1000] [14.5%] [New tab, perform top 10 video games of all time search]\n",
      "[<response><browser-command>search new tab</browser-command><args>top 10 video games of all time</args></response>]\n",
      "[146] of [1000] [14.6%] [Conduct a Google lookup for How can you identify and correct undefined variables that lead to errors in Python? in a fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How can you identify and correct undefined variables that lead to errors in Python?</args></response>]\n",
      "[147] of [1000] [14.7%] [In this tab, locate Using apply and map in Pandas]\n",
      "[<response><browser-command>search current tab</browser-command><args>Using apply and map in Pandas</args></response>]\n",
      "[148] of [1000] [14.8%] [Current window, search for Computer Vision applications]\n",
      "[<response><browser-command>search current tab</browser-command><args>Computer Vision applications</args></response>]\n",
      "[149] of [1000] [14.9%] [In a new tab, please find Invalid Index Error: Reindexing only valid with uniquely valued Index objects]\n",
      "[<response><browser-command>search new tab</browser-command><args>Invalid Index Error: Reindexing only valid with uniquely valued Index objects</args></response>]\n",
      "[150] of [1000] [15.0%] [Look for AI in manufacturing: How is AI being used to revolutionize manufacturing processes? on Google Scholar in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI in manufacturing: How is AI being used to revolutionize manufacturing processes?</args></response>]\n",
      "[151] of [1000] [15.1%] [Carry out a Google lookup for Ethical AI guidelines: What are some of the key guidelines for ethical AI development?, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Ethical AI guidelines: What are some of the key guidelines for ethical AI development?</args></response>]\n",
      "[152] of [1000] [15.2%] [Investigate What are the causes of floating point errors in Python, and how can they be minimized? on Google from this area]\n",
      "[<response><browser-command>search google current tab</browser-command><args>What are the causes of floating point errors in Python, and how can they be minimized?</args></response>]\n",
      "[153] of [1000] [15.3%] [Perform a Google lookup for Custom sorting in Pandas, results in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Custom sorting in Pandas</args></response>]\n",
      "[154] of [1000] [15.4%] [Execute a Google Scholar search in a new tab for Deep Learning in genomics]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Deep Learning in genomics</args></response>]\n",
      "[155] of [1000] [15.5%] [AI in human resources, perform Google search in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in human resources</args></response>]\n",
      "[156] of [1000] [15.6%] [Google Scholar search in a new tab, User Warning]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>User Warning</args></response>]\n",
      "[157] of [1000] [15.7%] [Go to Google Scholar and search how to take care of a pet dog/cat/fish in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>how to take care of a pet dog/cat/fish</args></response>]\n",
      "[158] of [1000] [15.8%] [Google Scholar running shoes review, please]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>running shoes review</args></response>]\n",
      "[159] of [1000] [15.9%] [Research Reference Error: Weak reference object no longer exists using Google from this spot]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Reference Error: Weak reference object no longer exists</args></response>]\n",
      "[160] of [1000] [16.0%] [Google search in a new tab, keywords: Unicode Warning: Unicode related warning]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Unicode Warning: Unicode related warning</args></response>]\n",
      "[161] of [1000] [16.1%] [Show me AI-driven content generation results in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI-driven content generation</args></response>]\n",
      "[162] of [1000] [16.2%] [Fetch Google Scholar results for What steps can you take to prepare for features that will be deprecated in future Python releases? in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>What steps can you take to prepare for features that will be deprecated in future Python releases?</args></response>]\n",
      "[163] of [1000] [16.3%] [Explore Syntax Error in the current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Syntax Error</args></response>]\n",
      "[164] of [1000] [16.4%] [Start a Google search in a new tab for BufferError]\n",
      "[<response><browser-command>search google new tab</browser-command><args>BufferError</args></response>]\n",
      "[165] of [1000] [16.5%] [Start a Google Scholar search for Pandas DataFrame creation in this tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Pandas DataFrame creation</args></response>]\n",
      "[166] of [1000] [16.6%] [New tab with Google Scholar search for Reference Error: Weak reference object no longer exists]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Reference Error: Weak reference object no longer exists</args></response>]\n",
      "[167] of [1000] [16.7%] [Index Error: Index out of bounds, Google search, open in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Index Error: Index out of bounds</args></response>]\n",
      "[168] of [1000] [16.8%] [Perform a Google check for BytesWarning]\n",
      "[<response><browser-command>search google current tab</browser-command><args>BytesWarning</args></response>]\n",
      "[169] of [1000] [16.9%] [Google Scholar Predictive analytics tools, open new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Predictive analytics tools</args></response>]\n",
      "[170] of [1000] [17.0%] [Execute a Google search for ResourceWarning]\n",
      "[<response><browser-command>search google current tab</browser-command><args>ResourceWarning</args></response>]\n",
      "[171] of [1000] [17.1%] [In this tab, Google Scholar how to improve public speaking skills]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how to improve public speaking skills</args></response>]\n",
      "[172] of [1000] [17.2%] [In a new tab, execute a Google search for Supervised vs. Unsupervised Learning: What are the key differences between supervised and unsupervised learning in AI?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Supervised vs. Unsupervised Learning: What are the key differences between supervised and unsupervised learning in AI?</args></response>]\n",
      "[173] of [1000] [17.3%] [Open new tab: learning Japanese online search]\n",
      "[<response><browser-command>search new tab</browser-command><args>learning Japanese online</args></response>]\n",
      "[174] of [1000] [17.4%] [Go Google How do you handle situations where a feature or method is not yet implemented in Python?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How do you handle situations where a feature or method is not yet implemented in Python?</args></response>]\n",
      "[175] of [1000] [17.5%] [Launch Google Scholar File Not Found Error: File not found or path is incorrect]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>File Not Found Error: File not found or path is incorrect</args></response>]\n",
      "[176] of [1000] [17.6%] [In this tab, Google the terms how to make money online]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to make money online</args></response>]\n",
      "[177] of [1000] [17.7%] [Search for how to start a blog, new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to start a blog</args></response>]\n",
      "[178] of [1000] [17.8%] [ZipFileError: Discover here]\n",
      "[<response><browser-command>search current tab</browser-command><args>ZipFileError</args></response>]\n",
      "[179] of [1000] [17.9%] [Scan User Warning: User-defined warning in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>User Warning: User-defined warning</args></response>]\n",
      "[180] of [1000] [18.0%] [Look up AI in virtual reality: How is AI enhancing virtual reality experiences? in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in virtual reality: How is AI enhancing virtual reality experiences?</args></response>]\n",
      "[181] of [1000] [18.1%] [Search for Outlier Detection methods, open in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Outlier Detection methods</args></response>]\n",
      "[182] of [1000] [18.2%] [Google Scholar Cross-Validation techniques: What are the benefits of using k-fold cross-validation in machine learning models?, now]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Cross-Validation techniques: What are the benefits of using k-fold cross-validation in machine learning models?</args></response>]\n",
      "[183] of [1000] [18.3%] [Search in this tab for why we feel pain]\n",
      "[<response><browser-command>search current tab</browser-command><args>why we feel pain</args></response>]\n",
      "[184] of [1000] [18.4%] [Google Scholar weather forecast washington dc, present window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>weather forecast washington dc</args></response>]\n",
      "[185] of [1000] [18.5%] [Get Google Scholar results for Setting and resetting index in Pandas here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Setting and resetting index in Pandas</args></response>]\n",
      "[186] of [1000] [18.6%] [Start what is the capital of France? search in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>what is the capital of France?</args></response>]\n",
      "[187] of [1000] [18.7%] [Conduct Apache Spark data processing: How does Apache Spark handle large-scale data processing efficiently? search in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Apache Spark data processing: How does Apache Spark handle large-scale data processing efficiently?</args></response>]\n",
      "[188] of [1000] [18.8%] [New tab, search Google for Import Warning]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Import Warning</args></response>]\n",
      "[189] of [1000] [18.9%] [Probe BufferError in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>BufferError</args></response>]\n",
      "[190] of [1000] [19.0%] [Google Scholar search for Windows Error, new tab please]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Windows Error</args></response>]\n",
      "[191] of [1000] [19.1%] [Use this tab to Google AI in public safety: How is AI being used to enhance public safety measures?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in public safety: How is AI being used to enhance public safety measures?</args></response>]\n",
      "[192] of [1000] [19.2%] [Let's look for Computer Vision applications in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Computer Vision applications</args></response>]\n",
      "[193] of [1000] [19.3%] [Google Scholar what is renewable energy?, begin]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>what is renewable energy?</args></response>]\n",
      "[194] of [1000] [19.4%] [Please initiate a Google search for Data munging with Pandas in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Data munging with Pandas</args></response>]\n",
      "[195] of [1000] [19.5%] [Conduct a Google search on Hadoop MapReduce tutorial in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Hadoop MapReduce tutorial</args></response>]\n",
      "[196] of [1000] [19.6%] [Error handling in Pandas, find and display]\n",
      "[<response><browser-command>search current tab</browser-command><args>Error handling in Pandas</args></response>]\n",
      "[197] of [1000] [19.7%] [Explore Floating Point Error on Google from this location]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Floating Point Error</args></response>]\n",
      "[198] of [1000] [19.8%] [Research BERT architecture: How has the BERT architecture advanced the field of natural language understanding? on Google from here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>BERT architecture: How has the BERT architecture advanced the field of natural language understanding?</args></response>]\n",
      "[199] of [1000] [19.9%] [Google Scholar Convolutional Neural Networks: What are the primary applications of convolutional neural networks in image processing?, execute]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Convolutional Neural Networks: What are the primary applications of convolutional neural networks in image processing?</args></response>]\n",
      "[200] of [1000] [20.0%] [Do a Google search of Performance tuning in Pandas in a fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Performance tuning in Pandas</args></response>]\n",
      "[201] of [1000] [20.1%] [Please show Google Scholar results for AI-driven fraud detection: How is AI being used to detect and prevent fraud? in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI-driven fraud detection: How is AI being used to detect and prevent fraud?</args></response>]\n",
      "[202] of [1000] [20.2%] [Research Unbound Local Error: Local variable referenced before assignment using Google from this spot]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Unbound Local Error: Local variable referenced before assignment</args></response>]\n",
      "[203] of [1000] [20.3%] [Perform Custom aggregation in Pandas search, open new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Custom aggregation in Pandas</args></response>]\n",
      "[204] of [1000] [20.4%] [Query Google with Pandas and regular expressions and display in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Pandas and regular expressions</args></response>]\n",
      "[205] of [1000] [20.5%] [Examine How can overflow errors be detected and handled in Python, especially with numerical operations? via Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How can overflow errors be detected and handled in Python, especially with numerical operations?</args></response>]\n",
      "[206] of [1000] [20.6%] [New tab: run top 10 songs on Billboard charts search]\n",
      "[<response><browser-command>search new tab</browser-command><args>top 10 songs on Billboard charts</args></response>]\n",
      "[207] of [1000] [20.7%] [Transformer architecture research: What are the latest research developments in Transformer architectures?: Look up in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Transformer architecture research: What are the latest research developments in Transformer architectures?</args></response>]\n",
      "[208] of [1000] [20.8%] [Kindly look for Unicode Encode Error in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Unicode Encode Error</args></response>]\n",
      "[209] of [1000] [20.9%] [AI in retail analytics: How is AI transforming retail analytics and customer insights? in Google Scholar, please]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in retail analytics: How is AI transforming retail analytics and customer insights?</args></response>]\n",
      "[210] of [1000] [21.0%] [Search in a new tab: How can you resolve recursion errors due to excessive recursive calls in Python?]\n",
      "[<response><browser-command>search new tab</browser-command><args>How can you resolve recursion errors due to excessive recursive calls in Python?</args></response>]\n",
      "[211] of [1000] [21.1%] [Examine What are runtime warnings in Python, and how can they be used to identify potential issues? on Google in this space]\n",
      "[<response><browser-command>search google current tab</browser-command><args>What are runtime warnings in Python, and how can they be used to identify potential issues?</args></response>]\n",
      "[212] of [1000] [21.2%] [Google Syntax Warning and present it on this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Syntax Warning</args></response>]\n",
      "[213] of [1000] [21.3%] [This tab: Search for searching for vegan recipes]\n",
      "[<response><browser-command>search current tab</browser-command><args>searching for vegan recipes</args></response>]\n",
      "[214] of [1000] [21.4%] [Buffer Error, Google it, open in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Buffer Error</args></response>]\n",
      "[215] of [1000] [21.5%] [Show Google search results of Azure Machine Learning platform: What features does the Azure Machine Learning platform provide for model deployment? in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Azure Machine Learning platform: What features does the Azure Machine Learning platform provide for model deployment?</args></response>]\n",
      "[216] of [1000] [21.6%] [Google Scholar how to deal with stress, show here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how to deal with stress</args></response>]\n",
      "[217] of [1000] [21.7%] [Perform a Google lookup for Natural Language Understanding: What advances have been made in natural language understanding with AI?, results in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Natural Language Understanding: What advances have been made in natural language understanding with AI?</args></response>]\n",
      "[218] of [1000] [21.8%] [Google AI in smart cities, display results in a new window]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in smart cities</args></response>]\n",
      "[219] of [1000] [21.9%] [Conduct a search for Pending Deprecation Warning in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Pending Deprecation Warning</args></response>]\n",
      "[220] of [1000] [22.0%] [Initiate a search for how to meditate on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to meditate</args></response>]\n",
      "[221] of [1000] [22.1%] [Search Google Scholar for Federated Learning: How does federated learning work, and what are its advantages? in a new tab, please]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Federated Learning: How does federated learning work, and what are its advantages?</args></response>]\n",
      "[222] of [1000] [22.2%] [Find and display Syntax Warning: Syntax issue warning results]\n",
      "[<response><browser-command>search current tab</browser-command><args>Syntax Warning: Syntax issue warning</args></response>]\n",
      "[223] of [1000] [22.3%] [Commence a Google Scholar search for What steps can you take to prepare for features that will be deprecated in future Python releases? in this window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What steps can you take to prepare for features that will be deprecated in future Python releases?</args></response>]\n",
      "[224] of [1000] [22.4%] [In a fresh tab, begin a Google search for AI in gaming]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in gaming</args></response>]\n",
      "[225] of [1000] [22.5%] [Research Syntax Error: Invalid syntax and present results]\n",
      "[<response><browser-command>search current tab</browser-command><args>Syntax Error: Invalid syntax</args></response>]\n",
      "[226] of [1000] [22.6%] [Browse Google Scholar for Responsible AI practices]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Responsible AI practices</args></response>]\n",
      "[227] of [1000] [22.7%] [How do you handle warnings related to Unicode issues in Python? search, this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>How do you handle warnings related to Unicode issues in Python?</args></response>]\n",
      "[228] of [1000] [22.8%] [Google Scholar Pandas and regular expressions, start]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Pandas and regular expressions</args></response>]\n",
      "[229] of [1000] [22.9%] [Open Google Scholar search results for online yoga classes in current view]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>online yoga classes</args></response>]\n",
      "[230] of [1000] [23.0%] [Run Google search on what is climate change and its effects? and display in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>what is climate change and its effects?</args></response>]\n",
      "[231] of [1000] [23.1%] [Get Google Scholar to search ConnectionResetError, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ConnectionResetError</args></response>]\n",
      "[232] of [1000] [23.2%] [Commence Google Scholar search on What are import warnings in Python, and how can they be addressed? here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are import warnings in Python, and how can they be addressed?</args></response>]\n",
      "[233] of [1000] [23.3%] [Can you search for How do you fix indentation errors that affect code structure in Python? in a new tab?]\n",
      "[<response><browser-command>search new tab</browser-command><args>How do you fix indentation errors that affect code structure in Python?</args></response>]\n",
      "[234] of [1000] [23.4%] [Google Scholar AI-driven chatbots: How are AI-driven chatbots enhancing customer service experiences?, start]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI-driven chatbots: How are AI-driven chatbots enhancing customer service experiences?</args></response>]\n",
      "[235] of [1000] [23.5%] [Now, Google Scholar File Exists Error]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>File Exists Error</args></response>]\n",
      "[236] of [1000] [23.6%] [In a new tab, conduct a Google search for AI in agriculture technology]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in agriculture technology</args></response>]\n",
      "[237] of [1000] [23.7%] [Display in a new tab: Google Scholar results for Dealing with outliers in Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Dealing with outliers in Pandas</args></response>]\n",
      "[238] of [1000] [23.8%] [Google Scholar Real-time data streaming in current window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Real-time data streaming</args></response>]\n",
      "[239] of [1000] [23.9%] [Search, find, and display  here]\n",
      "[<response><browser-command>search current tab</browser-command><args>search, find, and display</args></response>]\n",
      "[240] of [1000] [24.0%] [In a fresh tab, begin a Google search for shopping for groceries online]\n",
      "[<response><browser-command>search google new tab</browser-command><args>shopping for groceries online</args></response>]\n",
      "[241] of [1000] [24.1%] [Please conduct a Google Scholar search for How do you troubleshoot name errors that occur when a variable or function name is not recognized in the Python scope? in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>How do you troubleshoot name errors that occur when a variable or function name is not recognized in the Python scope?</args></response>]\n",
      "[242] of [1000] [24.2%] [Begin a new tab and search for FloatingPointError]\n",
      "[<response><browser-command>search new tab</browser-command><args>FloatingPointError</args></response>]\n",
      "[243] of [1000] [24.3%] [Google Scholar, I want to see What approaches can be taken to fix attribute errors that arise when an attribute or method is not found on an object in Python?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What approaches can be taken to fix attribute errors that arise when an attribute or method is not found on an object in Python?</args></response>]\n",
      "[244] of [1000] [24.4%] [Look up KeyError in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>KeyError</args></response>]\n",
      "[245] of [1000] [24.5%] [Look up How do you address Unicode-related errors in Python, especially in string handling? on Google Scholar in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>How do you address Unicode-related errors in Python, especially in string handling?</args></response>]\n",
      "[246] of [1000] [24.6%] [Open a new tab, find Value Error: Invalid value to set]\n",
      "[<response><browser-command>search new tab</browser-command><args>Value Error: Invalid value to set</args></response>]\n",
      "[247] of [1000] [24.7%] [Current tab: Execute how to find a job online search]\n",
      "[<response><browser-command>search current tab</browser-command><args>how to find a job online</args></response>]\n",
      "[248] of [1000] [24.8%] [DIY home improvement projects, perform Google search in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>DIY home improvement projects</args></response>]\n",
      "[249] of [1000] [24.9%] [Scan for How can system exit errors be handled gracefully in Python applications? on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How can system exit errors be handled gracefully in Python applications?</args></response>]\n",
      "[250] of [1000] [25.0%] [Let's look for top 10 songs on Billboard charts in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>top 10 songs on Billboard charts</args></response>]\n",
      "[251] of [1000] [25.1%] [Launch a Google search for AI for health diagnostics: How does AI contribute to advancements in health diagnostics? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI for health diagnostics: How does AI contribute to advancements in health diagnostics?</args></response>]\n",
      "[252] of [1000] [25.2%] [Pull up NoSQL databases for AI: Why are NoSQL databases often preferred in AI and machine learning projects? in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>NoSQL databases for AI: Why are NoSQL databases often preferred in AI and machine learning projects?</args></response>]\n",
      "[253] of [1000] [25.3%] [Pull up User Warning results in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>User Warning</args></response>]\n",
      "[254] of [1000] [25.4%] [Unleash Google Scholar search on why leaves change color here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>why leaves change color</args></response>]\n",
      "[255] of [1000] [25.5%] [how to play guitar, Google search, fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>how to play guitar</args></response>]\n",
      "[256] of [1000] [25.6%] [New tab, initiate a Google search for best hiking gear]\n",
      "[<response><browser-command>search google new tab</browser-command><args>best hiking gear</args></response>]\n",
      "[257] of [1000] [25.7%] [Start Google Scholar search on easy dinner recipes]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>easy dinner recipes</args></response>]\n",
      "[258] of [1000] [25.8%] [Google Scholar Warning: General warning message, activate]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Warning: General warning message</args></response>]\n",
      "[259] of [1000] [25.9%] [Generate new tab, Reading CSV files in Pandas search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Reading CSV files in Pandas</args></response>]\n",
      "[260] of [1000] [26.0%] [Search google how to deal with stress in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to deal with stress</args></response>]\n",
      "[261] of [1000] [26.1%] [Execute Google search for FloatingPointError in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>FloatingPointError</args></response>]\n",
      "[262] of [1000] [26.2%] [Google DIY home improvement projects, open results in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>DIY home improvement projects</args></response>]\n",
      "[263] of [1000] [26.3%] [hip hop music, Google search, open in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>hip hop music</args></response>]\n",
      "[264] of [1000] [26.4%] [Search Google Scholar for Data anonymization in Pandas]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Data anonymization in Pandas</args></response>]\n",
      "[265] of [1000] [26.5%] [Perform a Google lookup for Voice Recognition technologies, results in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Voice Recognition technologies</args></response>]\n",
      "[266] of [1000] [26.6%] [Carry out a Google search in a new tab for Explainable AI: Why is explainable AI important, and how is it achieved?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Explainable AI: Why is explainable AI important, and how is it achieved?</args></response>]\n",
      "[267] of [1000] [26.7%] [Search Real-time data streaming: How do you handle real-time data streaming in big data projects? in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Real-time data streaming: How do you handle real-time data streaming in big data projects?</args></response>]\n",
      "[268] of [1000] [26.8%] [Google Scholar why does ice float, engage]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>why does ice float</args></response>]\n",
      "[269] of [1000] [26.9%] [Pull up Memory Error: Out of memory in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Memory Error: Out of memory</args></response>]\n",
      "[270] of [1000] [27.0%] [Probe for Bytes Warning: Bytecode issue in current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Bytes Warning: Bytecode issue</args></response>]\n",
      "[271] of [1000] [27.1%] [Probe InterruptedError on Google from here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>InterruptedError</args></response>]\n",
      "[272] of [1000] [27.2%] [Find Google Scholar results for Interrupted Error in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Interrupted Error</args></response>]\n",
      "[273] of [1000] [27.3%] [Can we search online yoga classes in a new tab?]\n",
      "[<response><browser-command>search new tab</browser-command><args>online yoga classes</args></response>]\n",
      "[274] of [1000] [27.4%] [Find Responsible AI practices: How can organizations implement responsible AI practices?, open in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Responsible AI practices: How can organizations implement responsible AI practices?</args></response>]\n",
      "[275] of [1000] [27.5%] [Let's look for how to deal with stress in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to deal with stress</args></response>]\n",
      "[276] of [1000] [27.6%] [Kindly open Voice Recognition technologies in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Voice Recognition technologies</args></response>]\n",
      "[277] of [1000] [27.7%] [Find Google Scholar results for GANs recent advancements in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>GANs recent advancements</args></response>]\n",
      "[278] of [1000] [27.8%] [Commence Google Scholar search on Process Lookup Error here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Process Lookup Error</args></response>]\n",
      "[279] of [1000] [27.9%] [New tab, carry out Google search on AI in autonomous vehicles: What role does AI play in the development of autonomous vehicles?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in autonomous vehicles: What role does AI play in the development of autonomous vehicles?</args></response>]\n",
      "[280] of [1000] [28.0%] [Search Google for AI in digital marketing: What role does AI play in digital marketing strategies?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in digital marketing: What role does AI play in digital marketing strategies?</args></response>]\n",
      "[281] of [1000] [28.1%] [Scan for Handling large datasets with Pandas in a fresh tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Handling large datasets with Pandas</args></response>]\n",
      "[282] of [1000] [28.2%] [Take me to Google Scholar's InvalidOperation]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>InvalidOperation</args></response>]\n",
      "[283] of [1000] [28.3%] [Google Scholar BytesWarning, engage]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>BytesWarning</args></response>]\n",
      "[284] of [1000] [28.4%] [Perform a Google inspection for How do you handle warnings related to Unicode issues in Python?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How do you handle warnings related to Unicode issues in Python?</args></response>]\n",
      "[285] of [1000] [28.5%] [Bring up Google Scholar SyntaxError in a fresh tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>SyntaxError</args></response>]\n",
      "[286] of [1000] [28.6%] [Reading Excel files with Pandas, let's do Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Reading Excel files with Pandas</args></response>]\n",
      "[287] of [1000] [28.7%] [Search Google for How can child process-related errors be managed and resolved in Python? in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How can child process-related errors be managed and resolved in Python?</args></response>]\n",
      "[288] of [1000] [28.8%] [New tab, lookup for How do you address resource-related warnings in Python, especially regarding resource usage?]\n",
      "[<response><browser-command>search new tab</browser-command><args>How do you address resource-related warnings in Python, especially regarding resource usage?</args></response>]\n",
      "[289] of [1000] [28.9%] [Investigate AI and blockchain integration via Google from here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI and blockchain integration</args></response>]\n",
      "[290] of [1000] [29.0%] [Get Google Scholar to search what is the meaning of life?, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>what is the meaning of life?</args></response>]\n",
      "[291] of [1000] [29.1%] [Investigate ProcessLookupError via Google from here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>ProcessLookupError</args></response>]\n",
      "[292] of [1000] [29.2%] [popular podcasts search, this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>popular podcasts</args></response>]\n",
      "[293] of [1000] [29.3%] [Could you please Google Scholar Unicode Warning: Unicode related warning in a new tab?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Unicode Warning: Unicode related warning</args></response>]\n",
      "[294] of [1000] [29.4%] [Please run a Google Scholar search in a new tab for Stop Iteration: Iteration stopped]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Stop Iteration: Iteration stopped</args></response>]\n",
      "[295] of [1000] [29.5%] [New tab and Google Scholar Integrating Pandas with APIs please]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Integrating Pandas with APIs</args></response>]\n",
      "[296] of [1000] [29.6%] [Find Google Scholar results for Resource Warning in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Resource Warning</args></response>]\n",
      "[297] of [1000] [29.7%] [In a fresh tab, perform a Google search of funny cat videos]\n",
      "[<response><browser-command>search google new tab</browser-command><args>funny cat videos</args></response>]\n",
      "[298] of [1000] [29.8%] [Conduct a Google lookup for healthy breakfast ideas in a fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>healthy breakfast ideas</args></response>]\n",
      "[299] of [1000] [29.9%] [Bring up Google Scholar AI Fairness and Bias mitigation in a fresh tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI Fairness and Bias mitigation</args></response>]\n",
      "[300] of [1000] [30.0%] [Current tab: Execute learning Japanese online search]\n",
      "[<response><browser-command>search current tab</browser-command><args>learning Japanese</args></response>]\n",
      "[301] of [1000] [30.1%] [Launch Google Scholar search for why we dream, current tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>why we dream</args></response>]\n",
      "[302] of [1000] [30.2%] [Explore why leaves change color on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>why leaves change color</args></response>]\n",
      "[303] of [1000] [30.3%] [Show me healthy lunch ideas on Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>healthy lunch ideas</args></response>]\n",
      "[304] of [1000] [30.4%] [Initiate search: SyntaxWarning, new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>SyntaxWarning</args></response>]\n",
      "[305] of [1000] [30.5%] [Search Google Scholar for Outlier Detection methods: What methods are most effective for outlier detection in univariate datasets?, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Outlier Detection methods: What methods are most effective for outlier detection in univariate datasets?</args></response>]\n",
      "[306] of [1000] [30.6%] [Open new tab: latest tech gadgets search]\n",
      "[<response><browser-command>search new tab</browser-command><args>latest tech gadgets</args></response>]\n",
      "[307] of [1000] [30.7%] [Show Google Scholar JavaScript libraries for beginners in the present tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>JavaScript libraries for beginners</args></response>]\n",
      "[308] of [1000] [30.8%] [In a new window, Google search for Data Science career trends]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Data Science career trends</args></response>]\n",
      "[309] of [1000] [30.9%] [Go to new tab, Google Scholar Runtime Error: Runtime exception occurred]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Runtime Error: Runtime exception occurred</args></response>]\n",
      "[310] of [1000] [31.0%] [Look into I need hiking gear via Google from this position]\n",
      "[<response><browser-command>search google current tab</browser-command><args>I need hiking gear</args></response>]\n",
      "[311] of [1000] [31.1%] [Start a new tab and perform Google Scholar search for ReferenceError]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ReferenceError</args></response>]\n",
      "[312] of [1000] [31.2%] [New tab, Google Bytes Warning: Bytecode issue]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Bytes Warning: Bytecode issue</args></response>]\n",
      "[313] of [1000] [31.3%] [Browse Google for Unsorted Index Error: Index is unsorted]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Unsorted Index Error: Index is unsorted</args></response>]\n",
      "[314] of [1000] [31.4%] [Perform a Google inquiry for Buffer Error]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Buffer Error</args></response>]\n",
      "[315] of [1000] [31.5%] [New tab, carry out Google search on Managing data quality with Pandas]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Managing data quality with Pandas</args></response>]\n",
      "[316] of [1000] [31.6%] [Execute new tab, search for AI in manufacturing]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in manufacturing</args></response>]\n",
      "[317] of [1000] [31.7%] [Get Google Scholar results for IndexError in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>IndexError</args></response>]\n",
      "[318] of [1000] [31.8%] [Show ROC Curve analysis: How is ROC curve analysis utilized to evaluate the performance of binary classifiers? search outcome in current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>ROC Curve analysis: How is ROC curve analysis utilized to evaluate the performance of binary classifiers?</args></response>]\n",
      "[319] of [1000] [31.9%] [PyTorch vs. TensorFlow comparison: Scan in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>PyTorch vs. TensorFlow comparison</args></response>]\n",
      "[320] of [1000] [32.0%] [Google for Natural Language Understanding: What advances have been made in natural language understanding with AI? in this viewport]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Natural Language Understanding: What advances have been made in natural language understanding with AI?</args></response>]\n",
      "[321] of [1000] [32.1%] [Display search results in a new tab, keywords: How can system exit errors be handled gracefully in Python applications?]\n",
      "[<response><browser-command>search new tab</browser-command><args>How can system exit errors be handled gracefully in Python applications?</args></response>]\n",
      "[322] of [1000] [32.2%] [Look up machine learning basics on Google here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>machine learning basics</args></response>]\n",
      "[323] of [1000] [32.3%] [Google Connection Error and show it here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Connection Error</args></response>]\n",
      "[324] of [1000] [32.4%] [Perform AI in insurance underwriting: How is AI changing the landscape of insurance underwriting? search, open new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in insurance underwriting: How is AI changing the landscape of insurance underwriting?</args></response>]\n",
      "[325] of [1000] [32.5%] [Show Google Scholar results for Zip File Error in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Zip File Error</args></response>]\n",
      "[326] of [1000] [32.6%] [In a new tab, carry out a Google search for Pandas DataFrame merging]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Pandas DataFrame merging</args></response>]\n",
      "[327] of [1000] [32.7%] [Explore Custom data readers in Pandas in the current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Custom data readers in Pandas</args></response>]\n",
      "[328] of [1000] [32.8%] [Make a Google search for AI in sports analytics, open in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in sports analytics</args></response>]\n",
      "[329] of [1000] [32.9%] [Initiate Google Scholar search for Future Warning: Future change warning in this tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Future Warning: Future change warning</args></response>]\n",
      "[330] of [1000] [33.0%] [Start a Google search in a new tab for What are runtime warnings in Python, and how can they be used to identify potential issues?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>What are runtime warnings in Python, and how can they be used to identify potential issues?</args></response>]\n",
      "[331] of [1000] [33.1%] [Seek out Merge Error: No common columns to perform merge on using Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Merge Error: No common columns to perform merge on</args></response>]\n",
      "[332] of [1000] [33.2%] [Look into best hiking backpacks on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>best hiking backpacks</args></response>]\n",
      "[333] of [1000] [33.3%] [Perform Image Recognition technologies search in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Image Recognition technologies</args></response>]\n",
      "[334] of [1000] [33.4%] [Show video games findings in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>video games findings</args></response>]\n",
      "[335] of [1000] [33.5%] [Find how to deal with stress in the current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>how to deal with stress</args></response>]\n",
      "[336] of [1000] [33.6%] [Bring up Google Scholar Memory Error in a fresh tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Memory Error</args></response>]\n",
      "[337] of [1000] [33.7%] [Google Recursion Error: Maximum recursion depth exceeded in the current browser tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Recursion Error: Maximum recursion depth exceeded</args></response>]\n",
      "[338] of [1000] [33.8%] [Commence ImportWarning search in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>ImportWarning</args></response>]\n",
      "[339] of [1000] [33.9%] [In a fresh tab, start a Google search for classic rock music]\n",
      "[<response><browser-command>search google new tab</browser-command><args>classic rock music</args></response>]\n",
      "[340] of [1000] [34.0%] [Let's do a Google Scholar search for Voice Recognition technologies: What are the latest advancements in voice recognition technology?, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Voice Recognition technologies: What are the latest advancements in voice recognition technology?</args></response>]\n",
      "[341] of [1000] [34.1%] [Do a Google search, keywords: Memory Error]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Memory Error</args></response>]\n",
      "[342] of [1000] [34.2%] [New tab, carry out Google search on Advanced plotting with Pandas]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Advanced plotting with Pandas</args></response>]\n",
      "[343] of [1000] [34.3%] [Search and show Time series analysis in Pandas in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Time series analysis in Pandas</args></response>]\n",
      "[344] of [1000] [34.4%] [Look up What steps can be taken to resolve encoding issues with Unicode characters in Python? in current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>What steps can be taken to resolve encoding issues with Unicode characters in Python?</args></response>]\n",
      "[345] of [1000] [34.5%] [Open a new tab, then Google Scholar Data Visualization tools]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Data Visualization tools</args></response>]\n",
      "[346] of [1000] [34.6%] [New tab, initiate current environmental issues search]\n",
      "[<response><browser-command>search new tab</browser-command><args>current environmental issues</args></response>]\n",
      "[347] of [1000] [34.7%] [Google Scholar Memory Error, present window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Memory Error</args></response>]\n",
      "[348] of [1000] [34.8%] [Perform a Google inspection for TimeoutError]\n",
      "[<response><browser-command>search google current tab</browser-command><args>TimeoutError</args></response>]\n",
      "[349] of [1000] [34.9%] [Open Google, search AI in agriculture technology: How is AI being utilized in modern agricultural technology?, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in agriculture technology: How is AI being utilized in modern agricultural technology?</args></response>]\n",
      "[350] of [1000] [35.0%] [Initiate a search for Future Warning in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Future Warning</args></response>]\n",
      "[351] of [1000] [35.1%] [Google search for AI for customer service automation, show results in a fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI for customer service automation</args></response>]\n",
      "[352] of [1000] [35.2%] [Investigate Tab Error on Google from this area]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Tab Error</args></response>]\n",
      "[353] of [1000] [35.3%] [Execute Google Scholar search for ImportWarning here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>ImportWarning</args></response>]\n",
      "[354] of [1000] [35.4%] [Tab search: PyTorch vs. TensorFlow comparison]\n",
      "[<response><browser-command>search current tab</browser-command><args>PyTorch vs. TensorFlow comparison</args></response>]\n",
      "[355] of [1000] [35.5%] [Initiate search: searching for vegan recipes, new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>searching for vegan recipes</args></response>]\n",
      "[356] of [1000] [35.6%] [Generate new tab, how to tie a tie search]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to tie a tie</args></response>]\n",
      "[357] of [1000] [35.7%] [Search and provide results for ModuleNotFoundError here]\n",
      "[<response><browser-command>search current tab</browser-command><args>ModuleNotFoundError</args></response>]\n",
      "[358] of [1000] [35.8%] [Initiate AI-driven fraud detection search in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI-driven fraud detection</args></response>]\n",
      "[359] of [1000] [35.9%] [Scan for GANs recent advancements in a fresh tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>GANs recent advancements</args></response>]\n",
      "[360] of [1000] [36.0%] [Google How do you manage situations leading to an unexpected exit of generators in Python?, display results in a new window]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How do you manage situations leading to an unexpected exit of generators in Python?</args></response>]\n",
      "[361] of [1000] [36.1%] [Probe Unicode Warning: Unicode related warning using Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Unicode Warning: Unicode related warning</args></response>]\n",
      "[362] of [1000] [36.2%] [Locate AI for social good initiatives: What are some notable AI for social good initiatives? results in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI for social good initiatives: What are some notable AI for social good initiatives?</args></response>]\n",
      "[363] of [1000] [36.3%] [Start another tab and search for Future Warning: Future change warning]\n",
      "[<response><browser-command>search new tab</browser-command><args>Future Warning: Future change warning</args></response>]\n",
      "[364] of [1000] [36.4%] [Engage Google Scholar for Reading HTML tables with Pandas in current window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Reading HTML tables with Pandas</args></response>]\n",
      "[365] of [1000] [36.5%] [Please open a new tab and search Working with multi-dimensional data in Pandas]\n",
      "[<response><browser-command>search new tab</browser-command><args>Working with multi-dimensional data in Pandas</args></response>]\n",
      "[366] of [1000] [36.6%] [Perform a Google inquiry for Ruby on Rails tutorial]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Ruby on Rails tutorial</args></response>]\n",
      "[367] of [1000] [36.7%] [Display Convolutional Neural Networks: What are the primary applications of convolutional neural networks in image processing? results in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Convolutional Neural Networks: What are the primary applications of convolutional neural networks in image processing?</args></response>]\n",
      "[368] of [1000] [36.8%] [Execute new tab, search for Creating histograms in Pandas]\n",
      "[<response><browser-command>search new tab</browser-command><args>Creating histograms in Pandas</args></response>]\n",
      "[369] of [1000] [36.9%] [Please show Google Scholar results for Recurrent Neural Networks: How are recurrent neural networks uniquely suited for processing sequential data? in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Recurrent Neural Networks: How are recurrent neural networks uniquely suited for processing sequential data?</args></response>]\n",
      "[370] of [1000] [37.0%] [Seek and show Bytes Warning: Bytecode issue results here]\n",
      "[<response><browser-command>search current tab</browser-command><args>Bytes Warning: Bytecode issue</args></response>]\n",
      "[371] of [1000] [37.1%] [Run a search for Data conversion techniques in Pandas and show results in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Data conversion techniques in Pandas</args></response>]\n",
      "[372] of [1000] [37.2%] [Run a scan for Not Implemented Error: Method not implemented in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Not Implemented Error: Method not implemented</args></response>]\n",
      "[373] of [1000] [37.3%] [New tab, perform Google search on UnicodeEncodeError]\n",
      "[<response><browser-command>search google new tab</browser-command><args>UnicodeEncodeError</args></response>]\n",
      "[374] of [1000] [37.4%] [Kindly start UnicodeDecodeError search in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>UnicodeDecodeError</args></response>]\n",
      "[375] of [1000] [37.5%] [Look for Pending Deprecation Warning: Feature will be deprecated on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Pending Deprecation Warning: Feature will be deprecated</args></response>]\n",
      "[376] of [1000] [37.6%] [How can you handle reference errors, especially with weak references, in Python?, find and display]\n",
      "[<response><browser-command>search current tab</browser-command><args>How can you handle reference errors, especially with weak references, in Python?</args></response>]\n",
      "[377] of [1000] [37.7%] [Open a new tab and search Google for AI in agriculture technology]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in agriculture technology</args></response>]\n",
      "[378] of [1000] [37.8%] [Launch a Google lookup for why we dream in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>why we dream</args></response>]\n",
      "[379] of [1000] [37.9%] [Open new tab and perform OpenAI latest projects search]\n",
      "[<response><browser-command>search new tab</browser-command><args>OpenAI latest projects</args></response>]\n",
      "[380] of [1000] [38.0%] [Conduct a Google search on AI in climate change research]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in climate change research</args></response>]\n",
      "[381] of [1000] [38.1%] [Go Google why do dogs wag their tail]\n",
      "[<response><browser-command>search google current tab</browser-command><args>why do dogs wag their tail</args></response>]\n",
      "[382] of [1000] [38.2%] [In a new tab, Google search for Broken Pipe Error]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Broken Pipe Error</args></response>]\n",
      "[383] of [1000] [38.3%] [Start a new tab and perform Google Scholar search for Convolutional Neural Networks: What are the primary applications of convolutional neural networks in image processing?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Convolutional Neural Networks: What are the primary applications of convolutional neural networks in image processing?</args></response>]\n",
      "[384] of [1000] [38.4%] [Commence search for JavaScript vs Python in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>JavaScript vs Python</args></response>]\n",
      "[385] of [1000] [38.5%] [Value Error, Google search, fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Value Error</args></response>]\n",
      "[386] of [1000] [38.6%] [Execute Google Scholar how does electricity work?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how does electricity work?</args></response>]\n",
      "[387] of [1000] [38.7%] [Google Scholar search in a new tab, IBM Watson AI tools]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>IBM Watson AI tools</args></response>]\n",
      "[388] of [1000] [38.8%] [Search in new tab for python sort a list of strings]\n",
      "[<response><browser-command>search new tab</browser-command><args>python sort a list of strings</args></response>]\n",
      "[389] of [1000] [38.9%] [Execute Google Scholar search for Responsible AI practices in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Responsible AI practices</args></response>]\n",
      "[390] of [1000] [39.0%] [In the present tab, perform a Google Scholar search for Pending Deprecation Warning]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Pending Deprecation Warning</args></response>]\n",
      "[391] of [1000] [39.1%] [Search in this window for search new book releases]\n",
      "[<response><browser-command>search current tab</browser-command><args>search new book releases</args></response>]\n",
      "[392] of [1000] [39.2%] [Seek TensorFlow latest updates: What are the latest features added to TensorFlow in its most recent update? in a fresh tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>TensorFlow latest updates: What are the latest features added to TensorFlow in its most recent update?</args></response>]\n",
      "[393] of [1000] [39.3%] [Google Scholar Warning: General warning message, begin]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Warning: General warning message</args></response>]\n",
      "[394] of [1000] [39.4%] [Carry out a Google lookup for ImportError, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>ImportError</args></response>]\n",
      "[395] of [1000] [39.5%] [Search UnicodeWarning in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>UnicodeWarning</args></response>]\n",
      "[396] of [1000] [39.6%] [Execute In what scenarios do type mismatches occur, and how can they be resolved in Python? lookup in the current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>In what scenarios do type mismatches occur, and how can they be resolved in Python?</args></response>]\n",
      "[397] of [1000] [39.7%] [Please perform a Google search for What are the best practices for handling I/O blocking errors in Python? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>What are the best practices for handling I/O blocking errors in Python?</args></response>]\n",
      "[398] of [1000] [39.8%] [Carry out a search on Google for Cross-Validation techniques in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Cross-Validation techniques</args></response>]\n",
      "[399] of [1000] [39.9%] [Scour this tab for What are the common causes of runtime errors in Python, and how can they be debugged?]\n",
      "[<response><browser-command>search current tab</browser-command><args>What are the common causes of runtime errors in Python, and how can they be debugged?</args></response>]\n",
      "[400] of [1000] [40.0%] [Look into ZeroDivisionError on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>ZeroDivisionError</args></response>]\n",
      "[401] of [1000] [40.1%] [Locate AI in insurance underwriting, new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in insurance underwriting</args></response>]\n",
      "[402] of [1000] [40.2%] [Locate Advanced indexing in Pandas in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Advanced indexing in Pandas</args></response>]\n",
      "[403] of [1000] [40.3%] [Search google Data cleaning with Pandas in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Data cleaning with Pandas</args></response>]\n",
      "[404] of [1000] [40.4%] [In this tab, Google the terms Runtime Error]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Runtime Error</args></response>]\n",
      "[405] of [1000] [40.5%] [Google Scholar OverflowError, begin]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>OverflowError</args></response>]\n",
      "[406] of [1000] [40.6%] [Initiate a Google search on Unicode Encode Error in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Unicode Encode Error</args></response>]\n",
      "[407] of [1000] [40.7%] [Execute Google Scholar search for ROC Curve analysis: How is ROC curve analysis utilized to evaluate the performance of binary classifiers?, this tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>ROC Curve analysis: How is ROC curve analysis utilized to evaluate the performance of binary classifiers?</args></response>]\n",
      "[408] of [1000] [40.8%] [Current window, find Pandas DataFrame reshaping techniques]\n",
      "[<response><browser-command>search current tab</browser-command><args>Pandas DataFrame reshaping techniques</args></response>]\n",
      "[409] of [1000] [40.9%] [Perform a search for why is the sky blue in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>why is the sky blue</args></response>]\n",
      "[410] of [1000] [41.0%] [New tab: begin StopIteration search]\n",
      "[<response><browser-command>search new tab</browser-command><args>StopIteration</args></response>]\n",
      "[411] of [1000] [41.1%] [Seek Deprecation Warning using Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Deprecation Warning</args></response>]\n",
      "[412] of [1000] [41.2%] [Open new tab: Filtering data in Pandas DataFrame search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Filtering data in Pandas DataFrame</args></response>]\n",
      "[413] of [1000] [41.3%] [Search in this tab for AI in manufacturing: How is AI being used to revolutionize manufacturing processes?]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI in manufacturing: How is AI being used to revolutionize manufacturing processes?</args></response>]\n",
      "[414] of [1000] [41.4%] [Display Google Scholar search results for JavaScript vs Python in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>JavaScript vs Python</args></response>]\n",
      "[415] of [1000] [41.5%] [Initiate Google Scholar search for Syntax Warning: Syntax issue warning in this tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Syntax Warning: Syntax issue warning</args></response>]\n",
      "[416] of [1000] [41.6%] [Research Import Warning: Module import issue on Google from here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Import Warning: Module import issue</args></response>]\n",
      "[417] of [1000] [41.7%] [Kindly start current news in business search in another tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>current news in business</args></response>]\n",
      "[418] of [1000] [41.8%] [Probe EnvironmentWarning via Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>EnvironmentWarning</args></response>]\n",
      "[419] of [1000] [41.9%] [Perform a Google exploration for best restaurants near me]\n",
      "[<response><browser-command>search google current tab</browser-command><args>best restaurants near me</args></response>]\n",
      "[420] of [1000] [42.0%] [Google Scholar, show Value Error]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Value Error</args></response>]\n",
      "[421] of [1000] [42.1%] [Google Scholar Cloud computing for AI: How has cloud computing revolutionized AI development and deployment?, start]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Cloud computing for AI: How has cloud computing revolutionized AI development and deployment?</args></response>]\n",
      "[422] of [1000] [42.2%] [Google Scholar FileExistsError, open in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>FileExistsError</args></response>]\n",
      "[423] of [1000] [42.3%] [Conduct Google search for Not Implemented Error in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Not Implemented Error</args></response>]\n",
      "[424] of [1000] [42.4%] [Study What are runtime warnings in Python, and how can they be used to identify potential issues? on Google in this area]\n",
      "[<response><browser-command>search google current tab</browser-command><args>What are runtime warnings in Python, and how can they be used to identify potential issues?</args></response>]\n",
      "[425] of [1000] [42.5%] [Scan for AI-driven recommendation systems: What are the key components of AI-driven recommendation systems? in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI-driven recommendation systems: What are the key components of AI-driven recommendation systems?</args></response>]\n",
      "[426] of [1000] [42.6%] [Look into Transformer architecture research via Google from this position]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Transformer architecture research</args></response>]\n",
      "[427] of [1000] [42.7%] [Initiate a new tab, Google Scholar Recursion Error: Maximum recursion depth exceeded]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Recursion Error: Maximum recursion depth exceeded</args></response>]\n",
      "[428] of [1000] [42.8%] [Could you search Zip File Error in another tab?]\n",
      "[<response><browser-command>search new tab</browser-command><args>Zip File Error</args></response>]\n",
      "[429] of [1000] [42.9%] [Look up Resource Warning: Resource usage warning on Google here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Resource Warning: Resource usage warning</args></response>]\n",
      "[430] of [1000] [43.0%] [Show me Google Scholar results for latest sports scores in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>latest sports scores</args></response>]\n",
      "[431] of [1000] [43.1%] [Perform a search for Deep Learning in drug discovery in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Deep Learning in drug discovery</args></response>]\n",
      "[432] of [1000] [43.2%] [New tab with Google Scholar search for Type Error: Incorrect type comparison]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Type Error: Incorrect type comparison</args></response>]\n",
      "[433] of [1000] [43.3%] [Show me how to plant tomatoes in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to plant tomatoes</args></response>]\n",
      "[434] of [1000] [43.4%] [Seek What are import warnings in Python, and how can they be addressed? via Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>What are import warnings in Python, and how can they be addressed?</args></response>]\n",
      "[435] of [1000] [43.5%] [Get Google Scholar results for Future Warning: Future change warning here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Future Warning: Future change warning</args></response>]\n",
      "[436] of [1000] [43.6%] [Launch Google Scholar search for What are bytes warnings in Python, and how are they significant in data handling? in the present tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are bytes warnings in Python, and how are they significant in data handling?</args></response>]\n",
      "[437] of [1000] [43.7%] [Execute online yoga classes search in a fresh tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>online yoga classes</args></response>]\n",
      "[438] of [1000] [43.8%] [Google search for How do you address resource-related warnings in Python, especially regarding resource usage?, reveal results in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How do you address resource-related warnings in Python, especially regarding resource usage?</args></response>]\n",
      "[439] of [1000] [43.9%] [Find How do you handle situations where a feature or method is not yet implemented in Python? on Google Scholar in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>How do you handle situations where a feature or method is not yet implemented in Python?</args></response>]\n",
      "[440] of [1000] [44.0%] [Now in this tab, Google Scholar how to start a garden]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how to start a garden</args></response>]\n",
      "[441] of [1000] [44.1%] [Look for how to bake chocolate chip cookies in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>how to bake chocolate chip cookies</args></response>]\n",
      "[442] of [1000] [44.2%] [Show User Warning findings in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>User Warning</args></response>]\n",
      "[443] of [1000] [44.3%] [Tab new, and search Google Scholar for Ethical AI guidelines: What are some of the key guidelines for ethical AI development?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Ethical AI guidelines: What are some of the key guidelines for ethical AI development?</args></response>]\n",
      "[444] of [1000] [44.4%] [Scour for How do you prepare for future changes in Python indicated by future warnings? in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>How do you prepare for future changes in Python indicated by future warnings?</args></response>]\n",
      "[445] of [1000] [44.5%] [Search Google Scholar for Memory Error: Out of memory]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Memory Error: Out of memory</args></response>]\n",
      "[446] of [1000] [44.6%] [Start new tab, execute Invalid Operation search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Invalid Operation</args></response>]\n",
      "[447] of [1000] [44.7%] [Get Google Scholar results for video games in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>video games</args></response>]\n",
      "[448] of [1000] [44.8%] [Bring up Google Scholar for Column-wise operations in Pandas in this window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Column-wise operations in Pandas</args></response>]\n",
      "[449] of [1000] [44.9%] [Google Scholar What are the reasons for input/output errors in Python, and how can they be mitigated?, show here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are the reasons for input/output errors in Python, and how can they be mitigated?</args></response>]\n",
      "[450] of [1000] [45.0%] [Let's go, Google Scholar Sentiment Analysis tools]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Sentiment Analysis tools</args></response>]\n",
      "[451] of [1000] [45.1%] [Please open a new tab and search latest sports scores on Google Scholar]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>latest sports scores</args></response>]\n",
      "[452] of [1000] [45.2%] [Google Scholar Google Cloud AI services: What AI services does Google Cloud offer for developers and data scientists?, pull up in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Google Cloud AI services: What AI services does Google Cloud offer for developers and data scientists?</args></response>]\n",
      "[453] of [1000] [45.3%] [Fetch me best travel destinations in the USA on Google Scholar, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>best travel destinations in the USA</args></response>]\n",
      "[454] of [1000] [45.4%] [New tab, Google i want new shoes]\n",
      "[<response><browser-command>search google new tab</browser-command><args>i want new shoes</args></response>]\n",
      "[455] of [1000] [45.5%] [Initiate Google Scholar Bytes Warning: Bytecode issue]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Bytes Warning: Bytecode issue</args></response>]\n",
      "[456] of [1000] [45.6%] [Conduct a search for AI and blockchain integration: What are the benefits of integrating AI with blockchain technology? in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI and blockchain integration: What are the benefits of integrating AI with blockchain technology?</args></response>]\n",
      "[457] of [1000] [45.7%] [Get Google Scholar to search ValueError, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ValueError</args></response>]\n",
      "[458] of [1000] [45.8%] [Proceed to Google Scholar in a new tab and search for Data manipulation in Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Data manipulation in Pandas</args></response>]\n",
      "[459] of [1000] [45.9%] [Please conduct a Google search for what is the capital of Japan? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>what is the capital of Japan?</args></response>]\n",
      "[460] of [1000] [46.0%] [Investigate Custom aggregation in Pandas using Google from this place]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Custom aggregation in Pandas</args></response>]\n",
      "[461] of [1000] [46.1%] [Research ZipFileError via Google Scholar in this tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>ZipFileError</args></response>]\n",
      "[462] of [1000] [46.2%] [Please open a new tab and search Connection Aborted Error]\n",
      "[<response><browser-command>search new tab</browser-command><args>Connection Aborted Error</args></response>]\n",
      "[463] of [1000] [46.3%] [In the present window, search for Google Cloud AI services]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Google Cloud AI services</args></response>]\n",
      "[464] of [1000] [46.4%] [Initiate Google Scholar how to lose weight]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how to lose weight</args></response>]\n",
      "[465] of [1000] [46.5%] [Bring up AttributeError in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AttributeError</args></response>]\n",
      "[466] of [1000] [46.6%] [Google Scholar BufferError, please]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>BufferError</args></response>]\n",
      "[467] of [1000] [46.7%] [Fetch funny cat videos results in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>funny cat videos</args></response>]\n",
      "[468] of [1000] [46.8%] [Please show AI in video analysis: What are the latest AI techniques in video analysis and processing? in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in video analysis: What are the latest AI techniques in video analysis and processing?</args></response>]\n",
      "[469] of [1000] [46.9%] [Execute Google Scholar search for Transformer architecture research here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Transformer architecture research</args></response>]\n",
      "[470] of [1000] [47.0%] [Open a new tab, find buying a new laptop on Google Scholar]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>buying a new laptop</args></response>]\n",
      "[471] of [1000] [47.1%] [New tab, run a Google lookup for Syntax Error: Invalid syntax]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Syntax Error: Invalid syntax</args></response>]\n",
      "[472] of [1000] [47.2%] [Please show Google Scholar results for Index Error in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Index Error</args></response>]\n",
      "[473] of [1000] [47.3%] [In a new tab, run a Google search for What are bytes warnings in Python, and how are they significant in data handling?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>What are bytes warnings in Python, and how are they significant in data handling?</args></response>]\n",
      "[474] of [1000] [47.4%] [Initiate a Google lookup in a new tab for Data deduplication in Pandas]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Data deduplication in Pandas</args></response>]\n",
      "[475] of [1000] [47.5%] [New tab, conduct Google lookup on Pending Deprecation Warning: Feature will be deprecated]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Pending Deprecation Warning: Feature will be deprecated</args></response>]\n",
      "[476] of [1000] [47.6%] [Begin with Google Scholar Error handling in Pandas]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Error handling in Pandas</args></response>]\n",
      "[477] of [1000] [47.7%] [Do Google Scholar search for ConnectionRefusedError in current view]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>ConnectionRefusedError</args></response>]\n",
      "[478] of [1000] [47.8%] [Reshaping and pivoting in Pandas, show in Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Reshaping and pivoting in Pandas</args></response>]\n",
      "[479] of [1000] [47.9%] [Search in this tab for Deep Learning optimization: What strategies are used for optimizing deep learning models?]\n",
      "[<response><browser-command>search current tab</browser-command><args>Deep Learning optimization: What strategies are used for optimizing deep learning models?</args></response>]\n",
      "[480] of [1000] [48.0%] [Execute Natural Language Understanding search in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Natural Language Understanding</args></response>]\n",
      "[481] of [1000] [48.1%] [New tab, search Google for AI and IoT integration]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI and IoT integration</args></response>]\n",
      "[482] of [1000] [48.2%] [Kickstart Google Scholar search for AI in public safety in the current tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in public safety</args></response>]\n",
      "[483] of [1000] [48.3%] [Show me Pending Deprecation Warning in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Pending Deprecation Warning</args></response>]\n",
      "[484] of [1000] [48.4%] [Inquire easy hairstyles for long hair in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>easy hairstyles for long hair</args></response>]\n",
      "[485] of [1000] [48.5%] [Show Import Warning: Module import issue search outcome in current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Import Warning: Module import issue</args></response>]\n",
      "[486] of [1000] [48.6%] [Make a Google search for Deep Reinforcement Learning in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Deep Reinforcement Learning</args></response>]\n",
      "[487] of [1000] [48.7%] [Open new tab: find HTML vs CSS]\n",
      "[<response><browser-command>search new tab</browser-command><args>HTML vs CSS</args></response>]\n",
      "[488] of [1000] [48.8%] [Perform Frequency conversion in time series data search in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Frequency conversion in time series data</args></response>]\n",
      "[489] of [1000] [48.9%] [Kindly start Handling duplicate data in Pandas search in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Handling duplicate data in Pandas</args></response>]\n",
      "[490] of [1000] [49.0%] [Can you search for Converting data types in Pandas in a new tab?]\n",
      "[<response><browser-command>search new tab</browser-command><args>Converting data types in Pandas</args></response>]\n",
      "[491] of [1000] [49.1%] [Find Google Scholar results for ChildProcessError in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ChildProcessError</args></response>]\n",
      "[492] of [1000] [49.2%] [Locate Type Error: Incorrect type comparison in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Type Error: Incorrect type comparison</args></response>]\n",
      "[493] of [1000] [49.3%] [New tab with Google Scholar search for What steps can you take to prepare for features that will be deprecated in future Python releases?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>What steps can you take to prepare for features that will be deprecated in future Python releases?</args></response>]\n",
      "[494] of [1000] [49.4%] [Google need new summer clothes, results in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>need new summer clothes</args></response>]\n",
      "[495] of [1000] [49.5%] [Google Scholar Image Recognition technologies: How have image recognition technologies evolved in recent years?, go]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Image Recognition technologies: How have image recognition technologies evolved in recent years?</args></response>]\n",
      "[496] of [1000] [49.6%] [Search Google for AI in human resources]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in human resources</args></response>]\n",
      "[497] of [1000] [49.7%] [In a new tab, conduct a Google search for How do you handle warnings related to Unicode issues in Python?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How do you handle warnings related to Unicode issues in Python?</args></response>]\n",
      "[498] of [1000] [49.8%] [New tab: Google Scholar, What are runtime warnings in Python, and how can they be used to identify potential issues?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>What are runtime warnings in Python, and how can they be used to identify potential issues?</args></response>]\n",
      "[499] of [1000] [49.9%] [running shoes review on Google Scholar here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>running shoes review</args></response>]\n",
      "[500] of [1000] [50.0%] [Let's go, Google Scholar Blocking IO Error]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Blocking IO Error</args></response>]\n",
      "[501] of [1000] [50.1%] [Research How do you manage situations leading to an unexpected exit of generators in Python? via Google from this position]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How do you manage situations leading to an unexpected exit of generators in Python?</args></response>]\n",
      "[502] of [1000] [50.2%] [Start a new tab with Google Scholar search for AI in manufacturing: How is AI being used to revolutionize manufacturing processes?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI in manufacturing: How is AI being used to revolutionize manufacturing processes?</args></response>]\n",
      "[503] of [1000] [50.3%] [Google for MultiIndex in Pandas in this viewport]\n",
      "[<response><browser-command>search google current tab</browser-command><args>MultiIndex in Pandas</args></response>]\n",
      "[504] of [1000] [50.4%] [In the present tab, find What steps can you take to prepare for features that will be deprecated in future Python releases?]\n",
      "[<response><browser-command>search current tab</browser-command><args>What steps can you take to prepare for features that will be deprecated in future Python releases?</args></response>]\n",
      "[505] of [1000] [50.5%] [healthy dinner ideas: Look up in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>healthy dinner ideas</args></response>]\n",
      "[506] of [1000] [50.6%] [Execute a search for best vegan restaurants in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>best vegan restaurants</args></response>]\n",
      "[507] of [1000] [50.7%] [Execute a Google search for what is the meaning of love? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>what is the meaning of love?</args></response>]\n",
      "[508] of [1000] [50.8%] [Current tab: Search and display results for Overflow Error: Value too large to convert]\n",
      "[<response><browser-command>search current tab</browser-command><args>Overflow Error: Value too large to convert</args></response>]\n",
      "[509] of [1000] [50.9%] [Kindly start What are the reasons for attribute-related errors in Python objects and how can they be fixed? search in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>What are the reasons for attribute-related errors in Python objects and how can they be fixed?</args></response>]\n",
      "[510] of [1000] [51.0%] [Inquire GANs recent advancements in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>GANs recent advancements</args></response>]\n",
      "[511] of [1000] [51.1%] [Could you please Google Scholar How do you address runtime warnings in Python, especially those indicating risky runtime behavior? in a new tab?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>How do you address runtime warnings in Python, especially those indicating risky runtime behavior?</args></response>]\n",
      "[512] of [1000] [51.2%] [New tab: run Responsible AI practices: How can organizations implement responsible AI practices? search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Responsible AI practices: How can organizations implement responsible AI practices?</args></response>]\n",
      "[513] of [1000] [51.3%] [New tab, execute What steps can you take to prepare for features that will be deprecated in future Python releases? search]\n",
      "[<response><browser-command>search new tab</browser-command><args>What steps can you take to prepare for features that will be deprecated in future Python releases?</args></response>]\n",
      "[514] of [1000] [51.4%] [Current window, search for how do i cure dandruff?]\n",
      "[<response><browser-command>search current tab</browser-command><args>how do i cure dandruff?</args></response>]\n",
      "[515] of [1000] [51.5%] [New tab: search Google Scholar for Scikit-Learn documentation]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Scikit-Learn documentation</args></response>]\n",
      "[516] of [1000] [51.6%] [Seek How do you resolve issues when a required module is not found in Python? via Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How do you resolve issues when a required module is not found in Python?</args></response>]\n",
      "[517] of [1000] [51.7%] [Google Scholar, start with search for gluten-free recipes]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>search for gluten-free recipes</args></response>]\n",
      "[518] of [1000] [51.8%] [New tab, search how does electricity work?]\n",
      "[<response><browser-command>search new tab</browser-command><args>how does electricity work?</args></response>]\n",
      "[519] of [1000] [51.9%] [Use Google to find Stream Processing with Kafka]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Stream Processing with Kafka</args></response>]\n",
      "[520] of [1000] [52.0%] [In a new tab, run a Google search for Saving Pandas DataFrame to CSV]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Saving Pandas DataFrame to CSV</args></response>]\n",
      "[521] of [1000] [52.1%] [Probe for Connection Aborted Error in current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Connection Aborted Error</args></response>]\n",
      "[522] of [1000] [52.2%] [Investigate what is the meaning of life? via Google from here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>what is the meaning of life?</args></response>]\n",
      "[523] of [1000] [52.3%] [Now, Google Scholar ]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args></args></response>]\n",
      "[524] of [1000] [52.4%] [Do Google Scholar search for DIY gift ideas in current view]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>DIY gift ideas</args></response>]\n",
      "[525] of [1000] [52.5%] [Examine OpenAI latest projects: What are the latest projects undertaken by OpenAI? in the current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>OpenAI latest projects: What are the latest projects undertaken by OpenAI?</args></response>]\n",
      "[526] of [1000] [52.6%] [Open Google, search PermissionError, show results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>PermissionError</args></response>]\n",
      "[527] of [1000] [52.7%] [Get Google Scholar results for latest tech gadgets in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>latest tech gadgets</args></response>]\n",
      "[528] of [1000] [52.8%] [Perform a Google lookup for Handling missing data in Pandas, results in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Handling missing data in Pandas</args></response>]\n",
      "[529] of [1000] [52.9%] [Run Google Scholar search on best fashion trends this year, new tab please]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>best fashion trends this year</args></response>]\n",
      "[530] of [1000] [53.0%] [Uncover AI-driven chatbots in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI-driven chatbots</args></response>]\n",
      "[531] of [1000] [53.1%] [Please conduct a Google Scholar search for What are import warnings in Python, and how can they be addressed? in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>What are import warnings in Python, and how can they be addressed?</args></response>]\n",
      "[532] of [1000] [53.2%] [Do a search on Google Scholar for EnvironmentError, new tab please]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>EnvironmentError</args></response>]\n",
      "[533] of [1000] [53.3%] [Do a Google research for what are vitamins and minerals?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>what are vitamins and minerals?</args></response>]\n",
      "[534] of [1000] [53.4%] [In a new tab, please find learning Japanese online]\n",
      "[<response><browser-command>search new tab</browser-command><args>learning Japanese online</args></response>]\n",
      "[535] of [1000] [53.5%] [why do we yawn, Google it, new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>why do we yawn</args></response>]\n",
      "[536] of [1000] [53.6%] [Proceed to Google Scholar in a new tab and search for famous athletes]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>famous athletes</args></response>]\n",
      "[537] of [1000] [53.7%] [Launch a Google probe for Reinforcement Learning breakthroughs]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Reinforcement Learning breakthroughs</args></response>]\n",
      "[538] of [1000] [53.8%] [Google Scholar Import Warning: Module import issue, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Import Warning: Module import issue</args></response>]\n",
      "[539] of [1000] [53.9%] [Search Google Scholar in a new tab for Data wrangling with Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Data wrangling with Pandas</args></response>]\n",
      "[540] of [1000] [54.0%] [Investigate AI in climate change research: How is AI contributing to climate change research? using Google from this place]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in climate change research: How is AI contributing to climate change research?</args></response>]\n",
      "[541] of [1000] [54.1%] [Scan for AI in financial forecasting: How is AI used in financial forecasting and analysis? in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI in financial forecasting: How is AI used in financial forecasting and analysis?</args></response>]\n",
      "[542] of [1000] [54.2%] [New tab: Google Scholar, IndentationError]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>IndentationError</args></response>]\n",
      "[543] of [1000] [54.3%] [New tab, conduct Google lookup on Recursion Error: Maximum recursion depth exceeded]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Recursion Error: Maximum recursion depth exceeded</args></response>]\n",
      "[544] of [1000] [54.4%] [Run Google Scholar search on Connection Refused Error, new tab please]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Connection Refused Error</args></response>]\n",
      "[545] of [1000] [54.5%] [Display Random Forest search results in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Random Forest</args></response>]\n",
      "[546] of [1000] [54.6%] [Google Scholar how to write a cover letter, begin]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how to write a cover letter</args></response>]\n",
      "[547] of [1000] [54.7%] [Find Feature Engineering best practices: How does feature engineering improve the performance of machine learning models? in the current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Feature Engineering best practices: How does feature engineering improve the performance of machine learning models?</args></response>]\n",
      "[548] of [1000] [54.8%] [In a new tab, please Google Scholar search ConnectionRefusedError]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ConnectionRefusedError</args></response>]\n",
      "[549] of [1000] [54.9%] [Go find hip hop music in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>hip hop music</args></response>]\n",
      "[550] of [1000] [55.0%] [Make a Google search for How do you manage specific Windows errors in Python that are unique to the Windows operating system? in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How do you manage specific Windows errors in Python that are unique to the Windows operating system?</args></response>]\n",
      "[551] of [1000] [55.1%] [Browse Google Scholar for RuntimeWarning]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>RuntimeWarning</args></response>]\n",
      "[552] of [1000] [55.2%] [In a new tab, please find Reference Error: Weak reference object no longer exists]\n",
      "[<response><browser-command>search new tab</browser-command><args>Reference Error: Weak reference object no longer exists</args></response>]\n",
      "[553] of [1000] [55.3%] [New tab with Google Scholar search for Bytes Warning: Bytecode issue]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Bytes Warning: Bytecode issue</args></response>]\n",
      "[554] of [1000] [55.4%] [Google Scholar AI Fairness and Bias mitigation: How do you ensure fairness and mitigate bias in AI models?, now]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI Fairness and Bias mitigation: How do you ensure fairness and mitigate bias in AI models?</args></response>]\n",
      "[555] of [1000] [55.5%] [Open new tab, Google Google Cloud AI services: What AI services does Google Cloud offer for developers and data scientists?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Google Cloud AI services: What AI services does Google Cloud offer for developers and data scientists?</args></response>]\n",
      "[556] of [1000] [55.6%] [Please initiate a Google search for popular movie genres in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>popular movie genres</args></response>]\n",
      "[557] of [1000] [55.7%] [Execute a Google search for Saving Pandas DataFrame to CSV in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Saving Pandas DataFrame to CSV</args></response>]\n",
      "[558] of [1000] [55.8%] [Find Named Entity Recognition: What approaches are commonly used for named entity recognition in NLP?, open in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Named Entity Recognition: What approaches are commonly used for named entity recognition in NLP?</args></response>]\n",
      "[559] of [1000] [55.9%] [Start a search on Syntax Error in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Syntax Error</args></response>]\n",
      "[560] of [1000] [56.0%] [Pull up a new tab and search Word Embeddings]\n",
      "[<response><browser-command>search new tab</browser-command><args>Word Embeddings</args></response>]\n",
      "[561] of [1000] [56.1%] [Generate Google Scholar results for find new music in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>find new music</args></response>]\n",
      "[562] of [1000] [56.2%] [how to improve memory, find in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to improve memory</args></response>]\n",
      "[563] of [1000] [56.3%] [New tab: begin why does ice float search]\n",
      "[<response><browser-command>search new tab</browser-command><args>why does ice float</args></response>]\n",
      "[564] of [1000] [56.4%] [Bring up how to make homemade bread in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to make homemade bread</args></response>]\n",
      "[565] of [1000] [56.5%] [Search and show Buffer Error in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Buffer Error</args></response>]\n",
      "[566] of [1000] [56.6%] [Initiate a search for How can general warnings in Python be addressed to improve code quality? in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>How can general warnings in Python be addressed to improve code quality?</args></response>]\n",
      "[567] of [1000] [56.7%] [In a new tab, start a Google lookup for what is artificial intelligence?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>what is artificial intelligence?</args></response>]\n",
      "[568] of [1000] [56.8%] [New tab: begin AI-driven fraud detection search]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI-driven fraud detection</args></response>]\n",
      "[569] of [1000] [56.9%] [Find Pending Deprecation Warning on Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Pending Deprecation Warning</args></response>]\n",
      "[570] of [1000] [57.0%] [Display Google Scholar search results for AWS SageMaker for ML: How does AWS SageMaker facilitate machine learning model development? in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AWS SageMaker for ML: How does AWS SageMaker facilitate machine learning model development?</args></response>]\n",
      "[571] of [1000] [57.1%] [Please open a new tab and search AI in energy management: How does AI contribute to efficient energy management? on Google Scholar]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI in energy management: How does AI contribute to efficient energy management?</args></response>]\n",
      "[572] of [1000] [57.2%] [Find FutureWarning on Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>FutureWarning</args></response>]\n",
      "[573] of [1000] [57.3%] [Google Pandas and geospatial data, results in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Pandas and geospatial data</args></response>]\n",
      "[574] of [1000] [57.4%] [Go to Google Scholar and search Creating histograms in Pandas in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Creating histograms in Pandas</args></response>]\n",
      "[575] of [1000] [57.5%] [Current tab, Google Scholar What are the best practices for handling reset connections in network communications in Python?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are the best practices for handling reset connections in network communications in Python?</args></response>]\n",
      "[576] of [1000] [57.6%] [Run a new tab and Google Scholar Import Warning: Module import issue]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Import Warning: Module import issue</args></response>]\n",
      "[577] of [1000] [57.7%] [Scikit-Learn documentation, Google search, open in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Scikit-Learn documentation</args></response>]\n",
      "[578] of [1000] [57.8%] [In the present tab, find best sci-fi novels]\n",
      "[<response><browser-command>search current tab</browser-command><args>best sci-fi novels</args></response>]\n",
      "[579] of [1000] [57.9%] [Google Scholar, find Import Warning: Module import issue]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Import Warning: Module import issue</args></response>]\n",
      "[580] of [1000] [58.0%] [Current tab, delve for Reading HTML tables with Pandas]\n",
      "[<response><browser-command>search current tab</browser-command><args>Reading HTML tables with Pandas</args></response>]\n",
      "[581] of [1000] [58.1%] [Start a Google search for Environment Warning in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Environment Warning</args></response>]\n",
      "[582] of [1000] [58.2%] [Transformer architecture research new tab search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Transformer architecture research</args></response>]\n",
      "[583] of [1000] [58.3%] [Explore Google Scholar with Not A Directory Error here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Not A Directory Error</args></response>]\n",
      "[584] of [1000] [58.4%] [Launch another tab, search PermissionError]\n",
      "[<response><browser-command>search new tab</browser-command><args>PermissionError</args></response>]\n",
      "[585] of [1000] [58.5%] [Generate Value Error: Invalid value to set search in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Value Error: Invalid value to set</args></response>]\n",
      "[586] of [1000] [58.6%] [In the present tab, perform a Google Scholar search for Responsible AI practices]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Responsible AI practices</args></response>]\n",
      "[587] of [1000] [58.7%] [Open Google, search RuntimeWarning, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>RuntimeWarning</args></response>]\n",
      "[588] of [1000] [58.8%] [In the current tab, conduct a Pending Deprecation Warning: Feature will be deprecated search]\n",
      "[<response><browser-command>search current tab</browser-command><args>Pending Deprecation Warning: Feature will be deprecated</args></response>]\n",
      "[589] of [1000] [58.9%] [Start a new tab and perform Google Scholar search for finding a yoga class]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>finding a yoga class</args></response>]\n",
      "[590] of [1000] [59.0%] [Execute Google Scholar search for Using Pandas for financial analysis here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Using Pandas for financial analysis</args></response>]\n",
      "[591] of [1000] [59.1%] [Google Scholar What are the reasons for input/output errors in Python, and how can they be mitigated?, begin]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are the reasons for input/output errors in Python, and how can they be mitigated?</args></response>]\n",
      "[592] of [1000] [59.2%] [Google Scholar search for File Not Found Error: File not found or path is incorrect, new tab please]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>File Not Found Error: File not found or path is incorrect</args></response>]\n",
      "[593] of [1000] [59.3%] [Run Google search on AI in digital marketing: What role does AI play in digital marketing strategies? and display in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in digital marketing: What role does AI play in digital marketing strategies?</args></response>]\n",
      "[594] of [1000] [59.4%] [Conduct Google search for AI in public safety in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in public safety</args></response>]\n",
      "[595] of [1000] [59.5%] [Let's go, Google Scholar What are bytes warnings in Python, and how are they significant in data handling?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are bytes warnings in Python, and how are they significant in data handling?</args></response>]\n",
      "[596] of [1000] [59.6%] [Start another tab and search for best hiking shoes]\n",
      "[<response><browser-command>search new tab</browser-command><args>best hiking shoes</args></response>]\n",
      "[597] of [1000] [59.7%] [Let's search pop music in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>pop music</args></response>]\n",
      "[598] of [1000] [59.8%] [Initiate a Google search for How do you address resource-related warnings in Python, especially regarding resource usage?, and show results here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How do you address resource-related warnings in Python, especially regarding resource usage?</args></response>]\n",
      "[599] of [1000] [59.9%] [Find me Data anonymization in Pandas on Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Data anonymization in Pandas</args></response>]\n",
      "[600] of [1000] [60.0%] [Find me Unbound Local Error: Local variable referenced before assignment on Google Scholar in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Unbound Local Error: Local variable referenced before assignment</args></response>]\n",
      "[601] of [1000] [60.1%] [Launch a Google query for AI-driven recommendation systems: What are the key components of AI-driven recommendation systems? in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI-driven recommendation systems: What are the key components of AI-driven recommendation systems?</args></response>]\n",
      "[602] of [1000] [60.2%] [Go to Google Scholar and search best movies of all time in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>best movies of all time</args></response>]\n",
      "[603] of [1000] [60.3%] [Search Google Scholar for How can overflow errors be detected and handled in Python, especially with numerical operations?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>How can overflow errors be detected and handled in Python, especially with numerical operations?</args></response>]\n",
      "[604] of [1000] [60.4%] [Execute new tab, search for Pandas and Matplotlib integration]\n",
      "[<response><browser-command>search new tab</browser-command><args>Pandas and Matplotlib integration</args></response>]\n",
      "[605] of [1000] [60.5%] [Explore How can you handle value errors that occur when a function receives an argument of the right type but an inappropriate value in Python? on Google from this location]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How can you handle value errors that occur when a function receives an argument of the right type but an inappropriate value in Python?</args></response>]\n",
      "[606] of [1000] [60.6%] [Pull up a new tab and Google Scholar search for ImportWarning]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ImportWarning</args></response>]\n",
      "[607] of [1000] [60.7%] [Could you please Google Scholar Warning: General warning message in a new tab?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Warning: General warning message</args></response>]\n",
      "[608] of [1000] [60.8%] [In a new tab, perform a Google search of Import Warning]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Import Warning</args></response>]\n",
      "[609] of [1000] [60.9%] [In a new tab, Google Keras neural network examples: Where can you find practical examples of neural networks implemented using Keras?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Keras neural network examples: Where can you find practical examples of neural networks implemented using Keras?</args></response>]\n",
      "[610] of [1000] [61.0%] [In a new tab, execute a Google search for why do we blink]\n",
      "[<response><browser-command>search google new tab</browser-command><args>why do we blink</args></response>]\n",
      "[611] of [1000] [61.1%] [Search and return Google results for classic novels]\n",
      "[<response><browser-command>search google current tab</browser-command><args>classic novels</args></response>]\n",
      "[612] of [1000] [61.2%] [Start a Google search on current news in tech in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>current news in tech</args></response>]\n",
      "[613] of [1000] [61.3%] [Initiate Google Scholar Syntax Warning in the current tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Syntax Warning</args></response>]\n",
      "[614] of [1000] [61.4%] [Show Google search results of what is the population of New York City? in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>what is the population of New York City?</args></response>]\n",
      "[615] of [1000] [61.5%] [Fetch Reading HTML tables with Pandas in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Reading HTML tables with Pandas</args></response>]\n",
      "[616] of [1000] [61.6%] [Please carry out a Google search for top 10 Netflix series in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>top 10 Netflix series</args></response>]\n",
      "[617] of [1000] [61.7%] [FloatingPointError, search Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>FloatingPointError</args></response>]\n",
      "[618] of [1000] [61.8%] [Kindly look for what are vitamins and minerals? in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>what are vitamins and minerals?</args></response>]\n",
      "[619] of [1000] [61.9%] [Perform a Google examination for How can you resolve recursion errors due to excessive recursive calls in Python?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How can you resolve recursion errors due to excessive recursive calls in Python?</args></response>]\n",
      "[620] of [1000] [62.0%] [Please open a new tab and search PendingDeprecationWarning on Google Scholar]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>PendingDeprecationWarning</args></response>]\n",
      "[621] of [1000] [62.1%] [What are memory-related errors in Python, and how can they be prevented? search, this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>What are memory-related errors in Python, and how can they be prevented?</args></response>]\n",
      "[622] of [1000] [62.2%] [Run a Google search for search for gluten-free recipes in the current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>search for gluten-free recipes</args></response>]\n",
      "[623] of [1000] [62.3%] [Google how to knit a sweater, display in the current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to knit a sweater</args></response>]\n",
      "[624] of [1000] [62.4%] [Launch Google search for classical music here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>classical music</args></response>]\n",
      "[625] of [1000] [62.5%] [Open new tab: IndexError search]\n",
      "[<response><browser-command>search new tab</browser-command><args>IndexError</args></response>]\n",
      "[626] of [1000] [62.6%] [Please open a new tab and search Unicode Warning: Unicode related warning on Google Scholar]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Unicode Warning: Unicode related warning</args></response>]\n",
      "[627] of [1000] [62.7%] [Launch a Google search for AI in climate change research: How is AI contributing to climate change research? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI in climate change research: How is AI contributing to climate change research?</args></response>]\n",
      "[628] of [1000] [62.8%] [Investigate Floating Point Error on Google here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Floating Point Error</args></response>]\n",
      "[629] of [1000] [62.9%] [Google Data munging with Pandas in the current browser tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Data munging with Pandas</args></response>]\n",
      "[630] of [1000] [63.0%] [Google Scholar ProcessLookupError in the current tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>ProcessLookupError</args></response>]\n",
      "[631] of [1000] [63.1%] [Google best books of all time in the current browser tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>best books of all time</args></response>]\n",
      "[632] of [1000] [63.2%] [Initiate a Google search in a new tab for Word Embeddings: How do word embeddings capture semantic relationships in natural language processing?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Word Embeddings: How do word embeddings capture semantic relationships in natural language processing?</args></response>]\n",
      "[633] of [1000] [63.3%] [Generate FloatingPointError search in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>FloatingPointError</args></response>]\n",
      "[634] of [1000] [63.4%] [Open new tab, search for Named Entity Recognition: What approaches are commonly used for named entity recognition in NLP?]\n",
      "[<response><browser-command>search new tab</browser-command><args>Named Entity Recognition: What approaches are commonly used for named entity recognition in NLP?</args></response>]\n",
      "[635] of [1000] [63.5%] [Run a Google lookup for How can you manage errors that occur due to missing files in Python programs? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How can you manage errors that occur due to missing files in Python programs?</args></response>]\n",
      "[636] of [1000] [63.6%] [In this window, Google Scholar DIY home improvement projects]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>DIY home improvement projects</args></response>]\n",
      "[637] of [1000] [63.7%] [Start a Google search for best fashion trends this year in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>best fashion trends this year</args></response>]\n",
      "[638] of [1000] [63.8%] [Let's search Voice Recognition technologies: What are the latest advancements in voice recognition technology? in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Voice Recognition technologies: What are the latest advancements in voice recognition technology?</args></response>]\n",
      "[639] of [1000] [63.9%] [Perform a new tab search on Google Scholar for how to play guitar chords]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>how to play guitar chords</args></response>]\n",
      "[640] of [1000] [64.0%] [Find Optimizing Pandas code performance on Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Optimizing Pandas code performance</args></response>]\n",
      "[641] of [1000] [64.1%] [New tab, start a Google search for Filtering data in Pandas DataFrame]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Filtering data in Pandas DataFrame</args></response>]\n",
      "[642] of [1000] [64.2%] [In the present tab, find Data compression in Pandas]\n",
      "[<response><browser-command>search current tab</browser-command><args>Data compression in Pandas</args></response>]\n",
      "[643] of [1000] [64.3%] [Hunt What strategies can you use to fix type errors that arise from operations on incompatible data types in Python? in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>What strategies can you use to fix type errors that arise from operations on incompatible data types in Python?</args></response>]\n",
      "[644] of [1000] [64.4%] [Here, find Syntax Error: Invalid syntax]\n",
      "[<response><browser-command>search current tab</browser-command><args>Syntax Error: Invalid syntax</args></response>]\n",
      "[645] of [1000] [64.5%] [Open Google, search SEO strategies, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>SEO strategies</args></response>]\n",
      "[646] of [1000] [64.6%] [Execute a Google search for best vegan restaurants]\n",
      "[<response><browser-command>search google current tab</browser-command><args>best vegan restaurants</args></response>]\n",
      "[647] of [1000] [64.7%] [Fetch What are user-defined warnings in Python, and how can they be effectively used? in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>What are user-defined warnings in Python, and how can they be effectively used?</args></response>]\n",
      "[648] of [1000] [64.8%] [Proceed to search JavaScript vs Python in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>JavaScript vs Python</args></response>]\n",
      "[649] of [1000] [64.9%] [Open new tab: find how do i cure dandruff?]\n",
      "[<response><browser-command>search new tab</browser-command><args>how do i cure dandruff?</args></response>]\n",
      "[650] of [1000] [65.0%] [Perform a Google check for AI in natural language generation]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in natural language generation</args></response>]\n",
      "[651] of [1000] [65.1%] [Query for DeprecationWarning in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>DeprecationWarning</args></response>]\n",
      "[652] of [1000] [65.2%] [Find Resource Warning: Resource usage warning on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Resource Warning: Resource usage warning</args></response>]\n",
      "[653] of [1000] [65.3%] [Seek out RuntimeWarning in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>RuntimeWarning</args></response>]\n",
      "[654] of [1000] [65.4%] [Execute Google Scholar search for AI in content moderation: How is AI used for content moderation on digital platforms? here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in content moderation: How is AI used for content moderation on digital platforms?</args></response>]\n",
      "[655] of [1000] [65.5%] [In the current tab, conduct a alternative music search]\n",
      "[<response><browser-command>search current tab</browser-command><args>alternative music</args></response>]\n",
      "[656] of [1000] [65.6%] [New tab, execute Outlier Detection methods: What methods are most effective for outlier detection in univariate datasets? search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Outlier Detection methods: What methods are most effective for outlier detection in univariate datasets?</args></response>]\n",
      "[657] of [1000] [65.7%] [Google Scholar, I want to see What are the reasons for input/output errors in Python, and how can they be mitigated?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are the reasons for input/output errors in Python, and how can they be mitigated?</args></response>]\n",
      "[658] of [1000] [65.8%] [Perform a search for Keyboard Interrupt in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Keyboard Interrupt</args></response>]\n",
      "[659] of [1000] [65.9%] [New tab, perform Google search on Duplicate Label Error: Non-unique axis label]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Duplicate Label Error: Non-unique axis label</args></response>]\n",
      "[660] of [1000] [66.0%] [Google for best hiking shoes in this location]\n",
      "[<response><browser-command>search google current tab</browser-command><args>best hiking shoes</args></response>]\n",
      "[661] of [1000] [66.1%] [Bring up Google Scholar for What are common OS-level errors in Python and how can they be resolved? in this window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are common OS-level errors in Python and how can they be resolved?</args></response>]\n",
      "[662] of [1000] [66.2%] [Find, fetch, and show healthy breakfast ideas in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>healthy breakfast ideas</args></response>]\n",
      "[663] of [1000] [66.3%] [Unleash Google Scholar search on Bytes Warning here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Bytes Warning</args></response>]\n",
      "[664] of [1000] [66.4%] [New tab, lookup for ImportError]\n",
      "[<response><browser-command>search new tab</browser-command><args>ImportError</args></response>]\n",
      "[665] of [1000] [66.5%] [Open Google Scholar and search Syntax Warning in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Syntax Warning</args></response>]\n",
      "[666] of [1000] [66.6%] [Scan OS Error in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>OS Error</args></response>]\n",
      "[667] of [1000] [66.7%] [Perform a Google inspection for how to start a small business]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to start a small business</args></response>]\n",
      "[668] of [1000] [66.8%] [Google Scholar, initiate why we dream]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>why we dream</args></response>]\n",
      "[669] of [1000] [66.9%] [Search for SSLError and exhibit results here]\n",
      "[<response><browser-command>search current tab</browser-command><args>SSLError</args></response>]\n",
      "[670] of [1000] [67.0%] [Google top 10 mobile apps, results in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>top 10 mobile apps</args></response>]\n",
      "[671] of [1000] [67.1%] [FileExistsError, perform Google search in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>FileExistsError</args></response>]\n",
      "[672] of [1000] [67.2%] [Search in this window for User Warning]\n",
      "[<response><browser-command>search current tab</browser-command><args>User Warning</args></response>]\n",
      "[673] of [1000] [67.3%] [Look for Computer Vision applications: What are the groundbreaking applications of computer vision in today's technology?, new tab please]\n",
      "[<response><browser-command>search new tab</browser-command><args>Computer Vision applications: What are the groundbreaking applications of computer vision in today's technology?</args></response>]\n",
      "[674] of [1000] [67.4%] [Start Google Scholar search on Value Error]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Value Error</args></response>]\n",
      "[675] of [1000] [67.5%] [Proceed to Google Scholar in a new tab and search for top 10 movies of all time]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>top 10 movies of all time</args></response>]\n",
      "[676] of [1000] [67.6%] [Please do a Aggregation functions in Pandas search in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Aggregation functions in Pandas</args></response>]\n",
      "[677] of [1000] [67.7%] [Go to Google Scholar and search easy dinner recipes in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>easy dinner recipes</args></response>]\n",
      "[678] of [1000] [67.8%] [Unleash Google Scholar how to make pizza dough]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how to make pizza dough</args></response>]\n",
      "[679] of [1000] [67.9%] [Find why do apples turn brown on this page]\n",
      "[<response><browser-command>search current tab</browser-command><args>why do apples turn brown</args></response>]\n",
      "[680] of [1000] [68.0%] [Probe for why cats purr in current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>why cats purr</args></response>]\n",
      "[681] of [1000] [68.1%] [Launch Google Scholar Reference Error: Weak reference object no longer exists]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Reference Error: Weak reference object no longer exists</args></response>]\n",
      "[682] of [1000] [68.2%] [Start Google Scholar search on Data anonymization in Pandas]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Data anonymization in Pandas</args></response>]\n",
      "[683] of [1000] [68.3%] [In a new tab, execute a Google search for How do you address runtime warnings in Python, especially those indicating risky runtime behavior?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How do you address runtime warnings in Python, especially those indicating risky runtime behavior?</args></response>]\n",
      "[684] of [1000] [68.4%] [Execute new tab, search for Memory Error]\n",
      "[<response><browser-command>search new tab</browser-command><args>Memory Error</args></response>]\n",
      "[685] of [1000] [68.5%] [Begin a new tab, then Google search OS Error: Operating system error]\n",
      "[<response><browser-command>search google new tab</browser-command><args>OS Error: Operating system error</args></response>]\n",
      "[686] of [1000] [68.6%] [Use this tab to Google VMSError]\n",
      "[<response><browser-command>search google current tab</browser-command><args>VMSError</args></response>]\n",
      "[687] of [1000] [68.7%] [New tab, Google Scholar Data Cleaning techniques: What are the best practices for data cleaning in large datasets?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Data Cleaning techniques: What are the best practices for data cleaning in large datasets?</args></response>]\n",
      "[688] of [1000] [68.8%] [Please open Google Scholar Arithmetic Error in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Arithmetic Error</args></response>]\n",
      "[689] of [1000] [68.9%] [Perform a Google exploration for How do you manage situations leading to an unexpected exit of generators in Python?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How do you manage situations leading to an unexpected exit of generators in Python?</args></response>]\n",
      "[690] of [1000] [69.0%] [Search Google Scholar for UnicodeEncodeError, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>UnicodeEncodeError</args></response>]\n",
      "[691] of [1000] [69.1%] [Query for ModuleNotFoundError in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>ModuleNotFoundError</args></response>]\n",
      "[692] of [1000] [69.2%] [In a fresh tab, begin a Google search for Efficient file reading with Pandas]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Efficient file reading with Pandas</args></response>]\n",
      "[693] of [1000] [69.3%] [Google Not A Directory Error, display results in a new window]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Not A Directory Error</args></response>]\n",
      "[694] of [1000] [69.4%] [Search and return Google results for AI in manufacturing]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in manufacturing</args></response>]\n",
      "[695] of [1000] [69.5%] [why is the sky blue: Scan in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>why is the sky blue</args></response>]\n",
      "[696] of [1000] [69.6%] [Scan for AI in e-commerce personalization in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI in e-commerce personalization</args></response>]\n",
      "[697] of [1000] [69.7%] [Please show Google Scholar results for ConnectionResetError in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ConnectionResetError</args></response>]\n",
      "[698] of [1000] [69.8%] [Open why does bread rise in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>why does bread rise</args></response>]\n",
      "[699] of [1000] [69.9%] [Please begin a Google search for How can you handle errors in Python when a directory is incorrectly treated as a file? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How can you handle errors in Python when a directory is incorrectly treated as a file?</args></response>]\n",
      "[700] of [1000] [70.0%] [Look up Not A Directory Error here]\n",
      "[<response><browser-command>search current tab</browser-command><args>Not A Directory Error</args></response>]\n",
      "[701] of [1000] [70.1%] [Unleash Google Scholar What are the common causes of runtime errors in Python, and how can they be debugged?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are the common causes of runtime errors in Python, and how can they be debugged?</args></response>]\n",
      "[702] of [1000] [70.2%] [Look up AI in space exploration: What is the role of AI in recent space exploration missions? on Google here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in space exploration: What is the role of AI in recent space exploration missions?</args></response>]\n",
      "[703] of [1000] [70.3%] [Begin a Google lookup for Pandas and Matplotlib integration in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Pandas and Matplotlib integration</args></response>]\n",
      "[704] of [1000] [70.4%] [Google What are bytes warnings in Python, and how are they significant in data handling?, display in the current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>What are bytes warnings in Python, and how are they significant in data handling?</args></response>]\n",
      "[705] of [1000] [70.5%] [Search Google for how to brew beer at home]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to brew beer at home</args></response>]\n",
      "[706] of [1000] [70.6%] [Delve into Deprecation Warning: Feature is deprecated in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Deprecation Warning: Feature is deprecated</args></response>]\n",
      "[707] of [1000] [70.7%] [Explore Big Data analysis techniques in the current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Big Data analysis techniques</args></response>]\n",
      "[708] of [1000] [70.8%] [New tab with Google Scholar search for Custom aggregation in Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Custom aggregation in Pandas</args></response>]\n",
      "[709] of [1000] [70.9%] [Run a search for AI in e-commerce personalization and show results in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in e-commerce personalization</args></response>]\n",
      "[710] of [1000] [71.0%] [Locate AI and IoT integration: How are AI and IoT being integrated for advanced technological solutions? in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI and IoT integration: How are AI and IoT being integrated for advanced technological solutions?</args></response>]\n",
      "[711] of [1000] [71.1%] [Conduct a Google lookup for Managing data quality with Pandas in a fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Managing data quality with Pandas</args></response>]\n",
      "[712] of [1000] [71.2%] [Look up ConnectionError in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>ConnectionError</args></response>]\n",
      "[713] of [1000] [71.3%] [Examine AI for personalized education: How does AI contribute to personalized education solutions? on Google in this space]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI for personalized education: How does AI contribute to personalized education solutions?</args></response>]\n",
      "[714] of [1000] [71.4%] [Google Scholar, let's find Handling JSON data in Pandas]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Handling JSON data in Pandas</args></response>]\n",
      "[715] of [1000] [71.5%] [Launch a Google search for how to paint a room in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>how to paint a room</args></response>]\n",
      "[716] of [1000] [71.6%] [Query Future Warning: Future change warning on Google in the current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Future Warning: Future change warning</args></response>]\n",
      "[717] of [1000] [71.7%] [In a new tab, please find Runtime Warning: Runtime behavior warning]\n",
      "[<response><browser-command>search new tab</browser-command><args>Runtime Warning: Runtime behavior warning</args></response>]\n",
      "[718] of [1000] [71.8%] [Investigate Deprecation Warning on Google from this point]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Deprecation Warning</args></response>]\n",
      "[719] of [1000] [71.9%] [Google Scholar, search Deprecation Warning in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Deprecation Warning</args></response>]\n",
      "[720] of [1000] [72.0%] [Please Google Scholar Pandas and regular expressions in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Pandas and regular expressions</args></response>]\n",
      "[721] of [1000] [72.1%] [Run Google Scholar for Working with datetime in Pandas]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Working with datetime in Pandas</args></response>]\n",
      "[722] of [1000] [72.2%] [Use Google to search Runtime Error: Runtime exception occurred in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Runtime Error: Runtime exception occurred</args></response>]\n",
      "[723] of [1000] [72.3%] [Google Scholar, show Autonomous robotics]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Autonomous robotics</args></response>]\n",
      "[724] of [1000] [72.4%] [Carry out a search on Google for What are the common causes of runtime errors in Python, and how can they be debugged? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>What are the common causes of runtime errors in Python, and how can they be debugged?</args></response>]\n",
      "[725] of [1000] [72.5%] [Investigate What are the best practices to manage and prevent memory errors in Python applications? using Google from this locale]\n",
      "[<response><browser-command>search google current tab</browser-command><args>What are the best practices to manage and prevent memory errors in Python applications?</args></response>]\n",
      "[726] of [1000] [72.6%] [Key Error new tab search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Key Error</args></response>]\n",
      "[727] of [1000] [72.7%] [New tab, execute how to find a job online search]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to find a job online</args></response>]\n",
      "[728] of [1000] [72.8%] [Run Google search on AI-driven predictive maintenance and display in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI-driven predictive maintenance</args></response>]\n",
      "[729] of [1000] [72.9%] [In this tab, Google Scholar Deprecation Warning]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Deprecation Warning</args></response>]\n",
      "[730] of [1000] [73.0%] [New tab, search BufferError]\n",
      "[<response><browser-command>search new tab</browser-command><args>BufferError</args></response>]\n",
      "[731] of [1000] [73.1%] [Scope out Machine Learning in edtech on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Machine Learning in edtech</args></response>]\n",
      "[732] of [1000] [73.2%] [Start a Google search of Runtime Error: Runtime exception occurred in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Runtime Error: Runtime exception occurred</args></response>]\n",
      "[733] of [1000] [73.3%] [Google Scholar, best movies of all time now]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>best movies of all time</args></response>]\n",
      "[734] of [1000] [73.4%] [This tab: Search for How do you address deprecation warnings in Python to ensure code compatibility with future versions?]\n",
      "[<response><browser-command>search current tab</browser-command><args>How do you address deprecation warnings in Python to ensure code compatibility with future versions?</args></response>]\n",
      "[735] of [1000] [73.5%] [Open new tab: AI in agriculture technology search]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in agriculture technology</args></response>]\n",
      "[736] of [1000] [73.6%] [Perform a Google examination for BlockingIOError]\n",
      "[<response><browser-command>search google current tab</browser-command><args>BlockingIOError</args></response>]\n",
      "[737] of [1000] [73.7%] [Please open a new tab and search why stars twinkle on Google Scholar]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>why stars twinkle</args></response>]\n",
      "[738] of [1000] [73.8%] [Find Pandas DataFrame slicing on Google Scholar in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Pandas DataFrame slicing</args></response>]\n",
      "[739] of [1000] [73.9%] [Can you search for Bytes Warning in a new tab?]\n",
      "[<response><browser-command>search new tab</browser-command><args>Bytes Warning</args></response>]\n",
      "[740] of [1000] [74.0%] [Conduct a Google search on AI for personalized education in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI for personalized education</args></response>]\n",
      "[741] of [1000] [74.1%] [Launch Google Scholar for Merging strategies in Pandas]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Merging strategies in Pandas</args></response>]\n",
      "[742] of [1000] [74.2%] [Google Scholar search for latest space exploration news, new tab please]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>latest space exploration news</args></response>]\n",
      "[743] of [1000] [74.3%] [Google for DataFrame column operations in this viewport]\n",
      "[<response><browser-command>search google current tab</browser-command><args>DataFrame column operations</args></response>]\n",
      "[744] of [1000] [74.4%] [Check out How do you handle broken pipe errors in Python, especially in network communications? on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How do you handle broken pipe errors in Python, especially in network communications?</args></response>]\n",
      "[745] of [1000] [74.5%] [Launch a Google search for local weather update in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>local weather update</args></response>]\n",
      "[746] of [1000] [74.6%] [Run a Sorting data in Pandas DataFrame search in the active window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Sorting data in Pandas DataFrame</args></response>]\n",
      "[747] of [1000] [74.7%] [Perform Google Scholar search with ConnectionResetError in the current window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>ConnectionResetError</args></response>]\n",
      "[748] of [1000] [74.8%] [Execute how to care for succulents lookup in the current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>how to care for succulents</args></response>]\n",
      "[749] of [1000] [74.9%] [Run a scan for How do you prepare for future changes in Python indicated by future warnings? in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>How do you prepare for future changes in Python indicated by future warnings?</args></response>]\n",
      "[750] of [1000] [75.0%] [Search How do you address deprecation warnings in Python to ensure code compatibility with future versions? in another window]\n",
      "[<response><browser-command>search new tab</browser-command><args>How do you address deprecation warnings in Python to ensure code compatibility with future versions?</args></response>]\n",
      "[751] of [1000] [75.1%] [Use this tab to Google Unsorted Index Error: Index is unsorted]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Unsorted Index Error: Index is unsorted</args></response>]\n",
      "[752] of [1000] [75.2%] [Google Scholar best fashion brands, execute]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>best fashion brands</args></response>]\n",
      "[753] of [1000] [75.3%] [Open a new tab and find Machine Learning in edtech]\n",
      "[<response><browser-command>search new tab</browser-command><args>Machine Learning in edtech</args></response>]\n",
      "[754] of [1000] [75.4%] [Begin a new tab and search for latest science discoveries]\n",
      "[<response><browser-command>search new tab</browser-command><args>latest science discoveries</args></response>]\n",
      "[755] of [1000] [75.5%] [Look up Data partitioning in Pandas on Google Scholar in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Data partitioning in Pandas</args></response>]\n",
      "[756] of [1000] [75.6%] [New tab, carry out Google search on How can system exit errors be handled gracefully in Python applications?]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How can system exit errors be handled gracefully in Python applications?</args></response>]\n",
      "[757] of [1000] [75.7%] [Let's see the Google Scholar results for Generator Exit in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Generator Exit</args></response>]\n",
      "[758] of [1000] [75.8%] [Look up Recursion Error: Maximum recursion depth exceeded on Google Scholar in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Recursion Error: Maximum recursion depth exceeded</args></response>]\n",
      "[759] of [1000] [75.9%] [Pull up Unicode Warning: Unicode related warning in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Unicode Warning: Unicode related warning</args></response>]\n",
      "[760] of [1000] [76.0%] [Open new tab and perform why do we blink search]\n",
      "[<response><browser-command>search new tab</browser-command><args>why do we blink</args></response>]\n",
      "[761] of [1000] [76.1%] [Research Pandas DataFrame merging via Google Scholar in this tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Pandas DataFrame merging</args></response>]\n",
      "[762] of [1000] [76.2%] [Launch Google Scholar search for Data cleaning with Pandas, current tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Data cleaning with Pandas</args></response>]\n",
      "[763] of [1000] [76.3%] [Browse Google Scholar for FloatingPointError]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>FloatingPointError</args></response>]\n",
      "[764] of [1000] [76.4%] [Start a Google search of alternative music in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>alternative music</args></response>]\n",
      "[765] of [1000] [76.5%] [Search for Outlier Detection methods: What methods are most effective for outlier detection in univariate datasets? on Google in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Outlier Detection methods: What methods are most effective for outlier detection in univariate datasets?</args></response>]\n",
      "[766] of [1000] [76.6%] [Find Google Scholar results for Custom data readers in Pandas in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Custom data readers in Pandas</args></response>]\n",
      "[767] of [1000] [76.7%] [In the present tab, find AI and IoT integration]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI and IoT integration</args></response>]\n",
      "[768] of [1000] [76.8%] [Carry out Google search for top 10 action movies here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>top 10 action movies</args></response>]\n",
      "[769] of [1000] [76.9%] [Carry out a Google lookup for Image Recognition technologies, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Image Recognition technologies</args></response>]\n",
      "[770] of [1000] [77.0%] [Seek Data Cleaning techniques: What are the best practices for data cleaning in large datasets? in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Data Cleaning techniques: What are the best practices for data cleaning in large datasets?</args></response>]\n",
      "[771] of [1000] [77.1%] [Please conduct a Google search for ArithmeticError in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>ArithmeticError</args></response>]\n",
      "[772] of [1000] [77.2%] [Could you please Google Scholar Saving Pandas DataFrame to CSV in a new tab?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Saving Pandas DataFrame to CSV</args></response>]\n",
      "[773] of [1000] [77.3%] [Perform a new tab search on Google Scholar for Handling JSON data in Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Handling JSON data in Pandas</args></response>]\n",
      "[774] of [1000] [77.4%] [Runtime Warning in Google Scholar, please]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Runtime Warning</args></response>]\n",
      "[775] of [1000] [77.5%] [How do you prepare for future changes in Python indicated by future warnings? on Google Scholar here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>How do you prepare for future changes in Python indicated by future warnings?</args></response>]\n",
      "[776] of [1000] [77.6%] [Perform a Google Scholar search in a new tab for AI for personalized education: How does AI contribute to personalized education solutions?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI for personalized education: How does AI contribute to personalized education solutions?</args></response>]\n",
      "[777] of [1000] [77.7%] [Commence Google Scholar AI in digital marketing: What role does AI play in digital marketing strategies?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in digital marketing: What role does AI play in digital marketing strategies?</args></response>]\n",
      "[778] of [1000] [77.8%] [Reveal Named Entity Recognition: What approaches are commonly used for named entity recognition in NLP? results in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Named Entity Recognition: What approaches are commonly used for named entity recognition in NLP?</args></response>]\n",
      "[779] of [1000] [77.9%] [Probe Merging strategies in Pandas on Google from here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Merging strategies in Pandas</args></response>]\n",
      "[780] of [1000] [78.0%] [Visualizing data with Pandas, search Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Visualizing data with Pandas</args></response>]\n",
      "[781] of [1000] [78.1%] [New tab: run Bytes Warning: Bytecode issue search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Bytes Warning: Bytecode issue</args></response>]\n",
      "[782] of [1000] [78.2%] [Explore Pandas for data preprocessing in the current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Pandas for data preprocessing</args></response>]\n",
      "[783] of [1000] [78.3%] [Using Pandas in Jupyter Notebooks search, this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Using Pandas in Jupyter Notebooks</args></response>]\n",
      "[784] of [1000] [78.4%] [New tab, perform Keras neural network examples search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Keras neural network examples</args></response>]\n",
      "[785] of [1000] [78.5%] [What are user-defined warnings in Python, and how can they be effectively used? on Google Scholar, let's go]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are user-defined warnings in Python, and how can they be effectively used?</args></response>]\n",
      "[786] of [1000] [78.6%] [Find how to plant tomatoes on Google and show on this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to plant tomatoes</args></response>]\n",
      "[787] of [1000] [78.7%] [Start a Google Scholar search on Convolutional Neural Networks: What are the primary applications of convolutional neural networks in image processing? in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Convolutional Neural Networks: What are the primary applications of convolutional neural networks in image processing?</args></response>]\n",
      "[788] of [1000] [78.8%] [Browse for Machine Learning in logistics: How is machine learning improving logistics and supply chain management? on Google in this window]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Machine Learning in logistics: How is machine learning improving logistics and supply chain management?</args></response>]\n",
      "[789] of [1000] [78.9%] [Google OS Error: Operating system error and present it on this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>OS Error: Operating system error</args></response>]\n",
      "[790] of [1000] [79.0%] [Launch Google search for easy dinner recipes here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>easy dinner recipes</args></response>]\n",
      "[791] of [1000] [79.1%] [Show Runtime Error search outcome in current tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Runtime Error</args></response>]\n",
      "[792] of [1000] [79.2%] [Open a new tab and search Google for KeyError]\n",
      "[<response><browser-command>search google new tab</browser-command><args>KeyError</args></response>]\n",
      "[793] of [1000] [79.3%] [Google Scholar ArithmeticError, pull up in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ArithmeticError</args></response>]\n",
      "[794] of [1000] [79.4%] [Pull up Correlation analysis in Pandas results in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Correlation analysis in Pandas</args></response>]\n",
      "[795] of [1000] [79.5%] [Look up Google Scholar for funny jokes for kids, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>funny jokes for kids</args></response>]\n",
      "[796] of [1000] [79.6%] [Current window: Locate best beaches in the world]\n",
      "[<response><browser-command>search current tab</browser-command><args>best beaches in the world</args></response>]\n",
      "[797] of [1000] [79.7%] [Query for How do you fix indentation errors that affect code structure in Python? in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>How do you fix indentation errors that affect code structure in Python?</args></response>]\n",
      "[798] of [1000] [79.8%] [Here, Google Scholar Stop Iteration: Iteration stopped]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Stop Iteration: Iteration stopped</args></response>]\n",
      "[799] of [1000] [79.9%] [Do a Google search, keywords: best sci-fi novels]\n",
      "[<response><browser-command>search google current tab</browser-command><args>best sci-fi novels</args></response>]\n",
      "[800] of [1000] [80.0%] [AI in legal tech: What is the impact of AI on the legal tech industry?, let's do Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in legal tech: What is the impact of AI on the legal tech industry?</args></response>]\n",
      "[801] of [1000] [80.1%] [Google Scholar Using Pandas for predictive modeling, execute]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Using Pandas for predictive modeling</args></response>]\n",
      "[802] of [1000] [80.2%] [New tab: run AI for customer service automation: How is AI used to automate customer service interactions? search]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI for customer service automation: How is AI used to automate customer service interactions?</args></response>]\n",
      "[803] of [1000] [80.3%] [Open new tab, search for how to fix a leaky faucet]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to fix a leaky faucet</args></response>]\n",
      "[804] of [1000] [80.4%] [Google ZeroDivisionError and display in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>ZeroDivisionError</args></response>]\n",
      "[805] of [1000] [80.5%] [Check out UserWarning on Google from this locale]\n",
      "[<response><browser-command>search google current tab</browser-command><args>UserWarning</args></response>]\n",
      "[806] of [1000] [80.6%] [Display Precision-Recall trade-off: In what scenarios is the precision-recall trade-off critical in model evaluation? results in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Precision-Recall trade-off: In what scenarios is the precision-recall trade-off critical in model evaluation?</args></response>]\n",
      "[807] of [1000] [80.7%] [Look up why cats purr on Google in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>why cats purr</args></response>]\n",
      "[808] of [1000] [80.8%] [Creating scatter plots with Pandas new tab search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Creating scatter plots with Pandas</args></response>]\n",
      "[809] of [1000] [80.9%] [Look up Data Cleaning techniques: What are the best practices for data cleaning in large datasets? here]\n",
      "[<response><browser-command>search current tab</browser-command><args>Data Cleaning techniques: What are the best practices for data cleaning in large datasets?</args></response>]\n",
      "[810] of [1000] [81.0%] [Show Google search results of Unbound Local Error: Local variable referenced before assignment in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Unbound Local Error: Local variable referenced before assignment</args></response>]\n",
      "[811] of [1000] [81.1%] [Search in a new tab: HTTPError]\n",
      "[<response><browser-command>search new tab</browser-command><args>HTTPError</args></response>]\n",
      "[812] of [1000] [81.2%] [Conduct a Google search on What are the steps to resolve permission-related errors in file operations in Python?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>What are the steps to resolve permission-related errors in file operations in Python?</args></response>]\n",
      "[813] of [1000] [81.3%] [New tab, Google ReferenceError, reveal results]\n",
      "[<response><browser-command>search google new tab</browser-command><args>ReferenceError</args></response>]\n",
      "[814] of [1000] [81.4%] [Google Scholar, show photography tips]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>photography tips</args></response>]\n",
      "[815] of [1000] [81.5%] [Google Scholar NotImplementedError, engage]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>NotImplementedError</args></response>]\n",
      "[816] of [1000] [81.6%] [Show me KeyboardInterrupt results in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>KeyboardInterrupt</args></response>]\n",
      "[817] of [1000] [81.7%] [New tab, conduct Google search on Out Of Bounds Timedelta: Out of bounds for timedelta]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Out Of Bounds Timedelta: Out of bounds for timedelta</args></response>]\n",
      "[818] of [1000] [81.8%] [Do a Google exploration for UnicodeEncodeError]\n",
      "[<response><browser-command>search google current tab</browser-command><args>UnicodeEncodeError</args></response>]\n",
      "[819] of [1000] [81.9%] [Could you search Using Pandas in web development in another tab?]\n",
      "[<response><browser-command>search new tab</browser-command><args>Using Pandas in web development</args></response>]\n",
      "[820] of [1000] [82.0%] [Discover AI in content moderation: How is AI used for content moderation on digital platforms? in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI in content moderation: How is AI used for content moderation on digital platforms?</args></response>]\n",
      "[821] of [1000] [82.1%] [In a new tab, please Google Scholar search AI for social good initiatives: What are some notable AI for social good initiatives?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI for social good initiatives: What are some notable AI for social good initiatives?</args></response>]\n",
      "[822] of [1000] [82.2%] [Google Scholar exchange rates today in the current tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>exchange rates today</args></response>]\n",
      "[823] of [1000] [82.3%] [Scour this tab for BERT architecture: How has the BERT architecture advanced the field of natural language understanding?]\n",
      "[<response><browser-command>search current tab</browser-command><args>BERT architecture: How has the BERT architecture advanced the field of natural language understanding?</args></response>]\n",
      "[824] of [1000] [82.4%] [Open new tab: find AI for personalized education: How does AI contribute to personalized education solutions?]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI for personalized education: How does AI contribute to personalized education solutions?</args></response>]\n",
      "[825] of [1000] [82.5%] [Please conduct a Google search for AWS SageMaker for ML in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AWS SageMaker for ML</args></response>]\n",
      "[826] of [1000] [82.6%] [Seek How do you handle situations where a feature or method is not yet implemented in Python? via Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>How do you handle situations where a feature or method is not yet implemented in Python?</args></response>]\n",
      "[827] of [1000] [82.7%] [Please find Unbound Local Error: Local variable referenced before assignment in Google Scholar, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Unbound Local Error: Local variable referenced before assignment</args></response>]\n",
      "[828] of [1000] [82.8%] [Google Scholar, show why does coffee stain teeth]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>why does coffee stain teeth</args></response>]\n",
      "[829] of [1000] [82.9%] [Make an enquiry for Responsible AI practices: How can organizations implement responsible AI practices? and display the output]\n",
      "[<response><browser-command>search current tab</browser-command><args>Responsible AI practices: How can organizations implement responsible AI practices?</args></response>]\n",
      "[830] of [1000] [83.0%] [New tab, run a Google lookup for Apache Spark data processing]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Apache Spark data processing</args></response>]\n",
      "[831] of [1000] [83.1%] [Run a new tab and Google Scholar ImportWarning]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ImportWarning</args></response>]\n",
      "[832] of [1000] [83.2%] [Search top 10 universities in the world in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>top 10 universities in the world</args></response>]\n",
      "[833] of [1000] [83.3%] [New tab, run a Google lookup for Resource Warning: Resource usage warning]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Resource Warning: Resource usage warning</args></response>]\n",
      "[834] of [1000] [83.4%] [Bring up Google Scholar for how to improve public speaking skills in this window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how to improve public speaking skills</args></response>]\n",
      "[835] of [1000] [83.5%] [In a new tab, perform a Google search of classic rock music]\n",
      "[<response><browser-command>search google new tab</browser-command><args>classic rock music</args></response>]\n",
      "[836] of [1000] [83.6%] [Look for File Exists Error, new tab please]\n",
      "[<response><browser-command>search new tab</browser-command><args>File Exists Error</args></response>]\n",
      "[837] of [1000] [83.7%] [Inspect top 10 Netflix series on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>top 10 Netflix series</args></response>]\n",
      "[838] of [1000] [83.8%] [Explore Future Warning: Future change warning on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Future Warning: Future change warning</args></response>]\n",
      "[839] of [1000] [83.9%] [Perform a new tab search on Google Scholar for Responsible AI practices: How can organizations implement responsible AI practices?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Responsible AI practices: How can organizations implement responsible AI practices?</args></response>]\n",
      "[840] of [1000] [84.0%] [Perform Google search for AI in climate change research: How is AI contributing to climate change research?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in climate change research: How is AI contributing to climate change research?</args></response>]\n",
      "[841] of [1000] [84.1%] [Proceed to search Performance Warning: DataFrame is highly fragmented in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Performance Warning: DataFrame is highly fragmented</args></response>]\n",
      "[842] of [1000] [84.2%] [Initiate a Google Scholar search for FloatingPointError, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>FloatingPointError</args></response>]\n",
      "[843] of [1000] [84.3%] [In the present tab, perform a Google Scholar search for Apache Spark data processing: How does Apache Spark handle large-scale data processing efficiently?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Apache Spark data processing: How does Apache Spark handle large-scale data processing efficiently?</args></response>]\n",
      "[844] of [1000] [84.4%] [Conduct a Google search on PyTorch vs. TensorFlow comparison in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>PyTorch vs. TensorFlow comparison</args></response>]\n",
      "[845] of [1000] [84.5%] [New tab, Google Scholar famous historical events]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>famous historical events</args></response>]\n",
      "[846] of [1000] [84.6%] [Find me OS Error on Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>OS Error</args></response>]\n",
      "[847] of [1000] [84.7%] [Google Scholar search in a new tab, Scaling and normalizing data in Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Scaling and normalizing data in Pandas</args></response>]\n",
      "[848] of [1000] [84.8%] [Discover ConnectionResetError in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>ConnectionResetError</args></response>]\n",
      "[849] of [1000] [84.9%] [Uncover How do you address deprecation warnings in Python to ensure code compatibility with future versions? in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>How do you address deprecation warnings in Python to ensure code compatibility with future versions?</args></response>]\n",
      "[850] of [1000] [85.0%] [In this tab, locate Warning]\n",
      "[<response><browser-command>search current tab</browser-command><args>Warning</args></response>]\n",
      "[851] of [1000] [85.1%] [Search for Handling JSON data in Pandas on Google Scholar, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Handling JSON data in Pandas</args></response>]\n",
      "[852] of [1000] [85.2%] [Launch latest space exploration news search in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>latest space exploration news</args></response>]\n",
      "[853] of [1000] [85.3%] [Present window: Search Combining datasets with Pandas]\n",
      "[<response><browser-command>search current tab</browser-command><args>Combining datasets with Pandas</args></response>]\n",
      "[854] of [1000] [85.4%] [Search and show latest space exploration news in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>latest space exploration news</args></response>]\n",
      "[855] of [1000] [85.5%] [Please start a Google search for AI and blockchain integration in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI and blockchain integration</args></response>]\n",
      "[856] of [1000] [85.6%] [Seek FloatingPointError on Google in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>FloatingPointError</args></response>]\n",
      "[857] of [1000] [85.7%] [Discover best travel destinations in Asia in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>best travel destinations in Asia</args></response>]\n",
      "[858] of [1000] [85.8%] [Search google Pandas memory optimization in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Pandas memory optimization</args></response>]\n",
      "[859] of [1000] [85.9%] [Google for why is the sky blue in this viewport]\n",
      "[<response><browser-command>search google current tab</browser-command><args>why is the sky blue</args></response>]\n",
      "[860] of [1000] [86.0%] [Initiate search: Deep Reinforcement Learning: What are some of the breakthroughs achieved with deep reinforcement learning in recent years?, new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Deep Reinforcement Learning: What are some of the breakthroughs achieved with deep reinforcement learning in recent years?</args></response>]\n",
      "[861] of [1000] [86.1%] [Tab: Conduct What are the best practices for handling reset connections in network communications in Python? search]\n",
      "[<response><browser-command>search current tab</browser-command><args>What are the best practices for handling reset connections in network communications in Python?</args></response>]\n",
      "[862] of [1000] [86.2%] [Please open a new tab and search IsADirectoryError on Google Scholar]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>IsADirectoryError</args></response>]\n",
      "[863] of [1000] [86.3%] [New tab, start a Google search for OS Error: Operating system error]\n",
      "[<response><browser-command>search google new tab</browser-command><args>OS Error: Operating system error</args></response>]\n",
      "[864] of [1000] [86.4%] [Google Scholar, initiate Generating summary statistics in Pandas]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Generating summary statistics in Pandas</args></response>]\n",
      "[865] of [1000] [86.5%] [Commence a Google Scholar search for AI in smart cities: How are smart cities utilizing AI to improve urban living? in this window]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in smart cities: How are smart cities utilizing AI to improve urban living?</args></response>]\n",
      "[866] of [1000] [86.6%] [Google for Integrating Pandas with APIs in this viewport]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Integrating Pandas with APIs</args></response>]\n",
      "[867] of [1000] [86.7%] [Current tab: Search and display results for Reference Error: Weak reference object no longer exists]\n",
      "[<response><browser-command>search current tab</browser-command><args>Reference Error: Weak reference object no longer exists</args></response>]\n",
      "[868] of [1000] [86.8%] [Fetch Combining datasets with Pandas results in current window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Combining datasets with Pandas</args></response>]\n",
      "[869] of [1000] [86.9%] [Google HTML vs CSS, results in this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>HTML vs CSS</args></response>]\n",
      "[870] of [1000] [87.0%] [Use Google Scholar to search ImportWarning in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>ImportWarning</args></response>]\n",
      "[871] of [1000] [87.1%] [Get Google Scholar to search Sequential data processing in Pandas, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Sequential data processing in Pandas</args></response>]\n",
      "[872] of [1000] [87.2%] [Run Google Scholar for AI transparency initiatives: What initiatives are being taken to improve transparency in AI?, new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI transparency initiatives: What initiatives are being taken to improve transparency in AI?</args></response>]\n",
      "[873] of [1000] [87.3%] [Bring up Google Scholar, Machine Learning in logistics: How is machine learning improving logistics and supply chain management?, in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Machine Learning in logistics: How is machine learning improving logistics and supply chain management?</args></response>]\n",
      "[874] of [1000] [87.4%] [Google Scholar Machine Learning in biotech, current tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Machine Learning in biotech</args></response>]\n",
      "[875] of [1000] [87.5%] [Locate Efficient file reading with Pandas via Google in the current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Efficient file reading with Pandas</args></response>]\n",
      "[876] of [1000] [87.6%] [Search in this tab for Runtime Error: Runtime exception occurred]\n",
      "[<response><browser-command>search current tab</browser-command><args>Runtime Error: Runtime exception occurred</args></response>]\n",
      "[877] of [1000] [87.7%] [Scan for Resource Warning in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Resource Warning</args></response>]\n",
      "[878] of [1000] [87.8%] [Initiate a Google lookup in a new tab for how to meditate]\n",
      "[<response><browser-command>search google new tab</browser-command><args>how to meditate</args></response>]\n",
      "[879] of [1000] [87.9%] [Open a new tab and do a Google search for how to make pizza dough]\n",
      "[<response><browser-command>search google new tab</browser-command><args>how to make pizza dough</args></response>]\n",
      "[880] of [1000] [88.0%] [Display search results in a new tab, keywords: Deep Learning optimization]\n",
      "[<response><browser-command>search new tab</browser-command><args>Deep Learning optimization</args></response>]\n",
      "[881] of [1000] [88.1%] [Run weather forecast washington dc search in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>weather forecast washington dc</args></response>]\n",
      "[882] of [1000] [88.2%] [Google for Sorting data in Pandas DataFrame in this viewport]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Sorting data in Pandas DataFrame</args></response>]\n",
      "[883] of [1000] [88.3%] [Start a new tab, do a Google search for Machine Learning in cybersecurity]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Machine Learning in cybersecurity</args></response>]\n",
      "[884] of [1000] [88.4%] [Google Scholar Data Science career trends, start]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Data Science career trends</args></response>]\n",
      "[885] of [1000] [88.5%] [New tab: run best hiking shoes search]\n",
      "[<response><browser-command>search new tab</browser-command><args>best hiking shoes</args></response>]\n",
      "[886] of [1000] [88.6%] [Conduct a Google Scholar search for Exporting data from Pandas to Excel in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Exporting data from Pandas to Excel</args></response>]\n",
      "[887] of [1000] [88.7%] [Locate latest space exploration news results in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>latest space exploration news</args></response>]\n",
      "[888] of [1000] [88.8%] [Google Scholar, initiate UserWarning]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>UserWarning</args></response>]\n",
      "[889] of [1000] [88.9%] [Start a new tab, then Google search Efficient file reading with Pandas]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Efficient file reading with Pandas</args></response>]\n",
      "[890] of [1000] [89.0%] [Perform a Google inquiry for healthy meal ideas]\n",
      "[<response><browser-command>search google current tab</browser-command><args>healthy meal ideas</args></response>]\n",
      "[891] of [1000] [89.1%] [Google AI and blockchain integration: What are the benefits of integrating AI with blockchain technology?, display in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI and blockchain integration: What are the benefits of integrating AI with blockchain technology?</args></response>]\n",
      "[892] of [1000] [89.2%] [Start a search on AI in human resources: What are the applications of AI in human resources management? in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in human resources: What are the applications of AI in human resources management?</args></response>]\n",
      "[893] of [1000] [89.3%] [Render Google search results for AI in sports analytics: How is AI used in sports analytics to improve performance? in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI in sports analytics: How is AI used in sports analytics to improve performance?</args></response>]\n",
      "[894] of [1000] [89.4%] [Now, Google Scholar Machine Learning model deployment: What are the best practices for deploying machine learning models in production?]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Machine Learning model deployment: What are the best practices for deploying machine learning models in production?</args></response>]\n",
      "[895] of [1000] [89.5%] [Explore Data wrangling with Pandas on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Data wrangling with Pandas</args></response>]\n",
      "[896] of [1000] [89.6%] [Commence search for What are bytes warnings in Python, and how are they significant in data handling? in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>What are bytes warnings in Python, and how are they significant in data handling?</args></response>]\n",
      "[897] of [1000] [89.7%] [Show me Google Scholar results for AI in agriculture technology in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI in agriculture technology</args></response>]\n",
      "[898] of [1000] [89.8%] [Open a new tab, find Responsible AI practices: How can organizations implement responsible AI practices? on Google Scholar]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Responsible AI practices: How can organizations implement responsible AI practices?</args></response>]\n",
      "[899] of [1000] [89.9%] [Google Scholar how to make pizza dough, engage]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how to make pizza dough</args></response>]\n",
      "[900] of [1000] [90.0%] [Scan Pandas and regular expressions in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Pandas and regular expressions</args></response>]\n",
      "[901] of [1000] [90.1%] [Show me AI-driven recommendation systems on Google Scholar]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI-driven recommendation systems</args></response>]\n",
      "[902] of [1000] [90.2%] [Google Azure Machine Learning platform within this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Azure Machine Learning platform</args></response>]\n",
      "[903] of [1000] [90.3%] [Google Scholar, show Runtime Warning]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Runtime Warning</args></response>]\n",
      "[904] of [1000] [90.4%] [Look up NameError on Google here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>NameError</args></response>]\n",
      "[905] of [1000] [90.5%] [Pull up best vegan restaurants in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>best vegan restaurants</args></response>]\n",
      "[906] of [1000] [90.6%] [What are user-defined warnings in Python, and how can they be effectively used?, Google it, open in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>What are user-defined warnings in Python, and how can they be effectively used?</args></response>]\n",
      "[907] of [1000] [90.7%] [Start another tab and search for current news in business]\n",
      "[<response><browser-command>search new tab</browser-command><args>current news in business</args></response>]\n",
      "[908] of [1000] [90.8%] [Commence current global news search in another tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>current global news</args></response>]\n",
      "[909] of [1000] [90.9%] [Reference Error: Weak reference object no longer exists new tab search]\n",
      "[<response><browser-command>search new tab</browser-command><args>Reference Error: Weak reference object no longer exists</args></response>]\n",
      "[910] of [1000] [91.0%] [Google top 10 songs of all time and display in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>top 10 songs of all time</args></response>]\n",
      "[911] of [1000] [91.1%] [Search for Explainable AI on Google in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Explainable AI</args></response>]\n",
      "[912] of [1000] [91.2%] [Do a Google search of popular movie genres in a fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>popular movie genres</args></response>]\n",
      "[913] of [1000] [91.3%] [In a new tab, Google search for Data Science career trends]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Data Science career trends</args></response>]\n",
      "[914] of [1000] [91.4%] [Execute a search for Reading CSV files in Pandas in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>Reading CSV files in Pandas</args></response>]\n",
      "[915] of [1000] [91.5%] [Search and show funny memes in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>funny memes</args></response>]\n",
      "[916] of [1000] [91.6%] [Google Syntax Warning: Syntax issue warning and present it on this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Syntax Warning: Syntax issue warning</args></response>]\n",
      "[917] of [1000] [91.7%] [Go find what does blah blah blah mean on Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>what does blah blah blah mean</args></response>]\n",
      "[918] of [1000] [91.8%] [Begin Google Scholar how do i cure dandruff? in this tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>how do i cure dandruff?</args></response>]\n",
      "[919] of [1000] [91.9%] [In a fresh tab, perform a Google search of TabError]\n",
      "[<response><browser-command>search google new tab</browser-command><args>TabError</args></response>]\n",
      "[920] of [1000] [92.0%] [Pull up AI ethics in research: What are the key ethical considerations in AI research? in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI ethics in research: What are the key ethical considerations in AI research?</args></response>]\n",
      "[921] of [1000] [92.1%] [Do a Google search, keywords: Out Of Bounds Timedelta: Out of bounds for timedelta]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Out Of Bounds Timedelta: Out of bounds for timedelta</args></response>]\n",
      "[922] of [1000] [92.2%] [Google Scholar What are common causes and solutions for errors related to incorrect syntax in Python? in this location]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>What are common causes and solutions for errors related to incorrect syntax in Python?</args></response>]\n",
      "[923] of [1000] [92.3%] [New tab, Google Scholar AI in human resources: What are the applications of AI in human resources management?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI in human resources: What are the applications of AI in human resources management?</args></response>]\n",
      "[924] of [1000] [92.4%] [Search AI patent trends and open in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI patent trends</args></response>]\n",
      "[925] of [1000] [92.5%] [Hunt Ruby on Rails tutorial in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Ruby on Rails tutorial</args></response>]\n",
      "[926] of [1000] [92.6%] [Show me healthy snack ideas in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>healthy snack ideas</args></response>]\n",
      "[927] of [1000] [92.7%] [Probe how does electricity work? using Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how does electricity work?</args></response>]\n",
      "[928] of [1000] [92.8%] [Start a new tab and perform Google Scholar search for Rolling and expanding windows in Pandas]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Rolling and expanding windows in Pandas</args></response>]\n",
      "[929] of [1000] [92.9%] [In a new tab, carry out a Google search for Pending Deprecation Warning]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Pending Deprecation Warning</args></response>]\n",
      "[930] of [1000] [93.0%] [Google Scholar How do you prepare for future changes in Python indicated by future warnings?, engage]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>How do you prepare for future changes in Python indicated by future warnings?</args></response>]\n",
      "[931] of [1000] [93.1%] [Do search for how to knit a sweater, new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to knit a sweater</args></response>]\n",
      "[932] of [1000] [93.2%] [Do a Google Scholar Runtime Error: Runtime exception occurred search in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Runtime Error: Runtime exception occurred</args></response>]\n",
      "[933] of [1000] [93.3%] [Execute a search on Google for How do you address deprecation warnings in Python to ensure code compatibility with future versions?, display in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>How do you address deprecation warnings in Python to ensure code compatibility with future versions?</args></response>]\n",
      "[934] of [1000] [93.4%] [Show Google Scholar healthy meal ideas in the present tab]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>healthy meal ideas</args></response>]\n",
      "[935] of [1000] [93.5%] [Show Google Scholar results for Setting and resetting index in Pandas in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Setting and resetting index in Pandas</args></response>]\n",
      "[936] of [1000] [93.6%] [Generate a new tab, search i want new shoes]\n",
      "[<response><browser-command>search new tab</browser-command><args>i want new shoes</args></response>]\n",
      "[937] of [1000] [93.7%] [Display Quantum AI computing developments: What are the latest developments in quantum AI computing? findings in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>Quantum AI computing developments: What are the latest developments in quantum AI computing?</args></response>]\n",
      "[938] of [1000] [93.8%] [Look up AI patent trends: What are the current trends in AI patents? on Google here]\n",
      "[<response><browser-command>search google current tab</browser-command><args>AI patent trends: What are the current trends in AI patents?</args></response>]\n",
      "[939] of [1000] [93.9%] [Explore Google Scholar with Creating histograms in Pandas here]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Creating histograms in Pandas</args></response>]\n",
      "[940] of [1000] [94.0%] [Initiate Google search for System Error: Internal Python system issue in a novel tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>System Error: Internal Python system issue</args></response>]\n",
      "[941] of [1000] [94.1%] [AI in autonomous vehicles - hunt and present in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI in autonomous vehicles</args></response>]\n",
      "[942] of [1000] [94.2%] [Perform and exhibit how to save money search]\n",
      "[<response><browser-command>search current tab</browser-command><args>how to save money</args></response>]\n",
      "[943] of [1000] [94.3%] [Check out Responsible AI practices: How can organizations implement responsible AI practices? on Google from this locale]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Responsible AI practices: How can organizations implement responsible AI practices?</args></response>]\n",
      "[944] of [1000] [94.4%] [Run a new tab, Google search Syntax Warning]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Syntax Warning</args></response>]\n",
      "[945] of [1000] [94.5%] [Pending Deprecation Warning Google Scholar, now]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Pending Deprecation Warning</args></response>]\n",
      "[946] of [1000] [94.6%] [Begin a Google lookup for What are the reasons for attribute-related errors in Python objects and how can they be fixed? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>What are the reasons for attribute-related errors in Python objects and how can they be fixed?</args></response>]\n",
      "[947] of [1000] [94.7%] [New tab, lookup for Converting data types in Pandas]\n",
      "[<response><browser-command>search new tab</browser-command><args>Converting data types in Pandas</args></response>]\n",
      "[948] of [1000] [94.8%] [Execute Google Scholar search for learning Italian online in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>learning Italian online</args></response>]\n",
      "[949] of [1000] [94.9%] [Pull up why we dream results in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>why we dream</args></response>]\n",
      "[950] of [1000] [95.0%] [In a new tab, carry out a search on Google for how to write a resume]\n",
      "[<response><browser-command>search google new tab</browser-command><args>how to write a resume</args></response>]\n",
      "[951] of [1000] [95.1%] [Scan for SyntaxWarning in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>SyntaxWarning</args></response>]\n",
      "[952] of [1000] [95.2%] [Present tab: Look for How do you prepare for future changes in Python indicated by future warnings?]\n",
      "[<response><browser-command>search current tab</browser-command><args>How do you prepare for future changes in Python indicated by future warnings?</args></response>]\n",
      "[953] of [1000] [95.3%] [Begin a new tab, then Google search Environment Error]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Environment Error</args></response>]\n",
      "[954] of [1000] [95.4%] [Start a Google lookup for DeprecationWarning in a fresh tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>DeprecationWarning</args></response>]\n",
      "[955] of [1000] [95.5%] [Run a Google inquiry for Deep Learning optimization]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Deep Learning optimization</args></response>]\n",
      "[956] of [1000] [95.6%] [Please run a Google search for What approaches can be taken to fix attribute errors that arise when an attribute or method is not found on an object in Python? in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>What approaches can be taken to fix attribute errors that arise when an attribute or method is not found on an object in Python?</args></response>]\n",
      "[957] of [1000] [95.7%] [Use this tab to Google Recurrent Neural Networks: How are recurrent neural networks uniquely suited for processing sequential data?]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Recurrent Neural Networks: How are recurrent neural networks uniquely suited for processing sequential data?</args></response>]\n",
      "[958] of [1000] [95.8%] [Open new tab, Google IBM Watson AI tools]\n",
      "[<response><browser-command>search google new tab</browser-command><args>IBM Watson AI tools</args></response>]\n",
      "[959] of [1000] [95.9%] [Pull up How do you address issues related to assigning incorrect values to variables in Python? results in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>How do you address issues related to assigning incorrect values to variables in Python?</args></response>]\n",
      "[960] of [1000] [96.0%] [Launch another tab, search AI in smart cities: How are smart cities utilizing AI to improve urban living?]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in smart cities: How are smart cities utilizing AI to improve urban living?</args></response>]\n",
      "[961] of [1000] [96.1%] [Generate a new tab, search Filtering data in Pandas DataFrame]\n",
      "[<response><browser-command>search new tab</browser-command><args>Filtering data in Pandas DataFrame</args></response>]\n",
      "[962] of [1000] [96.2%] [Google search in a new tab, keywords: Arithmetic Error]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Arithmetic Error</args></response>]\n",
      "[963] of [1000] [96.3%] [Start GANs recent advancements search in another tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>GANs recent advancements</args></response>]\n",
      "[964] of [1000] [96.4%] [Launch a Google query for Integrating Pandas with APIs in current tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Integrating Pandas with APIs</args></response>]\n",
      "[965] of [1000] [96.5%] [Carry out a Google lookup for Handling duplicate data in Pandas, results in new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Handling duplicate data in Pandas</args></response>]\n",
      "[966] of [1000] [96.6%] [Google Using Pandas for ETL processes within this tab]\n",
      "[<response><browser-command>search google current tab</browser-command><args>Using Pandas for ETL processes</args></response>]\n",
      "[967] of [1000] [96.7%] [Research how to be more productive via Google from this position]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to be more productive</args></response>]\n",
      "[968] of [1000] [96.8%] [Find Google Scholar results for AI ethics in research in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>AI ethics in research</args></response>]\n",
      "[969] of [1000] [96.9%] [Reveal User Warning: User-defined warning in this window]\n",
      "[<response><browser-command>search current tab</browser-command><args>User Warning: User-defined warning</args></response>]\n",
      "[970] of [1000] [97.0%] [Study DIY home decor ideas on Google in this area]\n",
      "[<response><browser-command>search google current tab</browser-command><args>DIY home decor ideas</args></response>]\n",
      "[971] of [1000] [97.1%] [Launch AI in video analysis search in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in video analysis</args></response>]\n",
      "[972] of [1000] [97.2%] [In this tab, Google the terms DIY home decor ideas]\n",
      "[<response><browser-command>search google current tab</browser-command><args>DIY home decor ideas</args></response>]\n",
      "[973] of [1000] [97.3%] [Google Scholar Supervised vs. Unsupervised Learning, let's go]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Supervised vs. Unsupervised Learning</args></response>]\n",
      "[974] of [1000] [97.4%] [This screen, Google Scholar URL Error]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>URL Error</args></response>]\n",
      "[975] of [1000] [97.5%] [Initiate Google Scholar Scaling and normalizing data in Pandas in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Scaling and normalizing data in Pandas</args></response>]\n",
      "[976] of [1000] [97.6%] [Google Using Pandas for ETL processes, open results in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>Using Pandas for ETL processes</args></response>]\n",
      "[977] of [1000] [97.7%] [Could you search Deprecation Warning in another tab?]\n",
      "[<response><browser-command>search new tab</browser-command><args>Deprecation Warning</args></response>]\n",
      "[978] of [1000] [97.8%] [Please show Applying functions to Pandas DataFrame in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Applying functions to Pandas DataFrame</args></response>]\n",
      "[979] of [1000] [97.9%] [Open a new tab, find InterruptedError]\n",
      "[<response><browser-command>search new tab</browser-command><args>InterruptedError</args></response>]\n",
      "[980] of [1000] [98.0%] [Examine System Error: Internal Python system issue via Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>System Error: Internal Python system issue</args></response>]\n",
      "[981] of [1000] [98.1%] [Google Scholar Syntax Warning, start]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Syntax Warning</args></response>]\n",
      "[982] of [1000] [98.2%] [Start a search on Connection Error in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Connection Error</args></response>]\n",
      "[983] of [1000] [98.3%] [Please open a new tab and search how to meditate]\n",
      "[<response><browser-command>search new tab</browser-command><args>how to meditate</args></response>]\n",
      "[984] of [1000] [98.4%] [Hunt current health news in another tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>current health news</args></response>]\n",
      "[985] of [1000] [98.5%] [Now, Google Scholar AI in e-commerce personalization]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>AI in e-commerce personalization</args></response>]\n",
      "[986] of [1000] [98.6%] [In a new tab, carry out a Google search for how to stay motivated]\n",
      "[<response><browser-command>search google new tab</browser-command><args>how to stay motivated</args></response>]\n",
      "[987] of [1000] [98.7%] [Generate a new tab, search Correlation analysis in Pandas]\n",
      "[<response><browser-command>search new tab</browser-command><args>Correlation analysis in Pandas</args></response>]\n",
      "[988] of [1000] [98.8%] [Unearth AI in legal tech in this tab]\n",
      "[<response><browser-command>search current tab</browser-command><args>AI in legal tech</args></response>]\n",
      "[989] of [1000] [98.9%] [Start new tab, execute OpenAI latest projects: What are the latest projects undertaken by OpenAI? search]\n",
      "[<response><browser-command>search new tab</browser-command><args>OpenAI latest projects: What are the latest projects undertaken by OpenAI?</args></response>]\n",
      "[990] of [1000] [99.0%] [Open a fresh tab, search Google Scholar for Google Cloud AI services: What AI services does Google Cloud offer for developers and data scientists?]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Google Cloud AI services: What AI services does Google Cloud offer for developers and data scientists?</args></response>]\n",
      "[991] of [1000] [99.1%] [Check out what is the meaning of life? on Google from this locale]\n",
      "[<response><browser-command>search google current tab</browser-command><args>what is the meaning of life?</args></response>]\n",
      "[992] of [1000] [99.2%] [Please conduct a Google Scholar search for Frequency conversion in time series data in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>Frequency conversion in time series data</args></response>]\n",
      "[993] of [1000] [99.3%] [Conduct a Google search on top 10 movies of all time in a new tab]\n",
      "[<response><browser-command>search google new tab</browser-command><args>top 10 movies of all time</args></response>]\n",
      "[994] of [1000] [99.4%] [Carry out a Google search in a new tab for AI for speech synthesis]\n",
      "[<response><browser-command>search google new tab</browser-command><args>AI for speech synthesis</args></response>]\n",
      "[995] of [1000] [99.5%] [Execute Google Scholar Warning]\n",
      "[<response><browser-command>search google scholar current tab</browser-command><args>Warning</args></response>]\n",
      "[996] of [1000] [99.6%] [Run a Google investigation for how to stay motivated]\n",
      "[<response><browser-command>search google current tab</browser-command><args>how to stay motivated</args></response>]\n",
      "[997] of [1000] [99.7%] [Show Google Scholar results for healthy meal ideas in a new tab]\n",
      "[<response><browser-command>search google scholar new tab</browser-command><args>healthy meal ideas</args></response>]\n",
      "[998] of [1000] [99.8%] [Search AI in agriculture technology and open in new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>AI in agriculture technology</args></response>]\n",
      "[999] of [1000] [99.9%] [Kindly look for Attribute Error in a new tab]\n",
      "[<response><browser-command>search new tab</browser-command><args>Attribute Error</args></response>]\n",
      "[1000] of [1000] [100.0%] [Seek what are vitamins and minerals? via Google]\n",
      "[<response><browser-command>search google current tab</browser-command><args>what are vitamins and minerals?</args></response>]\n"
     ]
    }
   ],
   "source": [
    "responses = [ ]\n",
    "for idx, question in enumerate( questions ):\n",
    "    # Display progress every nth iteration\n",
    "    print( f\"[{idx + 1}] of [{len( questions )}] [{( ( idx + 1 ) / len( questions ) ) * 100:.1f}%] [{question}]\" )\n",
    "    response = generate_text( tokenizer, adapter_plus_model, question )\n",
    "    response = re.sub( r'>\\s+<', '><', response )\n",
    "    print( f\"[{response}]\" )\n",
    "    responses.append( response )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T22:14:25.546026Z",
     "start_time": "2023-12-21T20:44:46.133294Z"
    }
   },
   "id": "e641d66989b265ca"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( responses )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T22:14:25.568570Z",
     "start_time": "2023-12-21T22:14:25.561065Z"
    }
   },
   "id": "a05b5f377ca0be59"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         instruction  \\\n0  Your job is to discern the intent of a human v...   \n1  Your job is to discern the intent of a human v...   \n2  Your job is to discern the intent of a human v...   \n3  Your job is to discern the intent of a human v...   \n4  Your job is to discern the intent of a human v...   \n\n                                               input  \\\n0  \\n        Below is the raw human voice command...   \n1  \\n        Below is the raw human voice command...   \n2  \\n        Below is the raw human voice command...   \n3  \\n        Below is the raw human voice command...   \n4  \\n        Below is the raw human voice command...   \n\n                                              output  \\\n0  \\n        <response>\\n            <browser-com...   \n1  \\n        <response>\\n            <browser-com...   \n2  \\n        <response>\\n            <browser-com...   \n3  \\n        <response>\\n            <browser-com...   \n4  \\n        <response>\\n            <browser-com...   \n\n                                              prompt  \\\n0  ### Instruction:\\n    Use the Task and Input g...   \n1  ### Instruction:\\n    Use the Task and Input g...   \n2  ### Instruction:\\n    Use the Task and Input g...   \n3  ### Instruction:\\n    Use the Task and Input g...   \n4  ### Instruction:\\n    Use the Task and Input g...   \n\n                                            response  \n0  <response><browser-command>search google schol...  \n1  <response><browser-command>search google schol...  \n2  <response><browser-command>search new tab</bro...  \n3  <response><browser-command>search google curre...  \n4  <response><browser-command>search google new t...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>input</th>\n      <th>output</th>\n      <th>prompt</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n      <td>&lt;response&gt;&lt;browser-command&gt;search google schol...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n      <td>&lt;response&gt;&lt;browser-command&gt;search google schol...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n      <td>&lt;response&gt;&lt;browser-command&gt;search new tab&lt;/bro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n      <td>&lt;response&gt;&lt;browser-command&gt;search google curre...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Your job is to discern the intent of a human v...</td>\n      <td>\\n        Below is the raw human voice command...</td>\n      <td>\\n        &lt;response&gt;\\n            &lt;browser-com...</td>\n      <td>### Instruction:\\n    Use the Task and Input g...</td>\n      <td>&lt;response&gt;&lt;browser-command&gt;search google new t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[ 'response' ] = responses\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T22:14:25.570141Z",
     "start_time": "2023-12-21T22:14:25.562175Z"
    }
   },
   "id": "636a1d8f00d58761"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Install notebook magic that forces reload a source code\n",
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T18:05:25.920128Z",
     "start_time": "2023-12-21T18:05:25.854797Z"
    }
   },
   "id": "64208c933aab83d5"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "'/var/model/genie-in-the-box/src'"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir( \"/var/model/genie-in-the-box/src\" )\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T22:14:25.583970Z",
     "start_time": "2023-12-21T22:14:25.562447Z"
    }
   },
   "id": "2933dc0ac5dcd1df"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XmlFineTuningPromptGenerator...\n",
      "Commands file for [search new tab] exists: True\n",
      "Commands file for [search current tab] exists: True\n",
      "Commands file for [search google new tab] exists: True\n",
      "Commands file for [search google current tab] exists: True\n",
      "Commands file for [search google scholar new tab] exists: True\n",
      "Commands file for [search google scholar current tab] exists: True\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "- Validation Stats\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "               Is valid xml 100.0%\n",
      "          Contains response 100.0%\n",
      "   Contains browser command 100.0%\n",
      "              Contains args 100.0%\n",
      "          Response is exact 99.3%\n",
      "Response has correct values 99.3%\n",
      " Browser command is correct 99.6%\n",
      "            Args is correct 99.7%\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from ephemera.prompts.xml_fine_tuning_prompt_generator import XmlFineTuningPromptGenerator\n",
    "\n",
    "# Advice from phind when auto reload fails: https://www.phind.com/search?cache=l7c51x1v3tids6l43mgkkm9j\n",
    "os.chdir( \"/var/model/genie-in-the-box/src\" )\n",
    "%run \"ephemera/prompts/xml_fine_tuning_prompt_generator.py\"  \n",
    "\n",
    "xml_ftp_generator = XmlFineTuningPromptGenerator( path_prefix=\"/var/model/genie-in-the-box\" )\n",
    "\n",
    "test_df = xml_ftp_generator.validate_prompts_and_responses( test_df )\n",
    "\n",
    "xml_ftp_generator.print_validation_stats( test_df )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T22:14:25.943712Z",
     "start_time": "2023-12-21T22:14:25.565417Z"
    }
   },
   "id": "1b459e918a397994"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b9ec021e401e8645"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
